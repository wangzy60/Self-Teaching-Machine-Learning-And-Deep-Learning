{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac5f6d5d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#验证模型实现\" data-toc-modified-id=\"验证模型实现-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>验证模型实现</a></span></li><li><span><a href=\"#验证结果分析\" data-toc-modified-id=\"验证结果分析-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>验证结果分析</a></span><ul class=\"toc-item\"><li><span><a href=\"#结论\" data-toc-modified-id=\"结论-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>结论</a></span></li><li><span><a href=\"#过拟合分析\" data-toc-modified-id=\"过拟合分析-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>过拟合分析</a></span><ul class=\"toc-item\"><li><span><a href=\"#首先尝试增加dropout层，在resnet18提取完图片的特征之后，使用一个dropout层，分别尝试了0.3,0.5,0.7三个不同丢弃率的dropout层，下面是结果:\" data-toc-modified-id=\"首先尝试增加dropout层，在resnet18提取完图片的特征之后，使用一个dropout层，分别尝试了0.3,0.5,0.7三个不同丢弃率的dropout层，下面是结果:-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>首先尝试增加dropout层，在resnet18提取完图片的特征之后，使用一个dropout层，分别尝试了0.3,0.5,0.7三个不同丢弃率的dropout层，下面是结果:</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338e4c1",
   "metadata": {},
   "source": [
    "# 验证模型，解决过拟合问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdc914",
   "metadata": {},
   "source": [
    "## 验证模型实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6ea8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm \n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "import json\n",
    "\n",
    "    \n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,img_path,label_content=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_path.sort()\n",
    "        if label_content is not None:\n",
    "            self.label_content = label_content\n",
    "        else:\n",
    "            self.label_content = None\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_path = self.img_path[index]\n",
    "        img_cv2 = cv2.imread(img_path)  #return （H，W，C），C list by B，G，R\n",
    "        img_cv2 = cv2.resize(img_cv2,(200,100))  #cv2.resize(obj,(width,height))\n",
    "        img_array = img_cv2.transpose(2,0,1)\n",
    "        return img_array\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "    \n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,T,img_width):\n",
    "        super().__init__()\n",
    "        self.img_width = img_width\n",
    "        self.cnn_out_width = self.cal_finnal_width()\n",
    "        #self.cnn: input(N,3,100,200),output(N,512,4,7)\n",
    "        trained_resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        self.cnn = nn.Sequential(trained_resnet18.conv1,\n",
    "                                 trained_resnet18.bn1,\n",
    "                                 trained_resnet18.relu,\n",
    "                                 trained_resnet18.maxpool,\n",
    "                                 trained_resnet18.layer1,\n",
    "                                 trained_resnet18.layer2,\n",
    "                                 trained_resnet18.layer3,\n",
    "                                 trained_resnet18.layer4)\n",
    "        #self.feat_to_seq: input(N,7,512,1),output(N,30,512,1)\n",
    "        self.feat_to_seq = nn.Conv2d(self.cnn_out_width,T,kernel_size=(1,1),stride=1)\n",
    "        #self.rnn: input(30,N,512),output(30,N,64*2)\n",
    "        self.rnn = nn.GRU(input_size=512,hidden_size=64,bidirectional=True)\n",
    "        #self.linear: input(30,N,64*2),output(30,N,11)\n",
    "        self.linear = nn.Linear(128,11)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = self.cnn(X)\n",
    "        X = X.mean(dim=2,keepdim=True)\n",
    "        X = X.permute((0,3,1,2))\n",
    "        X = self.feat_to_seq(X)\n",
    "        X = X.permute((1,0,2,3))\n",
    "        X = X.squeeze(dim=3)\n",
    "        X,_ = self.rnn(X)\n",
    "        y_hat = self.linear(X)\n",
    "        return y_hat\n",
    "\n",
    "    def cal_finnal_width(self):\n",
    "        width = self.img_width\n",
    "        for i in range(5):\n",
    "            if width%2 == 0:\n",
    "                width = int(width/2)\n",
    "            else:\n",
    "                width = int(width/2)+1\n",
    "        return width\n",
    "    \n",
    "    \n",
    "class ValidModel():\n",
    "    def __init__(self,saved_model_path=None,T=30,img_width=200):\n",
    "        self.model = MyModel(T,img_width)\n",
    "        if saved_model_path is not None:\n",
    "            best_state_dict = torch.load(os.path.join('./',saved_model_path))\n",
    "            self.model.load_state_dict(best_state_dict)\n",
    "            if torch.cuda.is_available():\n",
    "                self.model.cuda()\n",
    "                print(saved_model_path,' cuda model load success!')\n",
    "            else:\n",
    "                print(saved_model_path,' model load success!')\n",
    "        else:\n",
    "            return('model loading failed')\n",
    "\n",
    "    def predict(self,img_fold_path):\n",
    "        img_path = glob.glob(os.path.join(img_fold_path,'*.png'))\n",
    "        my_dataset = MyDataset(img_path)\n",
    "        self.my_dataloader = DataLoader(my_dataset,batch_size=1)\n",
    "#         print(self.my_dataloader)\n",
    "\n",
    "        self.prediction_dict = OrderedDict()\n",
    "        my_dataloader = self.my_dataloader\n",
    "        my_dataloader = tqdm(my_dataloader,ncols=60)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for batch_index,batch_data in enumerate(my_dataloader):\n",
    "                X = batch_data.float()\n",
    "                if torch.cuda.is_available:\n",
    "                    X = X.cuda()\n",
    "                y_hat = self.model(X)\n",
    "                y_hat = y_hat.permute(1,0,2).cpu()\n",
    "                pred = torch.argmax(y_hat,dim=2)\n",
    "                batch_size = pred.shape[0]\n",
    "                pred_list = []\n",
    "                for i in range(batch_size):\n",
    "                    raw_pred_list = list(pred[i].numpy())\n",
    "                    pred_data = []\n",
    "                    for j in range(len(raw_pred_list)):\n",
    "                        if j == 0 and raw_pred_list[0] != 0:\n",
    "                            pred_data.append(raw_pred_list[0]-1)\n",
    "                        if j != 0 and raw_pred_list[j] != raw_pred_list[j-1] and raw_pred_list[j] != 0:\n",
    "                            pred_data.append(raw_pred_list[j]-1)\n",
    "                    if len(pred_data) != 0:\n",
    "                        pred_num = ''.join([str(int(num)) for num in pred_data])\n",
    "                        pred_num = int(pred_num)\n",
    "                        img_name = os.path.split(img_path[batch_index])[1]\n",
    "                        self.prediction_dict[img_name] = pred_num\n",
    "                    else:\n",
    "                        img_name = os.path.split(img_path[batch_index])[1]\n",
    "                        self.prediction_dict[img_name] = -1\n",
    "        \n",
    "        return self.prediction_dict\n",
    "            \n",
    "    def get_accurancy(self,label_path):\n",
    "        predict_right_num = 0 \n",
    "        prediction_dict = self.prediction_dict\n",
    "        label_content = json.load(open(label_path))\n",
    "        if len(prediction_dict.keys()) == len(label_content.keys()):\n",
    "            for img_name in prediction_dict.keys():\n",
    "                if prediction_dict[img_name] == int(''.join([str(x) for x in label_content[img_name]['label']])):\n",
    "                    predict_right_num+=1\n",
    "            acc = (predict_right_num/len(prediction_dict))\n",
    "            return acc\n",
    "        else:\n",
    "            print('label path error or may be need to call predict first')\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce525b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crnn_resnet18_ctc_best  cuda model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 30000/30000 [02:49<00:00, 176.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 30000\n",
      "train acc: 0.9961666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 10000/10000 [00:58<00:00, 171.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val len: 10000\n",
      "val acc: 0.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "class_list =['train','val']\n",
    "my_valid = ValidModel(saved_model_path='crnn_resnet18_ctc_best')\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))\n",
    "index = 1\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167890a",
   "metadata": {},
   "source": [
    "## 验证结果分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f82d23",
   "metadata": {},
   "source": [
    "### 结论\n",
    "　　从上面第一次使用验证集的结果来看，验证集的准确度只有0.58，而此时训练集的精度已经到了0.99，模型明显过拟合了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142ed76",
   "metadata": {},
   "source": [
    "### 过拟合分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0373a",
   "metadata": {},
   "source": [
    "　　常见的过拟合原因有几种，大概是在两个方面，一是数据端，一是模型端:   \n",
    "  \n",
    "　　对于数据来说， 1.数据数量不够导致模型过拟合，可以通过增加数据数量来解决。2.数据特征较多，有些特征相互关联影响，可以通过添加dropout层来解决。  \n",
    "  \n",
    "　　对于模型来说，3.模型过于复杂，参数多。模型过于复杂可以通过减少模型某些维度来解决，参数多可以通过通过添加正则项来解决。下面依次尝试这些办法，看是否能减少过拟合，在验证集上获得更好的表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce3137",
   "metadata": {},
   "source": [
    "#### 首先尝试增加dropout层，在resnet18提取完图片的特征之后，使用一个dropout层，分别尝试了0.3,0.5,0.7三个不同丢弃率的dropout层，下面是结果:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c45e5545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crnn_resnet18_ctc_dropout0.3_best  cuda model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 30000/30000 [02:50<00:00, 175.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 30000\n",
      "train acc: 0.9917666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████| 10000/10000 [01:47<00:00, 92.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val len: 10000\n",
      "val acc: 0.5791\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "class_list =['train','val']\n",
    "my_valid = ValidModel(saved_model_path='crnn_resnet18_ctc_dropout0.3_best')\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))\n",
    "index = 1\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b95b59a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crnn_resnet18_ctc_dropout0.5_best  cuda model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 30000/30000 [02:48<00:00, 178.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 30000\n",
      "train acc: 0.9739333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 10000/10000 [01:31<00:00, 109.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val len: 10000\n",
      "val acc: 0.5982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "class_list =['train','val']\n",
    "my_valid = ValidModel(saved_model_path='crnn_resnet18_ctc_dropout0.5_best')\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))\n",
    "index = 1\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a3270e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crnn_resnet18_ctc_dropout0.7_best  cuda model load success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████| 30000/30000 [05:11<00:00, 96.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 30000\n",
      "train acc: 0.9439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████| 10000/10000 [01:38<00:00, 101.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val len: 10000\n",
      "val acc: 0.5803\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "class_list =['train','val']\n",
    "my_valid = ValidModel(saved_model_path='crnn_resnet18_ctc_dropout0.7_best')\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))\n",
    "index = 1\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b9819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,img_path,label_content,img_width,img_height):\n",
    "        self.img_path = img_path\n",
    "        self.label_content = label_content\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_path = self.img_path[index]\n",
    "        img_cv2 = cv2.imread(img_path)  #return （H，W，C），C list by B，G，R\n",
    "        img_array = cv2.resize(img_cv2,(self.img_width,self.img_height))  #cv2.resize的输出为（w,h），宽在前，高在后\n",
    "        \n",
    "        img_name = os.path.split(img_path)[1]\n",
    "        img_label = self.label_content[img_name]['label']\n",
    "        #transform the label 0~9 to index 1~10，index 0 is for blank\n",
    "        img_label_index_list = [x+1 for x in img_label]\n",
    "        \n",
    "        return img_array,img_label_index_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,T,img_width,dropout):\n",
    "        super().__init__()\n",
    "        self.img_width = img_width\n",
    "        self.img_height = int(0.5*self.img_width)\n",
    "        self.cnn_out_width = self.cal_finnal_width()\n",
    "        self.cnn_out_height = self.cal_finnal_height()\n",
    "        #self.cnn: input(N,3,240,480),output(N,512,8,15)\n",
    "        trained_resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        self.cnn = nn.Sequential(trained_resnet18.conv1,\n",
    "                                 trained_resnet18.bn1,\n",
    "                                 trained_resnet18.relu,\n",
    "                                 trained_resnet18.maxpool,\n",
    "                                 trained_resnet18.layer1,\n",
    "                                 trained_resnet18.layer2,\n",
    "                                 trained_resnet18.layer3,\n",
    "                                 trained_resnet18.layer4)\n",
    "        self.feat_to_seq = nn.Conv2d(self.cnn_out_height,1,kernel_size=(1,1),stride=1)\n",
    "        self.rnn = nn.GRU(input_size=512,hidden_size=64,batch_first=True,bidirectional=True)\n",
    "        self.linear = nn.Linear(128,11)\n",
    "    \n",
    "    def forward(self,X):\n",
    "#         print('X:',X.shape)\n",
    "        X = self.cnn(X)\n",
    "#         print('cnn:',X.shape)\n",
    "        X = X.permute((0,2,1,3))\n",
    "        X = self.feat_to_seq(X)\n",
    "#         print('feat_to_seq:',X.shape)\n",
    "        X = X.permute((0,3,1,2))\n",
    "#         print('permute:',X.shape)\n",
    "        X = X.squeeze(dim=2)\n",
    "#         print('squeeze:',X.shape)\n",
    "        X,_ = self.rnn(X)\n",
    "#         print('rnn:',X.shape)\n",
    "        X = self.linear(X)\n",
    "        X = X.permute((1,0,2))\n",
    "#         print('linear:',X.shape)\n",
    "        return X\n",
    "\n",
    "    def cal_finnal_width(self):\n",
    "        width = self.img_width\n",
    "        for i in range(5):\n",
    "            if width%2 == 0:\n",
    "                width = int(width/2)\n",
    "            else:\n",
    "                width = int(width/2)+1\n",
    "        return width\n",
    "\n",
    "    def cal_finnal_height(self):\n",
    "        height = self.img_height\n",
    "        for i in range(5):\n",
    "            if height%2 == 0:\n",
    "                height = int(height/2)\n",
    "            else:\n",
    "                height = int(height/2)+1\n",
    "        return height\n",
    "\n",
    "class ValidModel():\n",
    "    def __init__(self,saved_model_path=None,T=30,img_width=200):\n",
    "        self.model = MyModel(T,img_width)\n",
    "        if saved_model_path is not None:\n",
    "            best_state_dict = torch.load(os.path.join('./',saved_model_path))\n",
    "            self.model.load_state_dict(best_state_dict)\n",
    "            if torch.cuda.is_available():\n",
    "                self.model.cuda()\n",
    "                print(saved_model_path,' cuda model load success!')\n",
    "            else:\n",
    "                print(saved_model_path,' model load success!')\n",
    "        else:\n",
    "            return('model loading failed')\n",
    "\n",
    "    def predict(self,img_fold_path):\n",
    "        img_path = glob.glob(os.path.join(img_fold_path,'*.png'))\n",
    "        my_dataset = MyDataset(img_path)\n",
    "        self.my_dataloader = DataLoader(my_dataset,batch_size=1)\n",
    "#         print(self.my_dataloader)\n",
    "\n",
    "        self.prediction_dict = OrderedDict()\n",
    "        my_dataloader = self.my_dataloader\n",
    "        my_dataloader = tqdm(my_dataloader,ncols=60)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for batch_index,batch_data in enumerate(my_dataloader):\n",
    "                X = batch_data.float()\n",
    "                if torch.cuda.is_available:\n",
    "                    X = X.cuda()\n",
    "                y_hat = self.model(X)\n",
    "                y_hat = y_hat.permute(1,0,2).cpu()\n",
    "                pred = torch.argmax(y_hat,dim=2)\n",
    "                batch_size = pred.shape[0]\n",
    "                pred_list = []\n",
    "                for i in range(batch_size):\n",
    "                    raw_pred_list = list(pred[i].numpy())\n",
    "                    pred_data = []\n",
    "                    for j in range(len(raw_pred_list)):\n",
    "                        if j == 0 and raw_pred_list[0] != 0:\n",
    "                            pred_data.append(raw_pred_list[0]-1)\n",
    "                        if j != 0 and raw_pred_list[j] != raw_pred_list[j-1] and raw_pred_list[j] != 0:\n",
    "                            pred_data.append(raw_pred_list[j]-1)\n",
    "                    if len(pred_data) != 0:\n",
    "                        pred_num = ''.join([str(int(num)) for num in pred_data])\n",
    "                        pred_num = int(pred_num)\n",
    "                        img_name = os.path.split(img_path[batch_index])[1]\n",
    "                        self.prediction_dict[img_name] = pred_num\n",
    "                    else:\n",
    "                        img_name = os.path.split(img_path[batch_index])[1]\n",
    "                        self.prediction_dict[img_name] = -1\n",
    "        \n",
    "        return self.prediction_dict\n",
    "            \n",
    "    def get_accurancy(self,label_path):\n",
    "        predict_right_num = 0 \n",
    "        prediction_dict = self.prediction_dict\n",
    "        label_content = json.load(open(label_path))\n",
    "        if len(prediction_dict.keys()) == len(label_content.keys()):\n",
    "            for img_name in prediction_dict.keys():\n",
    "                if prediction_dict[img_name] == int(''.join([str(x) for x in label_content[img_name]['label']])):\n",
    "                    predict_right_num+=1\n",
    "            acc = (predict_right_num/len(prediction_dict))\n",
    "            return acc\n",
    "        else:\n",
    "            print('label path error or may be need to call predict first')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba9d5ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13012/1050441173.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclass_list\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmy_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mValidModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'crnn_resnet18_ctc_valid_0.655'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvalid_dataset_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_valid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../input/{class_list[index]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{class_list[index]} len:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_dataset_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13012/2942673739.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, saved_model_path, T, img_width)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mValidModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msaved_model_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mbest_state_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'dropout'"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "class_list =['train','val']\n",
    "my_valid = ValidModel(saved_model_path='crnn_resnet18_ctc_valid_0.655',T=15,img_width=480)\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))\n",
    "index = 1\n",
    "valid_dataset_prediction = my_valid.predict(f'../input/{class_list[index]}')\n",
    "print(f'{class_list[index]} len:',len(valid_dataset_prediction.keys()))\n",
    "print(f'{class_list[index]} acc:',my_valid.get_accurancy(f'../input/{class_list[index]}.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51241ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
