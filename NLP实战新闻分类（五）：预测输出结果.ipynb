{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beae2c1e",
   "metadata": {},
   "source": [
    "# 模型验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df8dc6",
   "metadata": {},
   "source": [
    "## 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bf82541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def split_train_valid(csv_path,train_prec=0.75):\n",
    "    csv_data = pd.read_csv(csv_path,sep='\\t') \n",
    "    text_data = csv_data.text\n",
    "    label_data = csv_data.label\n",
    "    \n",
    "    mask = np.random.rand(len(text_data))<train_prec\n",
    "    train_text_data = text_data[mask].reset_index(drop=True)\n",
    "    valid_text_data = text_data[~mask].reset_index(drop=True)\n",
    "    train_label_data = label_data[mask].reset_index(drop=True)\n",
    "    valid_label_data = label_data[~mask].reset_index(drop=True)\n",
    "    \n",
    "    return train_text_data,valid_text_data,train_label_data,valid_label_data\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,text_data,label_data):\n",
    "        self.text_data = text_data\n",
    "        self.label_data = label_data\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        #所有text内的token索引增加1，0空出来代表空格，将每个text控制在1000长\n",
    "        text_str = self.text_data[index]\n",
    "        text_list = [int(x)+1 for x in text_str.split()]\n",
    "        if len(text_list)>=1000:\n",
    "            text_list = text_list[:1000]\n",
    "        else:\n",
    "            text_list.extend([0]*(1000-len(text_list)))\n",
    "        text_array = np.array(text_list)\n",
    "        label_array = np.array(self.label_data[index])\n",
    "        return text_array,label_array\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_data)\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(7551,101)\n",
    "        self.rnn = nn.GRU(101,50,batch_first=True,bidirectional=True)\n",
    "        self.fc = nn.Linear(100,14)\n",
    "        \n",
    "    def forward(self,X):\n",
    "#         print('X:',X.shape)\n",
    "        X = self.embedding(X)\n",
    "#         print('embedding:',X.shape)\n",
    "        _,X = self.rnn(X)\n",
    "#         print('rnn:',X.shape)\n",
    "        X = X.permute(1,0,2)\n",
    "        X = X.reshape((X.shape[0],-1))\n",
    "#         print('trans:',X.shape)\n",
    "        y_hat = self.fc(X)\n",
    "#         print('y_hat:',y_hat.shape)\n",
    "        return y_hat\n",
    "\n",
    "    \n",
    "class MyTrain():\n",
    "    def __init__(self,max_epoch=1,random_seed=1,lr=0.001,out_dir='./'):\n",
    "        self.max_epoch = max_epoch\n",
    "        self.random_seed = random_seed\n",
    "        self.lr = lr\n",
    "        self.out_dir = out_dir\n",
    "        self.iter = 0\n",
    "        \n",
    "    def fix_random(self):\n",
    "        import random\n",
    "        import numpy as np\n",
    "        import torch\n",
    "        random.seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        torch.random.manual_seed(self.random_seed)\n",
    "        torch.cuda.random.manual_seed_all(self.random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        print(f'random seed:{self.random_seed}')\n",
    "        \n",
    "    def my_train(self):\n",
    "        \n",
    "        max_epoch,lr = self.max_epoch,self.lr\n",
    "        \n",
    "        if self.random_seed is not None:\n",
    "            self.fix_random()\n",
    "        \n",
    "        train_text_data,valid_text_data,train_label_data,valid_label_data = split_train_valid('./train_set.csv',train_prec=0.75)\n",
    "        train_dataset = MyDataset(train_text_data,train_label_data)\n",
    "        valid_dataset = MyDataset(valid_text_data,valid_label_data)\n",
    "        \n",
    "        my_model = MyModel()\n",
    "        my_optim = torch.optim.Adam(my_model.parameters(),lr=lr)\n",
    "        my_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            my_model.cuda()\n",
    "            my_loss.cuda()\n",
    "        print(f'train device:{next(iter(my_model.parameters())).device}')  #显示训练设备\n",
    "        \n",
    "        best_f1_score = 0\n",
    "        epoch_index = 0\n",
    "\n",
    "        for epoch_index in range(max_epoch):\n",
    "            \n",
    "            loss_list = []\n",
    "            train_f1_score_list = []\n",
    "            valid_f1_score_list = []\n",
    "            train_dataloader = DataLoader(train_dataset,batch_size=120,shuffle=True)\n",
    "            valid_dataloader = DataLoader(valid_dataset,batch_size=40,shuffle=True)\n",
    "            my_dataloader = tqdm(train_dataloader)\n",
    "            \n",
    "            batch_index = 0\n",
    "                        \n",
    "            for train_data,valid_data in zip(my_dataloader,valid_dataloader):\n",
    "                                \n",
    "                my_model.train()  #将模型设置为训练模式\n",
    "                train_text,train_label = train_data\n",
    "                valid_text,valid_label = valid_data\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    train_text = train_text.cuda()\n",
    "                    train_label = train_label.cuda()\n",
    "                    valid_text = valid_text.cuda()\n",
    "                    valid_label = valid_label.cuda()\n",
    "                \n",
    "                train_y_hat = my_model(train_text)\n",
    "                batch_train_loss = my_loss(train_y_hat,train_label)\n",
    "                \n",
    "                my_optim.zero_grad()\n",
    "                batch_train_loss.backward()\n",
    "                my_optim.step()\n",
    "                my_optim.param_groups[0]['lr'] = lr*(0.8**(epoch_index%10))\n",
    "        \n",
    "                my_model.eval()  #将模型设置为验证模式\n",
    "                with torch.no_grad():\n",
    "                    valid_y_hat = my_model(valid_text)\n",
    "                    batch_valid_f1_score = self.f1_score(valid_y_hat.data,valid_label.data)\n",
    "                    valid_f1_score_list.append(batch_valid_f1_score)\n",
    "                    mean_valid_f1 = round(sum(valid_f1_score_list)/len(valid_f1_score_list),3)\n",
    "\n",
    "                    #显示batch结果\n",
    "                    batch_lr = round(my_optim.param_groups[0]['lr'],5)\n",
    "                    batch_loss = round(batch_train_loss.item(),4)\n",
    "                    loss_list.append(batch_loss)\n",
    "                    mean_loss = round((sum(loss_list)/len(loss_list)),3)\n",
    "\n",
    "                    batch_train_f1_score = self.f1_score(train_y_hat.data,train_label.data)\n",
    "                    train_f1_score_list.append(batch_train_f1_score)\n",
    "                    mean_train_f1 = round(sum(train_f1_score_list)/len(train_f1_score_list),3)\n",
    "\n",
    "                    my_dataloader.set_description(f'epoch:{epoch_index},batch:{batch_index},lr:{batch_lr},loss:{batch_loss},mean_loss:{mean_loss},train_f1:{mean_train_f1},valid_f1:{mean_valid_f1}')\n",
    "\n",
    "                    #存储模型\n",
    "                    if batch_train_f1_score>best_f1_score:\n",
    "                        torch.save(my_model.state_dict(),os.path.join(self.out_dir,'embedding_gru_best'))\n",
    "                        best_f1_score = batch_train_f1_score\n",
    "\n",
    "                    batch_index+=1\n",
    "            \n",
    "                \n",
    "    def f1_score(self,y_hat,label,eps=1e-8):\n",
    "        #y_hat(N,C),label(1)\n",
    "        y_hat = y_hat.cpu()\n",
    "        label = label.cpu()\n",
    "        preds_list = list(torch.argmax(y_hat,dim=1).numpy())\n",
    "        label_list = list(label.numpy())\n",
    "#         print(f'preds:{preds_list},label:{label_list}')\n",
    "        class_index_list = []\n",
    "        for class_index in label_list:\n",
    "            if class_index not in class_index_list:\n",
    "                class_index_list.append(class_index)\n",
    "\n",
    "        f1_score_list = []\n",
    "        for index in class_index_list:\n",
    "            if index not in preds_list:\n",
    "                sub_f1_score = 0\n",
    "            else:\n",
    "                tp = 0\n",
    "                fp = 0\n",
    "                fn = 0\n",
    "                for i in range(len(preds_list)):\n",
    "                    if preds_list[i] == index and label_list[i] == index:\n",
    "                        tp+=1\n",
    "                    if preds_list[i] == index and label_list[i] != index: \n",
    "                        fp+=1\n",
    "                    if preds_list[i] != index and label_list[i] == index:\n",
    "                        fn+=1\n",
    "                prec_val = tp/(tp+fp) \n",
    "                recall_val = tp/(tp+fn)\n",
    "                sub_f1_score = 2*(prec_val*recall_val)/(prec_val+recall_val+eps)\n",
    "            f1_score_list.append(sub_f1_score)\n",
    "\n",
    "        batch_f1_score = sum(f1_score_list)/len(f1_score_list)\n",
    "\n",
    "        return batch_f1_score\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b830f",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09f5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_path,test_data_path,model='train'):\n",
    "    p_model = MyModel()\n",
    "    best_stat_dict = torch.load(model_path)\n",
    "    p_model.load_state_dict(best_stat_dict)\n",
    "    if torch.cuda.is_available():\n",
    "        p_model.cuda()\n",
    "    test_data = pd.read_csv(test_data_path,sep='\\t')\n",
    "    test_text = test_data.text\n",
    "    if model == 'test':\n",
    "        test_label = np.ones_like(test_text) #当预测的不是train数据时，虚拟一个方便生成dataset和DataLoader\n",
    "    if model == 'train':\n",
    "        test_label = test_data.label\n",
    "    test_dataset = MyDataset(test_text,test_label)\n",
    "    test_dataloader = DataLoader(test_dataset,batch_size=1)\n",
    "    test_dataloader = tqdm(test_dataloader)\n",
    "    pred_list = []\n",
    "    for test_index,batch_data in enumerate(test_dataloader):\n",
    "        batch_text,batch_label = batch_data\n",
    "        if torch.cuda.is_available():\n",
    "            batch_text = batch_text.cuda()\n",
    "        p_model.eval()\n",
    "        preds = p_model(batch_text)\n",
    "        pred_class_index = preds.argmax()\n",
    "        pred_list.append(pred_class_index.item())\n",
    "\n",
    "    print(len(pred_list))\n",
    "    if model=='train':\n",
    "        train_f1_score = p_model.f1_score(preds,test_label)\n",
    "        print('train_set_f1:',train_f1_score)\n",
    "        \n",
    "    return pred_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1fadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [02:27<00:00, 339.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_path = 'embedding_gru_best_2674word_valid_f1_score_0.929'\n",
    "    \n",
    "    pred_list = predict(os.path.join('./',model_path),'./test.csv',model='test')\n",
    "    pred_data = pd.DataFrame(pred_list)\n",
    "    pred_data.head()\n",
    "    pred_data.to_csv('test_pred.csv',sep='\\t',index=False)\n",
    "    print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb7c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
