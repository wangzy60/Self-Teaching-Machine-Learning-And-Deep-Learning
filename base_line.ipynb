{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建数据处理\n",
    "\n",
    "CRNN demo 线上 0.62，还有一些问题，需要调参~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T13:42:49.380377Z",
     "start_time": "2020-06-04T13:42:48.604691Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def text_collate(batch):\n",
    "    img = list()\n",
    "    seq = list()\n",
    "    seq_len = list()\n",
    "    for sample in batch:\n",
    "        img.append(torch.from_numpy(sample[\"img\"].transpose((2, 0, 1))).float())\n",
    "        seq.extend(sample[\"seq\"])\n",
    "        seq_len.append(sample[\"seq_len\"])\n",
    "    img = torch.stack(img)\n",
    "    seq = torch.Tensor(seq).int()\n",
    "    seq_len = torch.Tensor(seq_len).int()\n",
    "    batch = {\"img\": img, \"seq\": seq, \"seq_len\": seq_len}\n",
    "    return batch\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        sample[\"img\"] = torch.from_numpy(sample[\"img\"].transpose((2, 0, 1))).float()\n",
    "        sample[\"seq\"] = torch.Tensor(sample[\"seq\"]).int()\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, size=(320, 32)):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample[\"img\"] = cv2.resize(sample[\"img\"], self.size)\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Rotation(object):\n",
    "    def __init__(self, angle=5, fill_value=0, p = 0.5):\n",
    "        self.angle = angle\n",
    "        self.fill_value = fill_value\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if np.random.uniform(0.0, 1.0) < self.p or not sample[\"aug\"]:\n",
    "            return sample\n",
    "        h,w,_ = sample[\"img\"].shape\n",
    "        ang_rot = np.random.uniform(self.angle) - self.angle/2\n",
    "        transform = cv2.getRotationMatrix2D((w/2, h/2), ang_rot, 1)\n",
    "        sample[\"img\"] = cv2.warpAffine(sample[\"img\"], transform, (w,h), borderValue = self.fill_value)\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Translation(object):\n",
    "    def __init__(self, fill_value=0, p = 0.5):\n",
    "        self.fill_value = fill_value\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if np.random.uniform(0.0, 1.0) < self.p or not sample[\"aug\"]:\n",
    "            return sample\n",
    "        h,w,_ = sample[\"img\"].shape\n",
    "        trans_range = [w / 10, h / 10]\n",
    "        tr_x = trans_range[0]*np.random.uniform()-trans_range[0]/2\n",
    "        tr_y = trans_range[1]*np.random.uniform()-trans_range[1]/2\n",
    "        transform = np.float32([[1,0, tr_x], [0,1, tr_y]])\n",
    "        sample[\"img\"] = cv2.warpAffine(sample[\"img\"], transform, (w,h), borderValue = self.fill_value)\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Scale(object):\n",
    "    def __init__(self, scale=[0.5, 1.2], fill_value=0, p = 0.5):\n",
    "        self.scale = scale\n",
    "        self.fill_value = fill_value\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if np.random.uniform(0.0, 1.0) < self.p or not sample[\"aug\"]:\n",
    "            return sample\n",
    "        h, w, _ = sample[\"img\"].shape\n",
    "        scale = np.random.uniform(self.scale[0], self.scale[1])\n",
    "        transform = np.float32([[scale, 0, 0],[0, scale, 0]])\n",
    "        sample[\"img\"] = cv2.warpAffine(sample[\"img\"], transform, (w,h), borderValue = self.fill_value)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T13:42:49.387083Z",
     "start_time": "2020-06-04T13:42:49.381986Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data_path, data_label, transform=None):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.data_label = data_label\n",
    "        self.transform = transform\n",
    "\n",
    "    def abc_len(self):\n",
    "        return len('0123456789')\n",
    "\n",
    "    def get_abc(self):\n",
    "        return '0123456789'\n",
    "\n",
    "    def set_mode(self, mode):\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data_label[idx]\n",
    "\n",
    "        img = cv2.imread(self.data_path[idx])\n",
    "        seq = self.text_to_seq(text)\n",
    "        sample = {\"img\": img, \"seq\": seq, \"seq_len\": len(seq), \"aug\": 1}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    def text_to_seq(self, text):\n",
    "        seq = []\n",
    "        for c in text:\n",
    "            seq.append(self.get_abc().find(str(c)) + 1)\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建CRNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T13:42:49.664717Z",
     "start_time": "2020-06-04T13:42:49.570488Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.models as models\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 abc='0123456789',\n",
    "                 backend='resnet18',\n",
    "                 rnn_hidden_size=64,\n",
    "                 rnn_num_layers=1,\n",
    "                 rnn_dropout=0,\n",
    "                 seq_proj=[0, 0]):\n",
    "        super(CRNN, self).__init__()\n",
    "\n",
    "        self.abc = abc\n",
    "        self.num_classes = len(self.abc)\n",
    "\n",
    "        self.feature_extractor = getattr(models, backend)(weights = 'DEFAULT')\n",
    "        self.cnn = nn.Sequential(\n",
    "            self.feature_extractor.conv1,\n",
    "            self.feature_extractor.bn1,\n",
    "            self.feature_extractor.relu,\n",
    "            self.feature_extractor.maxpool,\n",
    "            self.feature_extractor.layer1,\n",
    "            self.feature_extractor.layer2,\n",
    "            self.feature_extractor.layer3,\n",
    "            self.feature_extractor.layer4\n",
    "        )\n",
    "\n",
    "        self.fully_conv = seq_proj[0] == 0\n",
    "        if not self.fully_conv:\n",
    "            self.proj = nn.Conv2d(seq_proj[0], seq_proj[1], kernel_size=1)\n",
    "\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        self.rnn = nn.GRU(self.get_block_size(self.cnn),\n",
    "                          rnn_hidden_size, rnn_num_layers,\n",
    "                          batch_first=False,\n",
    "                          dropout=rnn_dropout, bidirectional=True)\n",
    "        self.linear = nn.Linear(rnn_hidden_size * 2, self.num_classes + 1)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x, decode=False):\n",
    "        hidden = self.init_hidden(x.size(0), next(self.parameters()).is_cuda)\n",
    "        features = self.cnn(x)\n",
    "        features = self.features_to_sequence(features)\n",
    "        seq, hidden = self.rnn(features, hidden)\n",
    "        seq = self.linear(seq)\n",
    "        if not self.training:\n",
    "            seq = self.softmax(seq)\n",
    "            if decode:\n",
    "                seq = self.decode(seq)\n",
    "        return seq\n",
    "\n",
    "    def init_hidden(self, batch_size, gpu=False):\n",
    "        h0 = Variable(torch.zeros( self.rnn_num_layers * 2,\n",
    "                                   batch_size,\n",
    "                                   self.rnn_hidden_size))\n",
    "        if gpu:\n",
    "            h0 = h0.cuda()\n",
    "        return h0\n",
    "\n",
    "    def features_to_sequence(self, features):\n",
    "        features = features.mean(2)\n",
    "        b, c, w = features.size()\n",
    "        features = features.reshape(b, c, 1, w)\n",
    "        b, c, h, w = features.size()\n",
    "        print(b, c, h, w)\n",
    "        assert h == 1, \"the height of out must be 1\"\n",
    "        if not self.fully_conv:\n",
    "            features = features.permute(0, 3, 2, 1)\n",
    "            features = self.proj(features)\n",
    "            features = features.permute(1, 0, 2, 3)\n",
    "        else:\n",
    "            features = features.permute(3, 0, 2, 1)\n",
    "        features = features.squeeze(2)\n",
    "        return features\n",
    "\n",
    "    def get_block_size(self, layer):\n",
    "        return layer[-1][-1].bn2.weight.size()[0]\n",
    "\n",
    "    def pred_to_string(self, pred):\n",
    "        seq = []\n",
    "        for i in range(pred.shape[0]):\n",
    "            label = np.argmax(pred[i])\n",
    "            seq.append(label - 1)\n",
    "        out = []\n",
    "        for i in range(len(seq)):\n",
    "            if len(out) == 0:\n",
    "                if seq[i] != -1:\n",
    "                    out.append(seq[i])\n",
    "            else:\n",
    "                if seq[i] != -1 and seq[i] != seq[i - 1]:\n",
    "                    out.append(seq[i])\n",
    "        out = ''.join(self.abc[i] for i in out)\n",
    "        return out\n",
    "\n",
    "    def decode(self, pred):\n",
    "        pred = pred.permute(1, 0, 2).cpu().data.numpy()\n",
    "        seq = []\n",
    "        for i in range(pred.shape[0]):\n",
    "            seq.append(self.pred_to_string(pred[i]))\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T13:42:50.123941Z",
     "start_time": "2020-06-04T13:42:50.114095Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def load_weights(target, source_state):\n",
    "    new_dict = OrderedDict()\n",
    "    for k, v in target.state_dict().items():\n",
    "        if k in source_state and v.size() == source_state[k].size():\n",
    "            new_dict[k] = source_state[k]\n",
    "        else:\n",
    "            new_dict[k] = v\n",
    "    target.load_state_dict(new_dict)\n",
    "\n",
    "def load_model(abc, seq_proj=[0, 0], backend='resnet18', snapshot=None, cuda=True):\n",
    "    net = CRNN(abc=abc, seq_proj=seq_proj, backend=backend)\n",
    "    # net = nn.DataParallel(net)\n",
    "    if snapshot is not None:\n",
    "        load_weights(net, torch.load(snapshot))\n",
    "    if cuda:\n",
    "        net = net.cuda()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T13:42:50.580069Z",
     "start_time": "2020-06-04T13:42:50.574165Z"
    }
   },
   "outputs": [],
   "source": [
    "class StepLR(object):\n",
    "    def __init__(self, optimizer, step_size=1000, max_iter=10000):\n",
    "        self.optimizer = optimizer\n",
    "        self.max_iter = max_iter\n",
    "        self.step_size = step_size\n",
    "        self.last_iter = -1\n",
    "        self.base_lrs = list(map(lambda group: group['lr'], optimizer.param_groups))\n",
    "\n",
    "    def get_lr(self):\n",
    "        return self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "    def step(self, last_iter=None):\n",
    "        if last_iter is not None:\n",
    "            self.last_iter = last_iter\n",
    "        if self.last_iter + 1 == self.max_iter:\n",
    "            self.last_iter = -1\n",
    "        self.last_iter = (self.last_iter + 1) % self.max_iter\n",
    "        for ids, param_group in enumerate(self.optimizer.param_groups):\n",
    "            param_group['lr'] = self.base_lrs[ids] * 0.8 ** ( self.last_iter // self.step_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T13:42:51.111965Z",
     "start_time": "2020-06-04T13:42:51.090418Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import string\n",
    "from tqdm import tqdm_notebook\n",
    "import click\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import editdistance\n",
    "\n",
    "def test(net, data, abc, cuda, batch_size=50):\n",
    "    data_loader = DataLoader(data, batch_size=batch_size,shuffle=False, collate_fn=text_collate)\n",
    "\n",
    "    count = 0\n",
    "    tp = 0\n",
    "    avg_ed = 0\n",
    "    iterator = tqdm_notebook(data_loader)\n",
    "    for sample in iterator:\n",
    "        imgs = Variable(sample[\"img\"])\n",
    "        if cuda:\n",
    "            imgs = imgs.cuda()\n",
    "        out = net(imgs, decode=True)\n",
    "        gt = (sample[\"seq\"].numpy() - 1).tolist()\n",
    "        lens = sample[\"seq_len\"].numpy().tolist()\n",
    "        pos = 0\n",
    "        key = ''\n",
    "        for i in range(len(out)):\n",
    "            gts = ''.join(abc[c] for c in gt[pos:pos+lens[i]])\n",
    "            pos += lens[i]\n",
    "            if gts == out[i]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                avg_ed += editdistance.eval(out[i], gts)\n",
    "            count += 1\n",
    "        iterator.set_description(\"acc: {0:.4f}; avg_ed: {0:.4f}\".format(tp / count, avg_ed / count))\n",
    "\n",
    "    acc = tp / count\n",
    "    avg_ed = avg_ed / count\n",
    "    return acc, avg_ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T14:33:12.675520Z",
     "start_time": "2020-06-04T13:42:51.732348Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 512 1 7\n",
      "1: tensor([[-3.0061e-01,  1.1819e-01, -1.2986e-01,  1.4738e-01,  1.6059e-01,\n",
      "          7.6066e-02, -4.5961e-01,  2.3386e-01, -5.8507e-02,  2.3317e-01,\n",
      "         -2.8817e-01],\n",
      "        [-9.7560e-02, -2.7570e-01, -3.9540e-01,  1.3396e-01, -8.9920e-02,\n",
      "         -1.2376e-01, -3.4916e-01,  2.6837e-01,  3.0012e-01, -1.2210e-01,\n",
      "         -4.9202e-01],\n",
      "        [-5.9928e-02, -2.9837e-01, -3.3365e-01,  2.2516e-01, -2.4375e-01,\n",
      "          1.7116e-01,  2.0111e-01,  2.8916e-01,  2.1435e-01,  1.7502e-02,\n",
      "          2.9515e-02],\n",
      "        [-1.8576e-01, -3.3481e-01, -2.0661e-01,  3.8545e-01, -9.4023e-02,\n",
      "          5.7063e-02, -5.2422e-02,  1.0645e-01, -3.8022e-02, -3.7294e-01,\n",
      "          2.3322e-01],\n",
      "        [ 3.1046e-01, -2.3083e-01, -1.3997e-01,  1.9210e-01, -1.7077e-01,\n",
      "         -3.8175e-01,  9.4731e-03, -2.5459e-01,  1.4377e-03, -1.4594e-01,\n",
      "          3.2116e-01],\n",
      "        [ 2.1083e-01, -3.6418e-01, -5.6386e-01,  1.3253e-01, -1.5115e-01,\n",
      "         -3.5169e-02, -2.0328e-01, -4.3426e-03,  3.0177e-01,  1.4928e-01,\n",
      "          1.1410e-01],\n",
      "        [-8.1210e-02, -3.2334e-01, -4.2498e-01, -3.0263e-03, -8.7993e-02,\n",
      "          3.2992e-01,  2.9143e-01, -1.7304e-01, -1.0446e-02, -1.8115e-01,\n",
      "          1.5338e-01],\n",
      "        [ 3.6671e-02, -4.2217e-01, -1.9602e-01, -1.1615e-03,  5.9598e-02,\n",
      "         -1.7085e-02,  1.4318e-01, -5.1187e-01, -5.9987e-03, -3.0443e-01,\n",
      "          2.4764e-01],\n",
      "        [-2.5502e-03,  6.5853e-03, -2.9660e-01, -8.5888e-02, -9.1321e-03,\n",
      "          2.9808e-01,  1.1052e-01, -6.0523e-02,  1.4930e-02, -1.1124e-01,\n",
      "         -4.7571e-02],\n",
      "        [ 3.0154e-01,  7.6084e-02, -2.4769e-01, -1.8517e-01, -3.3758e-01,\n",
      "         -1.8477e-02, -1.7666e-01, -2.6129e-01,  2.5699e-01, -2.2915e-01,\n",
      "         -4.2680e-01],\n",
      "        [ 3.6086e-01, -1.8197e-01, -4.3379e-01, -1.9390e-02, -3.5830e-01,\n",
      "          2.4152e-01,  4.7896e-01, -1.2135e-01,  9.1961e-03, -9.1844e-02,\n",
      "          8.4970e-02],\n",
      "        [ 2.2979e-01, -2.2619e-01, -2.6475e-01,  1.2693e-01, -2.9494e-01,\n",
      "         -5.3332e-04,  3.1605e-01, -2.3976e-01, -6.2047e-02, -2.0468e-01,\n",
      "          3.5280e-01],\n",
      "        [ 5.5594e-02, -2.8334e-01, -1.0792e-01,  2.5493e-01, -1.0220e-01,\n",
      "         -1.6387e-01,  2.2153e-01, -4.1094e-01, -2.2807e-01, -4.0010e-01,\n",
      "          3.7972e-01],\n",
      "        [ 4.2990e-01, -1.0829e-01, -2.2245e-02,  1.2117e-01, -4.7150e-01,\n",
      "         -3.3136e-01, -4.9513e-02, -3.8733e-01, -2.0725e-01, -1.7856e-01,\n",
      "          2.9268e-01],\n",
      "        [ 2.6855e-01, -1.8738e-01, -1.0741e-02,  4.1230e-02, -2.7936e-01,\n",
      "         -1.1803e-01, -3.3980e-01, -6.8490e-02, -3.9441e-02, -1.0750e-01,\n",
      "          3.5632e-01],\n",
      "        [ 4.2167e-01, -2.1538e-01, -3.4268e-02,  9.6110e-02, -4.3508e-02,\n",
      "         -2.2692e-01,  2.4691e-01, -4.6343e-01,  9.3057e-02, -4.5374e-01,\n",
      "          5.0560e-01],\n",
      "        [ 2.8377e-01, -1.1008e-01,  1.5792e-02,  5.5882e-02,  1.2557e-02,\n",
      "         -3.2861e-01,  2.7583e-01, -5.2696e-01, -9.9847e-02, -5.6837e-01,\n",
      "          3.7059e-01],\n",
      "        [-5.2784e-02,  6.0307e-02,  9.8325e-02,  1.0726e-01, -5.2361e-02,\n",
      "         -4.9663e-01,  4.5460e-02, -3.1545e-01, -2.9703e-01, -4.8162e-01,\n",
      "          2.6522e-01],\n",
      "        [ 2.0849e-01, -3.1621e-02,  1.2052e-01,  2.5234e-01,  1.8007e-01,\n",
      "         -5.4363e-01,  9.8696e-02, -5.4704e-01, -3.8761e-01, -4.4006e-01,\n",
      "          3.7175e-01],\n",
      "        [ 3.8697e-01,  1.2644e-01, -6.7623e-02, -2.5132e-01, -2.6023e-01,\n",
      "         -3.6725e-01, -1.6870e-01, -2.5602e-01,  8.0614e-02,  7.8880e-02,\n",
      "         -2.3394e-01],\n",
      "        [ 4.5363e-01, -2.5677e-01, -3.2497e-01, -3.5359e-01, -3.1752e-01,\n",
      "         -8.9394e-02, -7.8230e-02,  1.9977e-02,  2.2001e-01,  2.9274e-01,\n",
      "         -2.3490e-01],\n",
      "        [ 2.6787e-01, -1.5807e-01, -4.5396e-01, -3.5975e-01, -2.8131e-01,\n",
      "          1.9523e-01,  1.9249e-01,  2.3256e-01, -4.5933e-02,  5.3536e-01,\n",
      "          3.4726e-02],\n",
      "        [ 1.8261e-01, -3.1905e-02, -3.9114e-01, -3.4279e-01, -2.3307e-01,\n",
      "          2.6826e-01,  1.6659e-01,  4.1837e-01, -5.4273e-02,  5.3603e-01,\n",
      "         -1.0007e-01],\n",
      "        [-1.4571e-01,  2.7773e-01, -2.2760e-01, -1.0889e-01, -1.4598e-01,\n",
      "          1.8492e-01, -4.0279e-01,  5.6707e-01, -1.3557e-01,  3.5751e-01,\n",
      "         -2.0404e-02],\n",
      "        [-3.2352e-01,  3.1564e-01, -1.2281e-01,  5.7968e-02, -8.3600e-02,\n",
      "          1.1793e-01, -6.0141e-01,  6.3057e-01, -9.1087e-02,  2.2624e-01,\n",
      "          5.6790e-02],\n",
      "        [-3.8647e-01,  3.3922e-01, -2.4524e-02,  2.2801e-01,  1.7365e-02,\n",
      "          5.8129e-02, -7.9318e-01,  4.6601e-01, -1.6331e-01,  1.3413e-02,\n",
      "         -1.3924e-01],\n",
      "        [-1.6829e-01,  3.2657e-01, -1.5648e-01,  3.5368e-01,  2.0472e-01,\n",
      "         -2.4231e-02, -7.8605e-01,  2.3060e-01,  6.0441e-02, -3.0517e-02,\n",
      "         -4.3894e-01],\n",
      "        [-3.1682e-01, -3.1215e-02, -2.1842e-01,  4.6185e-01,  2.0927e-01,\n",
      "         -1.1950e-01, -9.4670e-01,  3.0732e-01,  3.1610e-01, -2.1737e-01,\n",
      "         -5.2050e-01],\n",
      "        [-1.8875e-01, -2.4672e-01, -2.9896e-01,  4.2018e-01,  5.5554e-02,\n",
      "         -1.3490e-01, -5.5633e-01,  8.8797e-02,  4.8039e-01, -1.9721e-01,\n",
      "         -3.9546e-01],\n",
      "        [ 3.3152e-01, -2.3475e-01,  6.2957e-02,  3.0654e-01,  1.9047e-01,\n",
      "         -2.2908e-02,  1.6737e-01, -2.2861e-01,  1.3983e-01, -3.5263e-01,\n",
      "          1.9722e-01]], grad_fn=<SliceBackward0>) \n",
      " 2: torch.Size([30, 20, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp/ipykernel_6400/4212607459.py:99: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(net.parameters(), 10.0)\n",
      "  0%|                                                                                         | 0/1500 [00:18<?, ?it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp/ipykernel_6400/4212607459.py\", line 113, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp/ipykernel_6400/4212607459.py\", line 101, in main\n",
      "    status = \"epoch: {}; iter: {}; lr: {}; loss_mean: {}; loss: {}\".format(epoch_count, lr_scheduler.last_iter, lr_scheduler.get_lr(), np.mean(loss_mean), loss.item())\n",
      "  File \"<__array_function__ internals>\", line 180, in mean\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 3474, in mean\n",
      "    return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\core\\_methods.py\", line 180, in _mean\n",
      "    if isinstance(ret, mu.ndarray):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\programdata\\miniconda3\\lib\\inspect.py\", line 745, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6400/4212607459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6400/4212607459.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(abc, seq_proj, backend, snapshot, input_size, base_lr, step_size, max_iter, batch_size, output_dir, test_epoch, test_init, gpu)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mloss_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"epoch: {}; iter: {}; lr: {}; loss_mean: {}; loss: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[0miterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3474\u001b[1;33m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[0;32m   3475\u001b[0m                           out=out, **kwargs)\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         ret = um.true_divide(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2076\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2077\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2079\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import click\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from warpctc_pytorch import CTCLoss\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "train_json = json.load(open('../input/train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json.keys()]\n",
    "train_path = ['../input/train/' + x for x in train_json.keys()]\n",
    "\n",
    "val_json = json.load(open('../input/val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json.keys()]\n",
    "val_path = ['../input/val/' + x for x in val_json.keys()]\n",
    "\n",
    "\n",
    "def main(\n",
    "        abc='0123456789', \n",
    "         seq_proj=\"7x30\", \n",
    "         backend=\"resnet18\",\n",
    "         snapshot=None, \n",
    "         input_size=\"200x100\",\n",
    "         base_lr=1e-3,\n",
    "         step_size=1000,\n",
    "         max_iter=10000,\n",
    "         batch_size=20,\n",
    "         output_dir='./',\n",
    "         test_epoch=1,\n",
    "         test_init=None, \n",
    "         gpu='0'):\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "    cuda = True \n",
    "\n",
    "    input_size = [int(x) for x in input_size.split('x')]\n",
    "    transform = Compose([\n",
    "        Rotation(),\n",
    "        Translation(),\n",
    "        # Scale(),\n",
    "        Resize(size=(input_size[0], input_size[1]))\n",
    "    ])\n",
    "    \n",
    "    data = TextDataset(train_path, train_label, transform=transform)\n",
    "    data_val = TextDataset(val_path, val_label, transform=transform)\n",
    "    \n",
    "    seq_proj = [int(x) for x in seq_proj.split('x')]\n",
    "    net = load_model(data.get_abc(), seq_proj, backend, snapshot, cuda)\n",
    "    optimizer = optim.Adam(net.parameters(), lr = base_lr, weight_decay=0.0001)\n",
    "    lr_scheduler = StepLR(optimizer, step_size=step_size, max_iter=max_iter)\n",
    "    loss_function = CTCLoss(zero_infinity = True)\n",
    "\n",
    "    acc_best = 0\n",
    "    epoch_count = 0\n",
    "    while True:\n",
    "        if (test_epoch is not None and epoch_count != 0 and epoch_count % test_epoch == 0) or (test_init and epoch_count == 0):\n",
    "            print(\"Test phase\")\n",
    "            data.set_mode(\"test\")\n",
    "            net = net.eval()\n",
    "            acc, avg_ed = test(net, data_val, data.get_abc(), cuda, 50)\n",
    "            net = net.train()\n",
    "            data.set_mode(\"train\")\n",
    "            if acc > acc_best:\n",
    "                if output_dir is not None:\n",
    "                    torch.save(net.state_dict(), os.path.join(output_dir, \"crnn_\" + backend + \"_\" + str(data.get_abc()) + \"_best\"))\n",
    "                acc_best = acc\n",
    "            print(\"acc: {}\\tacc_best: {}; avg_ed: {}\".format(acc, acc_best, avg_ed))\n",
    "\n",
    "        data_loader = DataLoader(data, batch_size=batch_size,shuffle=True, collate_fn=text_collate)\n",
    "        loss_mean = []\n",
    "        iterator = tqdm(data_loader)\n",
    "        iter_count = 0\n",
    "        for sample in iterator:\n",
    "            # for multi-gpu support\n",
    "            if sample[\"img\"].size(0) % len(gpu.split(',')) != 0:\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            imgs = Variable(sample[\"img\"])\n",
    "            labels = Variable(sample[\"seq\"]).view(-1)\n",
    "            label_lens = Variable(sample[\"seq_len\"].int())\n",
    "            if cuda:\n",
    "                imgs = imgs.cuda()\n",
    "            preds = net(imgs).cpu()\n",
    "            pred_lens = Variable(Tensor([preds.size(0)] * batch_size).int())\n",
    "            \n",
    "            # print(preds.shape, labels.shape)\n",
    "            print('1:',preds[:,0,:],'\\n', '2:',preds.shape)\n",
    "            loss = loss_function(preds, labels, pred_lens, label_lens)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(net.parameters(), 10.0)\n",
    "            loss_mean.append(loss.item())\n",
    "            status = \"epoch: {}; iter: {}; lr: {}; loss_mean: {}; loss: {}\".format(epoch_count, lr_scheduler.last_iter, lr_scheduler.get_lr(), np.mean(loss_mean), loss.item())\n",
    "            iterator.set_description(status)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            iter_count += 1\n",
    "        if output_dir is not None:\n",
    "            torch.save(net.state_dict(), os.path.join(output_dir, \"crnn_\" + backend + \"_\" + str(data.get_abc()) + \"_last\"))\n",
    "        epoch_count += 1\n",
    "\n",
    "    return 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T14:33:15.121745Z",
     "start_time": "2020-06-04T14:33:14.773774Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "test_path = glob.glob('../input/test_a/*')\n",
    "test_label = [[1]] * len(test_path)\n",
    "test_path.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T14:34:21.807169Z",
     "start_time": "2020-06-04T14:34:02.370513Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(net, data, abc, cuda, visualize, batch_size=50):\n",
    "    data_loader = DataLoader(data, batch_size=batch_size,shuffle=False, collate_fn=text_collate)\n",
    "\n",
    "    count = 0\n",
    "    tp = 0\n",
    "    avg_ed = 0\n",
    "    out = []\n",
    "    iterator = tqdm_notebook(data_loader)\n",
    "    for sample in iterator:\n",
    "        imgs = Variable(sample[\"img\"])\n",
    "        if cuda:\n",
    "            imgs = imgs.cuda()\n",
    "        out += net(imgs, decode=True)\n",
    "        # print(out)\n",
    "        # break\n",
    "    return out\n",
    "\n",
    "model = load_model('0123456789', seq_proj=[7, 30], backend='resnet18', snapshot='crnn_resnet18_0123456789_best', cuda=True)\n",
    "\n",
    "transform = Compose([\n",
    "    # Rotation(), \n",
    "    # Translation(),\n",
    "    # Scale(),\n",
    "    Resize(size=(200, 100))\n",
    "    ])\n",
    "test_data = TextDataset(test_path, test_label, transform=transform)\n",
    "\n",
    "model.training = False\n",
    "test_predict = predict(model, test_data, '0123456789', True, False, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T14:43:55.573991Z",
     "start_time": "2020-06-04T14:43:55.422881Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_submit = pd.read_csv('../input/sample_submit_A.csv')\n",
    "df_submit['file_code'] = test_predict\n",
    "df_submit.to_csv('submit.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [],
   "description": "",
   "notebookId": "413126",
   "source": "dsw"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
