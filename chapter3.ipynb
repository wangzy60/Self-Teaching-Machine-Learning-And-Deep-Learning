{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec69bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3256cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine():\n",
    "    '''\n",
    "    一个带有偏置的全链接层，偏置默认是零\n",
    "    '''\n",
    "    def __init__(self,W,b=0):\n",
    "        try:\n",
    "            import numpy as np\n",
    "        except:\n",
    "            print('initialing failed,please install numpy first')\n",
    "            return\n",
    "        self.params = {}\n",
    "        self.params['W'] = W\n",
    "        self.params['b'] = b\n",
    "    def forward(self,X):\n",
    "        return np.dot(X,self.params['W'])+self.params['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a044edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.56  0.3  -0.24  0.29 -0.48  0.3  -0.49]]\n"
     ]
    }
   ],
   "source": [
    "#实现一个简单的word2vec前向推理过程\n",
    "if __name__ == '__main__':\n",
    "    you = [[1,0,0,0,0,0,0]]\n",
    "    hello = [[0,0,1,0,0,0,0]]\n",
    "\n",
    "    W_in = np.random.randn(7,3)\n",
    "    W_out = np.random.randn(3,7)\n",
    "\n",
    "    layer_in = Affine(W_in)\n",
    "    layer_out = Affine(W_out)\n",
    "\n",
    "    predicts = layer_out.forward(0.5*(layer_in.forward(you)+layer_in.forward(hello)))\n",
    "\n",
    "    print(predicts.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53838e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_CBOW_train_data(input_string,window_size=1,out_format = 'one_hot'):\n",
    "    '''\n",
    "    实现将一段输入文本，根据窗口大小，以CBOW模型，转换成包含feat和target两部分的train data\n",
    "    输出的格式可以选择'one-hot'和'id'\n",
    "    string to corpus,corpus to train and target data, train and target data to one_hot\n",
    "    '''\n",
    "    try:\n",
    "        from chapter2 import s2c\n",
    "    except:\n",
    "        print('file addr error,please put current file and chapter2.ipynb in a same file')\n",
    "\n",
    "    corpus = s2c(input_string) #s2c返回一个字典，包含三个字字典，key分别是corpus，word_to_id,id_to_word\n",
    "    word_to_id = corpus['word_to_id']\n",
    "    id_to_word = corpus['id_to_word']\n",
    "    corpus = corpus['corpus']\n",
    "    \n",
    "    corpus_len = len(corpus)\n",
    "    word_to_id_len = len(word_to_id.items())\n",
    "    \n",
    "    if out_format == 'one_hot':\n",
    "        \n",
    "        train_feat = np.zeros((int(corpus_len-2*window_size),int(2*window_size),int(word_to_id_len)))\n",
    "        train_target = np.zeros((int(corpus_len-2*window_size),int(word_to_id_len)))\n",
    "        \n",
    "        for n,data_id in enumerate(corpus):                           #对于每一个语料库中的单词进行循环\n",
    "\n",
    "            if n-window_size >= 0 and n+window_size <= corpus_len-1:  #控制循环不超过语料库的边界\n",
    "\n",
    "                target_data = np.zeros(word_to_id_len)                  #生成train_target数据\n",
    "                target_data[data_id] =1\n",
    "                train_target[n-window_size] = target_data\n",
    "\n",
    "                for distance in range(1,window_size+1):                 #生成目标左边和右边的train_feat，一个train_feat包含多个数据,一个train_feat包含的数据数量是窗口大小的两倍\n",
    "\n",
    "                    left_data_index = n-distance\n",
    "                    right_data_index = n+distance\n",
    "\n",
    "                    left_data_id = corpus[left_data_index]\n",
    "                    right_data_id = corpus[right_data_index]\n",
    "\n",
    "                    left_data = np.zeros(word_to_id_len)\n",
    "                    left_data[left_data_id] = 1\n",
    "\n",
    "                    right_data = np.zeros(word_to_id_len)\n",
    "                    right_data[right_data_id] =1\n",
    "\n",
    "                    train_feat[n-window_size,window_size-distance] = left_data\n",
    "                    train_feat[n-window_size,window_size+distance-1] = right_data\n",
    "\n",
    "        return train_feat,train_target\n",
    "    \n",
    "    if out_format == 'id':\n",
    "        \n",
    "        train_feat = np.zeros((int(corpus_len-2*window_size),int(2*window_size)))\n",
    "        train_target = np.zeros(int(corpus_len-2*window_size))\n",
    "        \n",
    "        for n,data_id in enumerate(corpus):                           #对于每一个语料库中的单词进行循环\n",
    "\n",
    "            if n-window_size >= 0 and n+window_size <= corpus_len-1:  #控制循环不超过语料库的边界\n",
    "\n",
    "                train_target[n-window_size] = int(data_id)            #生成train_target数据\n",
    "\n",
    "                for distance in range(1,window_size+1):                 #生成目标左边和右边的train_feat，一个train_feat包含多个数据,一个train_feat包含的数据数量是窗口大小的两倍\n",
    "\n",
    "                    left_data_index = n-distance\n",
    "                    right_data_index = n+distance\n",
    "\n",
    "                    left_data_id = corpus[left_data_index]\n",
    "                    right_data_id = corpus[right_data_index]\n",
    "\n",
    "                    train_feat[n-window_size,window_size-distance] = left_data_id\n",
    "                    train_feat[n-window_size,window_size+distance-1] = right_data_id\n",
    "        \n",
    "        return train_feat,train_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b553a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feat:\n",
      " [[[1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]]] \n",
      "\n",
      "train_target:\n",
      " [[0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#测试creat_train_data()函数\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_string = 'you say goodbye and i say hello.'\n",
    "    train_feat,train_target = creat_CBOW_train_data(input_string,window_size=2,out_format='one_hot')\n",
    "    print('train_feat:\\n',train_feat,'\\n')\n",
    "    print('train_target:\\n',train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455dc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
