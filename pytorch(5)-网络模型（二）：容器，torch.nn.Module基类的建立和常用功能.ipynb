{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbbf91e",
   "metadata": {},
   "source": [
    "## 容器\n",
    "#### 我们熟悉的各种层在torch.nn中都是以模型的形式存在，如sigmoid层，或者convolutional层，这些我们熟知的层，在torch.nn中都是以一个模型的形式存在，并且它们都是torch.nn.Module()类的子类。\n",
    "#### 在实际创建深度学习模型过程中，我们的模型往往需要组合很多层，组合很多层之后的这个模型，在torch.nn结构内跟前面说的内置sigmoid层等，属于同一个类别，都是torch.nn.Module()类的子类。\n",
    "#### 所以当我们创建一个自己的深度学习模型的时候，同样的也需要去写一个这样的子类，并把需要的层放在这个子类里来组合成一个我们实际需要的模型，这种能把多个层组合到一起来方便使用的东西，就是‘容器’。\n",
    "#### torch.nn.Module()这个类是torch.nn库中容器的一种，简单来说，容器就是用来把多个神经网络层打包组合成一个方便调用的东西，torch.nn.Module()是torch.nn中最重要的一种容器。\n",
    "### torch.nn中分别包含如下几种容器：\n",
    "#### 1) torch.nn.Module类。\n",
    "最大最复杂的容器\n",
    "#### 2) torch.nn.Sequential类\n",
    "以非常简单的步骤生成一个可以训练的模型，输入x之后可以自动对所有内部层进行前向传播，返回预测结果，无需依次对每一层模型调用前向传播。\n",
    "#### 3) torch.nn.ModuleList类\n",
    "以列表的形式储存多个深度学习模型。需要传入一个列表来生成实例，列表的每个元素需要是一个模型。可以对这个列表进行象list一样的增删改查。\n",
    "#### 4) torch.nn.ModuleDict类\n",
    "以有序字典的形式存储多个深度学习模型。需要传入键值对或者OrderedDict对象来生成实例。可以像dict一样对这个字典进行操作。\n",
    "#### 5) torch.nn.ParameterList类\n",
    "以列表的形式保存多个模型参数。原理和可操作范围同上。\n",
    "#### 6) torch.nn.ParameterDict类\n",
    "以字典的形式保存多个模型参数。原理和可操作范围同上。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bb102a",
   "metadata": {},
   "source": [
    "### 1) torch.nn.Module类："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3b24d",
   "metadata": {},
   "source": [
    "#### 1、使用torch.nn.Module类构造我们自己的深度学习模型，需要编写一个继承于torch.nn.Module的子类，而不是直接调用torch.nn.Module类。\n",
    "#### 编写子类的过程中，需要对子类的\\__init__和forward()方法重写，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529972c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SVHN_Model1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #初始化父类的一些属性\n",
    "        #Python 3 和 Python 2 的另一个区别是: \n",
    "        #Python 3 可以使用直接使用 super().xxx 代替 super(Class, self).xxx\n",
    "        super().__init__()\n",
    "        \n",
    "        #先进行2次卷积\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=(3,3),stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,kernel_size=(3,3),stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "        #然后链接6个全连接输出层\n",
    "        self.fc1 = nn.Linear(32*3*7,11)\n",
    "        self.fc2 = nn.Linear(32*3*7,11)\n",
    "        self.fc3 = nn.Linear(32*3*7,11)\n",
    "        self.fc4 = nn.Linear(32*3*7,11)\n",
    "        self.fc5 = nn.Linear(32*3*7,11)\n",
    "        self.fc6 = nn.Linear(32*3*7,11)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        #对self.cnn使用self.cnn(x)会调用nn.Module的_call_impl()函数，\n",
    "        #_call_impl()函数内部主要就是self.forward()方法，\n",
    "        #而nn.Module类本身只有_forward_unimplemented()方法，当调用这个方法时会弹出错误:需要自己定义forward方法后使用\n",
    "        feat = self.cnn(x)\n",
    "        \n",
    "        #view()函数相当于reshape(),-1表示对应位置的维度通过自动计算求得\n",
    "        #这里是把卷积层的结果传给全链接层，卷积层的结果是带有depth的3维数据，而全链接层的数据都是摊平的2维数据\n",
    "        #所以需要先view一下，view后的数据维度除了需要保持batch_size之外，其他维度全部合并到一起。\n",
    "        feat = feat.view(feat.shape[0],-1)\n",
    "        \n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        c6 = self.fc6(feat)\n",
    "        \n",
    "        return c1,c2,c3,c4,c5,c6\n",
    "    \n",
    "svhn_model = SVHN_Model1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf457c",
   "metadata": {},
   "source": [
    "#### 编写子类的时候必须要对__init__()进行重写，并且需要在重写开始位置调用父类(torch.nn.Module)的\\__init__()方法。父类的\\__init__()方法源码如下：    \n",
    "    \n",
    "#### 可以看到torch.nn.Module类的\\__init__构造方法中，对很多属性进行了初始化，所以我们需要调用父类的\\__init__的方法，以免自己初始化这些属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Module:\n",
    "    \n",
    "    training: bool\n",
    "    _parameters: Dict[str, Optional[Parameter]]\n",
    "    _buffers: Dict[str, Optional[Tensor]]\n",
    "    _non_persistent_buffers_set: Set[str]\n",
    "    _backward_hooks: Dict[int, Callable]\n",
    "    _is_full_backward_hook: Optional[bool]\n",
    "    _forward_hooks: Dict[int, Callable]\n",
    "    _forward_pre_hooks: Dict[int, Callable]\n",
    "    _state_dict_hooks: Dict[int, Callable]\n",
    "    _load_state_dict_pre_hooks: Dict[int, Callable]\n",
    "    _load_state_dict_post_hooks: Dict[int, Callable]\n",
    "    _modules: Dict[str, Optional['Module']]\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "            \"\"\"\n",
    "            Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
    "            \"\"\"\n",
    "            torch._C._log_api_usage_once(\"python.nn_module\")\n",
    "\n",
    "            \"\"\"\n",
    "            Calls super().__setattr__('a', a) instead of the typical self.a = a\n",
    "            to avoid Module.__setattr__ overhead. Module's __setattr__ has special\n",
    "            handling for parameters, submodules, and buffers but simply calls into\n",
    "            super().__setattr__ for all other attributes.\n",
    "            \"\"\"\n",
    "            super().__setattr__('training', True)\n",
    "            super().__setattr__('_parameters', OrderedDict())\n",
    "            super().__setattr__('_buffers', OrderedDict())\n",
    "            super().__setattr__('_non_persistent_buffers_set', set())\n",
    "            super().__setattr__('_backward_hooks', OrderedDict())\n",
    "            super().__setattr__('_is_full_backward_hook', None)\n",
    "            super().__setattr__('_forward_hooks', OrderedDict())\n",
    "            super().__setattr__('_forward_pre_hooks', OrderedDict())\n",
    "            super().__setattr__('_state_dict_hooks', OrderedDict())\n",
    "            super().__setattr__('_load_state_dict_pre_hooks', OrderedDict())\n",
    "            super().__setattr__('_load_state_dict_post_hooks', OrderedDict())\n",
    "            super().__setattr__('_modules', OrderedDict())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d3a8f",
   "metadata": {},
   "source": [
    "#### 2、Module类的其他功能\n",
    "\n",
    "##### add & apply:\n",
    "##### 添加模型:add_module(name,Module)\n",
    "##### 对每层应用函数：apply(fn)。将Module里的每一个子模型和Module自身依次作为参数传给自定义的函数\n",
    "\n",
    "##### modules & parameters:\n",
    "##### 以生成器的方式返回树状模型中所有的模型，包含子模型，小的组合模型，以及模型自身：modules()\n",
    "##### 返回模型和子模型的参数：parameters(recurse=True)\n",
    "##### 获取子模型，获取子模型参数：get_submodule(target),get_parameter(target)\n",
    "\n",
    "##### children:\n",
    "##### 返回包含所有子模型的生成器：children()\n",
    "##### 返回直接子模型的名字和模型：named_children()。\n",
    "\n",
    "##### transform:\n",
    "##### 转换：to(device想要转到的设备/dtype想要转换成的数据类型/tensor转换成和给定tensor一样的数据类型和所在设备/memory_format)\n",
    "##### 将所有的模型参数和缓存数据移动到cpu上：cpu()\n",
    "##### 参数数据类型转换，bfloat16(),double(),float(),half(),直接修改模型本身\n",
    "\n",
    "##### reset:\n",
    "##### 清空模型的参数和缓存：to_empty(device)\n",
    "##### 将所有参数的导数重置为0：zero_grad(set_to_none = Fasle)\n",
    "\n",
    "##### other:\n",
    "##### 切换模型到训练或预测状态：eval(),train(bool)\n",
    "##### 控制模型是否进行自动导数：requires_grad_(requires_grad=True)\n",
    "##### 以字典的形式返回模型当前所有的状态：state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4120d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVHN_Model1(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c2583",
   "metadata": {},
   "source": [
    "##### 添加模型:add_module(name,Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ad44dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVHN_Model1(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_model.add_module('fc7',nn.Linear(32*3*7,11))\n",
    "svhn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba165de",
   "metadata": {},
   "source": [
    "##### 对每层应用函数：apply(fn)。将Module里的每一个子模型和Module自身依次作为参数传给自定义的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4a55fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Linear(in_features=672, out_features=11, bias=True)\n",
      "Linear(in_features=672, out_features=11, bias=True)\n",
      "Linear(in_features=672, out_features=11, bias=True)\n",
      "Linear(in_features=672, out_features=11, bias=True)\n",
      "Linear(in_features=672, out_features=11, bias=True)\n",
      "Linear(in_features=672, out_features=11, bias=True)\n",
      "Linear(in_features=672, out_features=11, bias=True)\n",
      "SVHN_Model1(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVHN_Model1(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#常用来初始化各层的参数\n",
    "def f(module):\n",
    "    print(module)\n",
    "\n",
    "svhn_model.apply(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceccb91",
   "metadata": {},
   "source": [
    "##### 返回包含所有子模型的生成器：children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc62d742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个子模型：\n",
      " Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "第1个子模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第2个子模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第3个子模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第4个子模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第5个子模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第6个子模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第7个子模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n"
     ]
    }
   ],
   "source": [
    "chi = svhn_model.children()\n",
    "for i,m in enumerate(chi):\n",
    "    print(f'第{i}个子模型：\\n',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6835ce6",
   "metadata": {},
   "source": [
    "##### 以生成器的方式返回树状模型中所有的模型，包含子模型，小的组合模型，以及模型自身：modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e91aca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个模型：\n",
      " SVHN_Model1(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
      ")\n",
      "第1个模型：\n",
      " Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "第2个模型：\n",
      " Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "第3个模型：\n",
      " ReLU()\n",
      "第4个模型：\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "第5个模型：\n",
      " Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "第6个模型：\n",
      " ReLU()\n",
      "第7个模型：\n",
      " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "第8个模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第9个模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第10个模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第11个模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第12个模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第13个模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n",
      "第14个模型：\n",
      " Linear(in_features=672, out_features=11, bias=True)\n"
     ]
    }
   ],
   "source": [
    "chi2 = svhn_model.modules()\n",
    "\n",
    "for i,m in enumerate(chi2):\n",
    "    print(f'第{i}个模型：\\n',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155040b8",
   "metadata": {},
   "source": [
    "##### 将所有的模型参数和缓存数据移动到cpu上：cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_model.cpu()\n",
    "\n",
    "#将所有模型参数和缓存移动到cuda上：cuda(device)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device)\n",
    "svhn_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78504e13",
   "metadata": {},
   "source": [
    "##### 参数数据类型转换，bfloat16(),double(),float(),half(),直接修改模型本身"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42eed4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVHN_Model1(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_model.bfloat16()\n",
    "svhn_model.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9383c5",
   "metadata": {},
   "source": [
    "##### 切换模型到训练或预测状态：eval(),train(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "198664c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVHN_Model1(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_model.eval()\n",
    "svhn_model.train(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72143fbd",
   "metadata": {},
   "source": [
    "##### 获取子模型，获取子模型参数：get_submodule(target),get_parameter(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "22facab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n"
     ]
    }
   ],
   "source": [
    "#target是字符串，书写格式为'父模型名字.子模型名字.子模型名字'，只能是层的名字\n",
    "#如果target存在，则返回具体的模型或参数，如果不存在或书写错误则报错\n",
    "\n",
    "#返回svhn_model模型下名字为cnn模型的名字为0的参数\n",
    "#svhn_model.get_parameter('fc1')\n",
    "\n",
    "#返回svhn_model模型下名字为cnn模型的名字为0的模型\n",
    "print(svhn_model.get_submodule('cnn.0'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add4a41",
   "metadata": {},
   "source": [
    "#####  返回直接子模型的名字和模型：named_children()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1cf89e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个模型：\n",
      " ('cnn', Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "))\n",
      "第1个模型：\n",
      " ('fc1', Linear(in_features=672, out_features=11, bias=True))\n",
      "第2个模型：\n",
      " ('fc2', Linear(in_features=672, out_features=11, bias=True))\n",
      "第3个模型：\n",
      " ('fc3', Linear(in_features=672, out_features=11, bias=True))\n",
      "第4个模型：\n",
      " ('fc4', Linear(in_features=672, out_features=11, bias=True))\n",
      "第5个模型：\n",
      " ('fc5', Linear(in_features=672, out_features=11, bias=True))\n",
      "第6个模型：\n",
      " ('fc6', Linear(in_features=672, out_features=11, bias=True))\n",
      "第7个模型：\n",
      " ('fc7', Linear(in_features=672, out_features=11, bias=True))\n"
     ]
    }
   ],
   "source": [
    "#注意直接两个字\n",
    "tmp2 = svhn_model.named_children()\n",
    "for i,m in enumerate(tmp2):\n",
    "    print(f'第{i}个模型：\\n',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f980d1e",
   "metadata": {},
   "source": [
    "##### 返回树状模型的所有模型的名字和模型：named_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f4e1111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个模型：\n",
      " ('', SVHN_Model1(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
      "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
      "))\n",
      "第1个模型：\n",
      " ('cnn', Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "))\n",
      "第2个模型：\n",
      " ('cnn.0', Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)))\n",
      "第3个模型：\n",
      " ('cnn.1', ReLU())\n",
      "第4个模型：\n",
      " ('cnn.2', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n",
      "第5个模型：\n",
      " ('cnn.3', Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)))\n",
      "第6个模型：\n",
      " ('cnn.4', ReLU())\n",
      "第7个模型：\n",
      " ('cnn.5', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n",
      "第8个模型：\n",
      " ('fc1', Linear(in_features=672, out_features=11, bias=True))\n",
      "第9个模型：\n",
      " ('fc2', Linear(in_features=672, out_features=11, bias=True))\n",
      "第10个模型：\n",
      " ('fc3', Linear(in_features=672, out_features=11, bias=True))\n",
      "第11个模型：\n",
      " ('fc4', Linear(in_features=672, out_features=11, bias=True))\n",
      "第12个模型：\n",
      " ('fc5', Linear(in_features=672, out_features=11, bias=True))\n",
      "第13个模型：\n",
      " ('fc6', Linear(in_features=672, out_features=11, bias=True))\n",
      "第14个模型：\n",
      " ('fc7', Linear(in_features=672, out_features=11, bias=True))\n"
     ]
    }
   ],
   "source": [
    "tmp3 = svhn_model.named_modules()\n",
    "for i,m in enumerate(tmp3):\n",
    "    print(f'第{i}个模型：\\n',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b242d96e",
   "metadata": {},
   "source": [
    "##### 返回模型和子模型的参数：parameters(recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a8024b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个参数：\n",
      " torch.Size([11, 672])\n",
      "第1个参数：\n",
      " torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "#参数为True,返回树状模型上所有模型的参数\n",
    "#参数为Fasle，只返回直接子模型的参数\n",
    "\n",
    "#返回模型里第二个全连接层的所有参数\n",
    "tmp4 = svhn_model.fc2.parameters(recurse=True)\n",
    "for i,m in enumerate(tmp4):\n",
    "    print(f'第{i}个参数：\\n',m.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20bd03",
   "metadata": {},
   "source": [
    "##### 控制模型是否进行自动导数：requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "76e0d563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVHN_Model1(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc2): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc3): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc4): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc5): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc6): Linear(in_features=672, out_features=11, bias=True)\n",
       "  (fc7): Linear(in_features=672, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d9386",
   "metadata": {},
   "source": [
    "##### 以字典的形式返回模型当前所有的状态：state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d4fe27c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cnn.0.weight', 'cnn.0.bias', 'cnn.3.weight', 'cnn.3.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias', 'fc7.weight', 'fc7.bias'] \n",
      "\n",
      "torch.Size([16])\n",
      "tensor([ 0.0952, -0.0598, -0.1001, -0.1191,  0.1641, -0.1553,  0.0522, -0.0344,\n",
      "        -0.1016,  0.1299,  0.1484,  0.1045,  0.1875,  0.0398,  0.0874, -0.1465],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#也可以用来查看某一个具体参数\n",
    "\n",
    "print(list(svhn_model.state_dict().keys()),'\\n')\n",
    "print(list(svhn_model.state_dict().values())[1].shape)\n",
    "print(list(svhn_model.state_dict().values())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842b9bf",
   "metadata": {},
   "source": [
    "##### 转换：to(device想要转到的设备/dtype想要转换成的数据类型/tensor转换成和给定tensor一样的数据类型和所在设备/memory_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c171158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#转换直接在原数据上修改\n",
    "\n",
    "svhn_model.fc2.weight.to(torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba29ab7",
   "metadata": {},
   "source": [
    "##### 清空模型的参数和缓存：to_empty(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13067491",
   "metadata": {},
   "source": [
    "##### 将所有参数的导数重置为0：zero_grad(set_to_none = Fasle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c56417e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_model.zero_grad(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
