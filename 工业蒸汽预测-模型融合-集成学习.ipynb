{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7123a5b4",
   "metadata": {},
   "source": [
    "## 模型融合\n",
    "#### Boosting方法\n",
    "##### AdaBoost:\n",
    "$$f(x_i) = \\sum _{i=0}^m a_mG_m(x_i) $$\n",
    "二分类模型：损失函数为指数函数，基函数(共有m个)线性相加，通过分布前向算法求解    \n",
    "    \n",
    "其中，$G_m()$为基分类器，$a_m$为每个基函数的权重    \n",
    "    \n",
    "每个基分类器训练使用的数据不同之处在于每个数据的权重在每一轮会进行更新，更新原则是上一轮识别正确的权重这一轮权重降低，上一轮识别错误数据则权重增加，以保证下一个基分类器能重点训练上一次训练错误的数据。\n",
    "     \n",
    "整个训练过程中产生了n组不同权重的训练数据，虽然数据的值从头到晚没有变，但是因为数据的权重发生了改变，同一个数据在整个数据化中所占的比例其实一直在变化，从而导致了不同的基分类器的识别倾向不同，这一点与神经网络类似，不同的基分类器对不同的特征有不同的敏感度，当将这些基分类器组合起来之后，他们对特征就能做出相对好的预测了。    \n",
    "\n",
    "特征树的构建选取：选取当前能达成最小整体损失的那个特征的那个值作为树的划分条件，跟损失函数的选取有较大关系\n",
    "##### GBDT指数分类提升树：\n",
    "$$f(x_i) = \\sum _{i=0}^m T_m(x_i,θ_m) $$\n",
    "二分类模型：相比于AdaBoost的不同点在于，限定了基函数为CART树，且基函数不再带有权重。损失函数仍然为指数函数，线性相加模型，通过分布前向算法求解。θ为CART树的参数    \n",
    "    \n",
    "其中$T_m()$代表整个模型中的一颗CART树。    \n",
    "     \n",
    "与AdaBoost的主要区别在于，没有了数据权重的概念，数据集中各个数据的权重都是相等且不变的，改变的是每个基函数训练时使用的数据基中target的数值，feat的值不变。    \n",
    "    \n",
    "下一个基函数使用的target的值为上一个整体损失函数$（L(y_i,f_m(x_i)）$的导数。\n",
    "\n",
    "特征树的构建选取：比较所有分类情况下的指数函数的总体损失值，选取损失值最小的那一个\n",
    "##### GBDT-MSE回归提升树：\n",
    "$$f(x_i) = \\sum _{i=0}^m T_m(x_i,θ_m) $$\n",
    "与GBDT指数分类提升树基本一样，除了以下几点：    \n",
    "1、损失函数使用MSE    \n",
    "2、每个叶子节点需要有一个输出值$c_R$，当输入数据最终被分到这个叶子节点时，CART树将输出这个$c_R$作为结果，其中R是这颗树中叶子节点的数量，即每个叶子节点都需要有一个$c_R$。$c_R$的值根据损失函数确定，当选择这个$c_R$时，需要达到当前叶子节点的损失最小的效果。根据公式推导，损失函数为MSE时，$c_R$的值取当前叶子节点所有值的算术平均值叶子节点的损失最小。    \n",
    "3、每个CART树使用的训练数据同GBDT指数分类提升树，只不过刚好$（L(y_i,f_m(x_i)）$的导数等于$y_i - y_i ^- $，也就是y的实际值和计算值的差，也叫残差\n",
    "##### GBDT一般损失函数提升树：\n",
    "与GBDT回归和分类树一样，只是当损失函数不再是指数函数和MSE时适用，计算过程更复杂一些\n",
    "##### XGBoost：\n",
    "$$f(x_i) = \\sum _{i=0}^m T_m(x_i,θ_m) +λR+β1/2 \\sum w_R^2$$ \n",
    "与GBDT的使用区别在于：    \n",
    "1、增加了正则项：$λR+β1/2 \\sum w_R^2$，其中λ和β是超参数，R是每个基树叶子节点的个数，$w_R$是每个叶子节点的输出值\n",
    "2、相比于GBDT使用泰勒一阶展开公式拟合误差，XGBoost使用泰勒二阶展开公式拟合误差，准确度更高\n",
    "##### LGB：\n",
    "据说与XGBoost内容和算法基本一样，但是占用电脑资源更少，算起来更快。\n",
    "#### Bagging方法\n",
    "##### 随机森林：\n",
    "假设有m个数据，需要训练n个基分类器。    \n",
    "每轮从数据集中随机抽取m个数据组成一个新的数据集，每抽出一个数据就将数据放回，最终形成n个数据集，其中每个数据集中可能存在多个相同的数据。理论上来说数据集中每次约有30%以上的数据不会加入新数据集中，这部分没有加入当前数据集的数据称为oob(out of bag)数据，可以当做验证数据使用。    \n",
    "每个基分类器训练之前，将从对应的数据集中随机抽取一部分特征进行训练，以增强模型的泛化能力。抽取的特征数量或者比例可以自定。        \n",
    "基分类器也可以是CART树。\n",
    "#### Stacking方法\n",
    "待补充\n",
    "#### Blending方法\n",
    "待补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260a04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6ec8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2876 entries, 0 to 2875\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   NEW_V0   2876 non-null   float64\n",
      " 1   NEW_V1   2876 non-null   float64\n",
      " 2   NEW_V2   2876 non-null   float64\n",
      " 3   NEW_V3   2876 non-null   float64\n",
      " 4   NEW_V4   2876 non-null   float64\n",
      " 5   NEW_V5   2876 non-null   float64\n",
      " 6   NEW_V6   2876 non-null   float64\n",
      " 7   NEW_V7   2876 non-null   float64\n",
      " 8   NEW_V8   2876 non-null   float64\n",
      " 9   NEW_V9   2876 non-null   float64\n",
      " 10  NEW_V10  2876 non-null   float64\n",
      " 11  NEW_V11  2876 non-null   float64\n",
      " 12  NEW_V12  2876 non-null   float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 292.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.175\n",
       "1       0.676\n",
       "2       0.633\n",
       "3       0.206\n",
       "4       0.384\n",
       "        ...  \n",
       "2871    0.235\n",
       "2872    1.042\n",
       "2873    0.005\n",
       "2874    0.350\n",
       "2875    0.417\n",
       "Name: target, Length: 2876, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('zhengqi_train_change_feat.txt',sep='\\t')\n",
    "test_data = pd.read_csv('zhengqi_test_change_feat.txt',sep='\\t')\n",
    "train_target= train_data['target']\n",
    "train_feat = train_data.drop('target',axis=1)\n",
    "train_feat.info()\n",
    "train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "201296b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gds(model_name,model_params):\n",
    "    \n",
    "    gdsearch = GridSearchCV(model_name,model_params,cv=6,\n",
    "                            scoring='neg_mean_squared_error',\n",
    "                           verbose=1,return_train_score=True)\n",
    "    gdsearch.fit(train_feat,train_target)\n",
    "    model=gdsearch.best_estimator_\n",
    "    best_index= gdsearch.best_index_\n",
    "    best_score= gdsearch.best_score_\n",
    "    best_params = gdsearch.best_params_\n",
    "    grid_result = pd.DataFrame(gdsearch.cv_results_)\n",
    "    cv_mean = abs(grid_result.loc[best_index,'mean_test_score'])\n",
    "    cv_std = grid_result.loc[best_index,'std_test_score']\n",
    "\n",
    "    print('best_index:',best_index)\n",
    "    print('best_score:',best_score)\n",
    "    print('best params:',best_params)\n",
    "    print('grid_result:',grid_result)\n",
    "    print('cv_mean:',cv_mean)\n",
    "    print('cv_std:',cv_std)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70911f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 125 candidates, totalling 750 fits\n",
      "best_index: 31\n",
      "best_score: -0.1505143313001109\n",
      "best params: {'max_depth': 2, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "grid_result:      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.445803      0.021724         0.002166        0.000894   \n",
      "1         0.571312      0.001658         0.002161        0.000372   \n",
      "2         0.718248      0.007648         0.001991        0.000009   \n",
      "3         0.864856      0.010480         0.001662        0.000471   \n",
      "4         1.008305      0.020577         0.001995        0.000576   \n",
      "..             ...           ...              ...             ...   \n",
      "120       2.237203      0.044647         0.004146        0.001074   \n",
      "121       2.955857      0.062506         0.003664        0.000468   \n",
      "122       3.633626      0.096389         0.003823        0.000896   \n",
      "123       4.388535      0.035715         0.006815        0.004542   \n",
      "124       5.104832      0.121315         0.004830        0.000694   \n",
      "\n",
      "    param_max_depth param_min_samples_split param_n_estimators  \\\n",
      "0                 1                       3                150   \n",
      "1                 1                       3                200   \n",
      "2                 1                       3                250   \n",
      "3                 1                       3                300   \n",
      "4                 1                       3                350   \n",
      "..              ...                     ...                ...   \n",
      "120               5                       7                150   \n",
      "121               5                       7                200   \n",
      "122               5                       7                250   \n",
      "123               5                       7                300   \n",
      "124               5                       7                350   \n",
      "\n",
      "                                                params  split0_test_score  \\\n",
      "0    {'max_depth': 1, 'min_samples_split': 3, 'n_es...          -0.125757   \n",
      "1    {'max_depth': 1, 'min_samples_split': 3, 'n_es...          -0.119485   \n",
      "2    {'max_depth': 1, 'min_samples_split': 3, 'n_es...          -0.117109   \n",
      "3    {'max_depth': 1, 'min_samples_split': 3, 'n_es...          -0.114534   \n",
      "4    {'max_depth': 1, 'min_samples_split': 3, 'n_es...          -0.112830   \n",
      "..                                                 ...                ...   \n",
      "120  {'max_depth': 5, 'min_samples_split': 7, 'n_es...          -0.126912   \n",
      "121  {'max_depth': 5, 'min_samples_split': 7, 'n_es...          -0.129200   \n",
      "122  {'max_depth': 5, 'min_samples_split': 7, 'n_es...          -0.131411   \n",
      "123  {'max_depth': 5, 'min_samples_split': 7, 'n_es...          -0.132439   \n",
      "124  {'max_depth': 5, 'min_samples_split': 7, 'n_es...          -0.132060   \n",
      "\n",
      "     split1_test_score  ...  std_test_score  rank_test_score  \\\n",
      "0            -0.159727  ...        0.030517              121   \n",
      "1            -0.152731  ...        0.030731              106   \n",
      "2            -0.150809  ...        0.030032               66   \n",
      "3            -0.149632  ...        0.029731               46   \n",
      "4            -0.148432  ...        0.029970               34   \n",
      "..                 ...  ...             ...              ...   \n",
      "120          -0.142127  ...        0.025930               44   \n",
      "121          -0.142199  ...        0.024885               64   \n",
      "122          -0.143098  ...        0.024420               85   \n",
      "123          -0.143417  ...        0.024875              100   \n",
      "124          -0.143008  ...        0.024890              102   \n",
      "\n",
      "     split0_train_score  split1_train_score  split2_train_score  \\\n",
      "0             -0.140336           -0.134584           -0.135745   \n",
      "1             -0.131155           -0.125034           -0.126616   \n",
      "2             -0.125704           -0.119042           -0.120642   \n",
      "3             -0.121898           -0.114889           -0.116407   \n",
      "4             -0.119039           -0.111831           -0.113275   \n",
      "..                  ...                 ...                 ...   \n",
      "120           -0.029450           -0.028984           -0.027896   \n",
      "121           -0.021678           -0.021768           -0.020742   \n",
      "122           -0.016099           -0.015765           -0.014985   \n",
      "123           -0.012037           -0.011843           -0.011014   \n",
      "124           -0.008646           -0.008754           -0.008213   \n",
      "\n",
      "     split3_train_score  split4_train_score  split5_train_score  \\\n",
      "0             -0.133687           -0.136470           -0.123166   \n",
      "1             -0.124864           -0.127024           -0.114549   \n",
      "2             -0.119495           -0.120973           -0.109162   \n",
      "3             -0.115817           -0.116765           -0.105415   \n",
      "4             -0.113090           -0.113685           -0.102654   \n",
      "..                  ...                 ...                 ...   \n",
      "120           -0.026988           -0.028384           -0.028524   \n",
      "121           -0.020171           -0.021521           -0.022069   \n",
      "122           -0.014478           -0.016138           -0.016374   \n",
      "123           -0.010680           -0.011947           -0.011956   \n",
      "124           -0.007809           -0.008770           -0.008780   \n",
      "\n",
      "     mean_train_score  std_train_score  \n",
      "0           -0.133998         0.005278  \n",
      "1           -0.124874         0.005062  \n",
      "2           -0.119170         0.004973  \n",
      "3           -0.115198         0.004916  \n",
      "4           -0.112262         0.004868  \n",
      "..                ...              ...  \n",
      "120         -0.028371         0.000786  \n",
      "121         -0.021325         0.000657  \n",
      "122         -0.015640         0.000682  \n",
      "123         -0.011580         0.000530  \n",
      "124         -0.008495         0.000364  \n",
      "\n",
      "[125 rows x 25 columns]\n",
      "cv_mean: 0.1505143313001109\n",
      "cv_std: 0.02869695389580395\n"
     ]
    }
   ],
   "source": [
    "#GBDT模型\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbdt_params={'max_depth':[1,2,3,4,5],\n",
    "             'min_samples_split':[3,4,5,6,7],\n",
    "             'n_estimators':[150,200,250,300,350]}\n",
    "gbdt_model = GradientBoostingRegressor()\n",
    "\n",
    "gbdt_model = gds(gbdt_model,gbdt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dc1384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 625 candidates, totalling 3750 fits\n",
      "best_index: 585\n",
      "best_score: -0.17766892636766707\n",
      "best params: {'max_depth': 5, 'max_features': 0.9, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "grid_result:      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0         0.269815      0.010946         0.010808        0.001065   \n",
      "1         0.343411      0.000933         0.013967        0.000576   \n",
      "2         0.438987      0.020215         0.017459        0.000954   \n",
      "3         0.535227      0.034148         0.022939        0.005400   \n",
      "4         0.669044      0.025368         0.027770        0.004046   \n",
      "..             ...           ...              ...             ...   \n",
      "620       1.109535      0.024345         0.012634        0.000470   \n",
      "621       1.487519      0.028450         0.016457        0.000509   \n",
      "622       1.897430      0.041188         0.020278        0.000742   \n",
      "623       2.314658      0.142965         0.025596        0.002420   \n",
      "624       2.537722      0.011668         0.028262        0.000467   \n",
      "\n",
      "    param_max_depth param_max_features param_min_samples_split  \\\n",
      "0                 1                0.6                       3   \n",
      "1                 1                0.6                       3   \n",
      "2                 1                0.6                       3   \n",
      "3                 1                0.6                       3   \n",
      "4                 1                0.6                       3   \n",
      "..              ...                ...                     ...   \n",
      "620               5               0.99                       7   \n",
      "621               5               0.99                       7   \n",
      "622               5               0.99                       7   \n",
      "623               5               0.99                       7   \n",
      "624               5               0.99                       7   \n",
      "\n",
      "    param_n_estimators                                             params  \\\n",
      "0                  150  {'max_depth': 1, 'max_features': 0.6, 'min_sam...   \n",
      "1                  200  {'max_depth': 1, 'max_features': 0.6, 'min_sam...   \n",
      "2                  250  {'max_depth': 1, 'max_features': 0.6, 'min_sam...   \n",
      "3                  300  {'max_depth': 1, 'max_features': 0.6, 'min_sam...   \n",
      "4                  350  {'max_depth': 1, 'max_features': 0.6, 'min_sam...   \n",
      "..                 ...                                                ...   \n",
      "620                150  {'max_depth': 5, 'max_features': 0.99, 'min_sa...   \n",
      "621                200  {'max_depth': 5, 'max_features': 0.99, 'min_sa...   \n",
      "622                250  {'max_depth': 5, 'max_features': 0.99, 'min_sa...   \n",
      "623                300  {'max_depth': 5, 'max_features': 0.99, 'min_sa...   \n",
      "624                350  {'max_depth': 5, 'max_features': 0.99, 'min_sa...   \n",
      "\n",
      "     split0_test_score  ...  std_test_score  rank_test_score  \\\n",
      "0            -0.469692  ...        0.106059              620   \n",
      "1            -0.463287  ...        0.114285              604   \n",
      "2            -0.458348  ...        0.108045              601   \n",
      "3            -0.473141  ...        0.106970              613   \n",
      "4            -0.459700  ...        0.116540              622   \n",
      "..                 ...  ...             ...              ...   \n",
      "620          -0.134186  ...        0.034259               96   \n",
      "621          -0.135481  ...        0.032799               67   \n",
      "622          -0.133514  ...        0.033891               73   \n",
      "623          -0.133080  ...        0.033587               45   \n",
      "624          -0.132755  ...        0.033899               76   \n",
      "\n",
      "     split0_train_score  split1_train_score  split2_train_score  \\\n",
      "0             -0.529326           -0.485353           -0.498477   \n",
      "1             -0.517138           -0.497341           -0.487490   \n",
      "2             -0.515380           -0.488332           -0.477920   \n",
      "3             -0.526859           -0.506759           -0.482968   \n",
      "4             -0.516113           -0.508511           -0.493777   \n",
      "..                  ...                 ...                 ...   \n",
      "620           -0.137831           -0.132104           -0.129485   \n",
      "621           -0.136787           -0.131221           -0.129105   \n",
      "622           -0.136547           -0.131996           -0.129197   \n",
      "623           -0.136625           -0.131282           -0.129251   \n",
      "624           -0.136418           -0.132656           -0.129025   \n",
      "\n",
      "     split3_train_score  split4_train_score  split5_train_score  \\\n",
      "0             -0.489030           -0.539122           -0.495063   \n",
      "1             -0.484249           -0.512682           -0.477705   \n",
      "2             -0.471986           -0.510653           -0.494075   \n",
      "3             -0.479082           -0.529422           -0.495642   \n",
      "4             -0.502542           -0.518411           -0.492172   \n",
      "..                  ...                 ...                 ...   \n",
      "620           -0.129383           -0.129991           -0.119695   \n",
      "621           -0.129334           -0.129887           -0.118991   \n",
      "622           -0.129368           -0.129747           -0.118802   \n",
      "623           -0.129869           -0.129494           -0.119424   \n",
      "624           -0.129219           -0.130166           -0.119478   \n",
      "\n",
      "     mean_train_score  std_train_score  \n",
      "0           -0.506062         0.020541  \n",
      "1           -0.496101         0.014561  \n",
      "2           -0.493058         0.015835  \n",
      "3           -0.503455         0.019612  \n",
      "4           -0.505254         0.010098  \n",
      "..                ...              ...  \n",
      "620         -0.129748         0.005357  \n",
      "621         -0.129221         0.005266  \n",
      "622         -0.129276         0.005326  \n",
      "623         -0.129324         0.005090  \n",
      "624         -0.129494         0.005148  \n",
      "\n",
      "[625 rows x 26 columns]\n",
      "cv_mean: 0.17766892636766707\n",
      "cv_std: 0.034247936685286834\n"
     ]
    }
   ],
   "source": [
    "#RF模型\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_params={'max_depth':[1,2,3,4,5],\n",
    "           'min_samples_split':[3,4,5,6,7],\n",
    "           'n_estimators':[150,200,250,300,350],\n",
    "           'max_features':[0.6,0.7,0.8,0.9,0.99]}\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "rf_model = gds(rf_model,rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8611ad1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 3125 candidates, totalling 18750 fits\n",
      "best_index: 826\n",
      "best_score: -0.14753302374269328\n",
      "best params: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 300, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "grid_result:       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0          0.113885      0.077147         0.002992    2.892856e-07   \n",
      "1          0.080452      0.001487         0.002992    5.757255e-04   \n",
      "2          0.080618      0.001064         0.002992    3.203653e-07   \n",
      "3          0.082446      0.003341         0.002992    2.282684e-07   \n",
      "4          0.080119      0.000470         0.002992    1.638375e-07   \n",
      "...             ...           ...              ...             ...   \n",
      "3120       0.656246      0.005182         0.003325    4.699374e-04   \n",
      "3121       0.656246      0.002230         0.003491    4.986525e-04   \n",
      "3122       0.655415      0.003706         0.003491    4.985333e-04   \n",
      "3123       0.657077      0.002960         0.003491    4.985730e-04   \n",
      "3124       0.655581      0.002554         0.003657    4.698531e-04   \n",
      "\n",
      "     param_learning_rate param_max_depth param_n_estimators param_reg_alpha  \\\n",
      "0                      1               1                150               1   \n",
      "1                      1               1                150               1   \n",
      "2                      1               1                150               1   \n",
      "3                      1               1                150               1   \n",
      "4                      1               1                150               1   \n",
      "...                  ...             ...                ...             ...   \n",
      "3120              0.0001               5                350          0.0001   \n",
      "3121              0.0001               5                350          0.0001   \n",
      "3122              0.0001               5                350          0.0001   \n",
      "3123              0.0001               5                350          0.0001   \n",
      "3124              0.0001               5                350          0.0001   \n",
      "\n",
      "     param_reg_lambda                                             params  ...  \\\n",
      "0                   1  {'learning_rate': 1, 'max_depth': 1, 'n_estima...  ...   \n",
      "1                 0.1  {'learning_rate': 1, 'max_depth': 1, 'n_estima...  ...   \n",
      "2                0.01  {'learning_rate': 1, 'max_depth': 1, 'n_estima...  ...   \n",
      "3               0.001  {'learning_rate': 1, 'max_depth': 1, 'n_estima...  ...   \n",
      "4              0.0001  {'learning_rate': 1, 'max_depth': 1, 'n_estima...  ...   \n",
      "...               ...                                                ...  ...   \n",
      "3120                1  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...  ...   \n",
      "3121              0.1  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...  ...   \n",
      "3122             0.01  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...  ...   \n",
      "3123            0.001  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...  ...   \n",
      "3124           0.0001  {'learning_rate': 0.0001, 'max_depth': 5, 'n_e...  ...   \n",
      "\n",
      "      std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0           0.026957              670           -0.113180           -0.106212   \n",
      "1           0.028142              681           -0.112906           -0.105343   \n",
      "2           0.030615              719           -0.112874           -0.105480   \n",
      "3           0.030026              693           -0.112799           -0.106369   \n",
      "4           0.030026              694           -0.112798           -0.106369   \n",
      "...              ...              ...                 ...                 ...   \n",
      "3120        0.241856             2538           -1.048324           -1.068525   \n",
      "3121        0.239850             2513           -1.047176           -1.067302   \n",
      "3122        0.239611             2507           -1.047007           -1.067106   \n",
      "3123        0.239604             2501           -1.046989           -1.067086   \n",
      "3124        0.239606             2503           -1.046987           -1.067084   \n",
      "\n",
      "      split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0              -0.106313           -0.107421           -0.106857   \n",
      "1              -0.105730           -0.107033           -0.106274   \n",
      "2              -0.105650           -0.106793           -0.106315   \n",
      "3              -0.105648           -0.106776           -0.106310   \n",
      "4              -0.105648           -0.106776           -0.106309   \n",
      "...                  ...                 ...                 ...   \n",
      "3120           -1.047850           -0.921011           -1.036385   \n",
      "3121           -1.046657           -0.919854           -1.035199   \n",
      "3122           -1.046486           -0.919700           -1.035034   \n",
      "3123           -1.046469           -0.919684           -1.035017   \n",
      "3124           -1.046468           -0.919682           -1.035016   \n",
      "\n",
      "      split5_train_score  mean_train_score  std_train_score  \n",
      "0              -0.098349         -0.106389         0.004322  \n",
      "1              -0.097952         -0.105873         0.004359  \n",
      "2              -0.097910         -0.105837         0.004353  \n",
      "3              -0.097863         -0.105961         0.004347  \n",
      "4              -0.097863         -0.105961         0.004347  \n",
      "...                  ...               ...              ...  \n",
      "3120           -1.007476         -1.021595         0.048548  \n",
      "3121           -1.006150         -1.020390         0.048542  \n",
      "3122           -1.005992         -1.020221         0.048532  \n",
      "3123           -1.005975         -1.020203         0.048531  \n",
      "3124           -1.005973         -1.020202         0.048531  \n",
      "\n",
      "[3125 rows x 27 columns]\n",
      "cv_mean: 0.14753302374269328\n",
      "cv_std: 0.027586588829595925\n"
     ]
    }
   ],
   "source": [
    "#XGBoost模型\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params={'max_depth':[1,2,3,4,5],\n",
    "           'reg_alpha':[1,0.1,0.01,0.001,0.0001],\n",
    "           'reg_lambda':[1,0.1,0.01,0.001,0.0001],\n",
    "           'n_estimators':[150,200,250,300,350],\n",
    "           'learning_rate':[1,0.1,0.01,0.001,0.0001]}\n",
    "\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "xgb_model = gds(xgb_model,xgb_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
