{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d16301d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#阈值处理\" data-toc-modified-id=\"阈值处理-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>阈值处理</a></span><ul class=\"toc-item\"><li><span><a href=\"#二值化阈值处理，cv2.threshold（）\" data-toc-modified-id=\"二值化阈值处理，cv2.threshold（）-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>二值化阈值处理，cv2.threshold（）</a></span></li><li><span><a href=\"#非二值化阈值处理，cv2.threshold（）\" data-toc-modified-id=\"非二值化阈值处理，cv2.threshold（）-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>非二值化阈值处理，cv2.threshold（）</a></span><ul class=\"toc-item\"><li><span><a href=\"#cv2.THRESH_TRUNC模式，将大于阈值的像素值都改成阈值,注意函数返回值有两个\" data-toc-modified-id=\"cv2.THRESH_TRUNC模式，将大于阈值的像素值都改成阈值,注意函数返回值有两个-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>cv2.THRESH_TRUNC模式，将大于阈值的像素值都改成阈值,注意函数返回值有两个</a></span></li><li><span><a href=\"#cv2.THERSH_TOZERO模式，将小于阈值的像素值变成0，大于阈值的不变\" data-toc-modified-id=\"cv2.THERSH_TOZERO模式，将小于阈值的像素值变成0，大于阈值的不变-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>cv2.THERSH_TOZERO模式，将小于阈值的像素值变成0，大于阈值的不变</a></span></li><li><span><a href=\"#cv2.THERSH_TOZERO_INV模式，将超过阈值的像素值变为0，小于阈值的不变\" data-toc-modified-id=\"cv2.THERSH_TOZERO_INV模式，将超过阈值的像素值变为0，小于阈值的不变-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>cv2.THERSH_TOZERO_INV模式，将超过阈值的像素值变为0，小于阈值的不变</a></span></li><li><span><a href=\"#自适应局部阈值处理，cv2.adaptiveThreshold()\" data-toc-modified-id=\"自适应局部阈值处理，cv2.adaptiveThreshold()-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>自适应局部阈值处理，cv2.adaptiveThreshold()</a></span></li><li><span><a href=\"#自动计算全局阈值模式，cv2.THRESH_OTSU\" data-toc-modified-id=\"自动计算全局阈值模式，cv2.THRESH_OTSU-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>自动计算全局阈值模式，cv2.THRESH_OTSU</a></span></li></ul></li></ul></li><li><span><a href=\"#图像模糊/平滑/去噪\" data-toc-modified-id=\"图像模糊/平滑/去噪-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>图像模糊/平滑/去噪</a></span><ul class=\"toc-item\"><li><span><a href=\"#均值滤波，cv2.blur（）\" data-toc-modified-id=\"均值滤波，cv2.blur（）-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>均值滤波，cv2.blur（）</a></span></li><li><span><a href=\"#方框滤波，cv2.boxFilter（）\" data-toc-modified-id=\"方框滤波，cv2.boxFilter（）-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>方框滤波，cv2.boxFilter（）</a></span></li><li><span><a href=\"#高斯滤波，cv2.GaussianBlur（）\" data-toc-modified-id=\"高斯滤波，cv2.GaussianBlur（）-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>高斯滤波，cv2.GaussianBlur（）</a></span></li><li><span><a href=\"#中值滤波，cv2.medianBlur（）\" data-toc-modified-id=\"中值滤波，cv2.medianBlur（）-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>中值滤波，cv2.medianBlur（）</a></span></li><li><span><a href=\"#双边滤波，cv2.bilateralFilter（）\" data-toc-modified-id=\"双边滤波，cv2.bilateralFilter（）-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>双边滤波，cv2.bilateralFilter（）</a></span></li></ul></li><li><span><a href=\"#形态学操作\" data-toc-modified-id=\"形态学操作-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>形态学操作</a></span><ul class=\"toc-item\"><li><span><a href=\"#腐蚀与膨胀（背景扩大和前景扩大）\" data-toc-modified-id=\"腐蚀与膨胀（背景扩大和前景扩大）-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>腐蚀与膨胀（背景扩大和前景扩大）</a></span><ul class=\"toc-item\"><li><span><a href=\"#腐蚀，cv2.erode（）\" data-toc-modified-id=\"腐蚀，cv2.erode（）-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>腐蚀，cv2.erode（）</a></span></li><li><span><a href=\"#膨胀，cv2.dilate（）\" data-toc-modified-id=\"膨胀，cv2.dilate（）-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>膨胀，cv2.dilate（）</a></span></li></ul></li><li><span><a href=\"#腐蚀与膨胀的组合操作，cv2.morphologyEx()\" data-toc-modified-id=\"腐蚀与膨胀的组合操作，cv2.morphologyEx()-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>腐蚀与膨胀的组合操作，cv2.morphologyEx()</a></span><ul class=\"toc-item\"><li><span><a href=\"#开运算，cv2.MORPH_OPEN\" data-toc-modified-id=\"开运算，cv2.MORPH_OPEN-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>开运算，cv2.MORPH_OPEN</a></span></li><li><span><a href=\"#闭运算，cv2.MORPH_CLOSE\" data-toc-modified-id=\"闭运算，cv2.MORPH_CLOSE-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>闭运算，cv2.MORPH_CLOSE</a></span></li><li><span><a href=\"#梯度运算，cv2.MORPH_GRADIENT\" data-toc-modified-id=\"梯度运算，cv2.MORPH_GRADIENT-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>梯度运算，cv2.MORPH_GRADIENT</a></span></li><li><span><a href=\"#顶帽运算，cv2.MORPH_TOPHAT\" data-toc-modified-id=\"顶帽运算，cv2.MORPH_TOPHAT-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>顶帽运算，cv2.MORPH_TOPHAT</a></span></li><li><span><a href=\"#黑帽运算，cv2.MORPH_BLACKHAT\" data-toc-modified-id=\"黑帽运算，cv2.MORPH_BLACKHAT-3.2.5\"><span class=\"toc-item-num\">3.2.5&nbsp;&nbsp;</span>黑帽运算，cv2.MORPH_BLACKHAT</a></span></li><li><span><a href=\"#自定义核函数\" data-toc-modified-id=\"自定义核函数-3.2.6\"><span class=\"toc-item-num\">3.2.6&nbsp;&nbsp;</span>自定义核函数</a></span></li></ul></li></ul></li><li><span><a href=\"#图像边缘（图像梯度）\" data-toc-modified-id=\"图像边缘（图像梯度）-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>图像边缘（图像梯度）</a></span><ul class=\"toc-item\"><li><span><a href=\"#基于sobel算子的边缘检测，cv2.Sobel（）\" data-toc-modified-id=\"基于sobel算子的边缘检测，cv2.Sobel（）-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>基于sobel算子的边缘检测，cv2.Sobel（）</a></span></li><li><span><a href=\"#基于scharr算子的边缘检测，cv2.Scharr（）\" data-toc-modified-id=\"基于scharr算子的边缘检测，cv2.Scharr（）-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>基于scharr算子的边缘检测，cv2.Scharr（）</a></span></li><li><span><a href=\"#基于laplacian算子的边缘检测，cv2.Laplacian（）\" data-toc-modified-id=\"基于laplacian算子的边缘检测，cv2.Laplacian（）-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>基于laplacian算子的边缘检测，cv2.Laplacian（）</a></span></li><li><span><a href=\"#Canny边缘检测，cv2.Canny（）\" data-toc-modified-id=\"Canny边缘检测，cv2.Canny（）-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Canny边缘检测，cv2.Canny（）</a></span></li></ul></li><li><span><a href=\"#图像的上采样与下采样\" data-toc-modified-id=\"图像的上采样与下采样-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>图像的上采样与下采样</a></span><ul class=\"toc-item\"><li><span><a href=\"#图像的下采样，cv2.pyrDown（）\" data-toc-modified-id=\"图像的下采样，cv2.pyrDown（）-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>图像的下采样，cv2.pyrDown（）</a></span></li><li><span><a href=\"#图像的上采样，cv2.pyrDown（）\" data-toc-modified-id=\"图像的上采样，cv2.pyrDown（）-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>图像的上采样，cv2.pyrDown（）</a></span></li><li><span><a href=\"#图像的上下采样可逆化实现：拉普拉斯金字塔\" data-toc-modified-id=\"图像的上下采样可逆化实现：拉普拉斯金字塔-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>图像的上下采样可逆化实现：拉普拉斯金字塔</a></span></li></ul></li><li><span><a href=\"#图像轮廓检测\" data-toc-modified-id=\"图像轮廓检测-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>图像轮廓检测</a></span><ul class=\"toc-item\"><li><span><a href=\"#查找、绘制轮廓\" data-toc-modified-id=\"查找、绘制轮廓-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>查找、绘制轮廓</a></span><ul class=\"toc-item\"><li><span><a href=\"#查找轮廓，cv2.morphologyEx（）\" data-toc-modified-id=\"查找轮廓，cv2.morphologyEx（）-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>查找轮廓，cv2.morphologyEx（）</a></span></li><li><span><a href=\"#绘制轮廓，cv2.findContours（）\" data-toc-modified-id=\"绘制轮廓，cv2.findContours（）-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>绘制轮廓，cv2.findContours（）</a></span></li></ul></li><li><span><a href=\"#轮廓的特征\" data-toc-modified-id=\"轮廓的特征-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>轮廓的特征</a></span><ul class=\"toc-item\"><li><span><a href=\"#轮廓的面积，cv2.contourArea（）\" data-toc-modified-id=\"轮廓的面积，cv2.contourArea（）-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>轮廓的面积，cv2.contourArea（）</a></span></li><li><span><a href=\"#轮廓的周长，cv2.arcLength（）\" data-toc-modified-id=\"轮廓的周长，cv2.arcLength（）-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>轮廓的周长，cv2.arcLength（）</a></span></li></ul></li><li><span><a href=\"#轮廓的矩\" data-toc-modified-id=\"轮廓的矩-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>轮廓的矩</a></span><ul class=\"toc-item\"><li><span><a href=\"#矩的意义和求法，cv2.moments（）\" data-toc-modified-id=\"矩的意义和求法，cv2.moments（）-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>矩的意义和求法，cv2.moments（）</a></span></li><li><span><a href=\"#Hu矩，cv2.HuMoments()\" data-toc-modified-id=\"Hu矩，cv2.HuMoments()-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;</span>Hu矩，cv2.HuMoments()</a></span></li></ul></li><li><span><a href=\"#轮廓的拟合\" data-toc-modified-id=\"轮廓的拟合-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>轮廓的拟合</a></span><ul class=\"toc-item\"><li><span><a href=\"#矩形拟合\" data-toc-modified-id=\"矩形拟合-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>矩形拟合</a></span></li><li><span><a href=\"#最小矩形拟合，cv2.minAreaRect（）\" data-toc-modified-id=\"最小矩形拟合，cv2.minAreaRect（）-6.4.2\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>最小矩形拟合，cv2.minAreaRect（）</a></span></li><li><span><a href=\"#最小圆形拟合，cv2.minEnclosingCircle（）\" data-toc-modified-id=\"最小圆形拟合，cv2.minEnclosingCircle（）-6.4.3\"><span class=\"toc-item-num\">6.4.3&nbsp;&nbsp;</span>最小圆形拟合，cv2.minEnclosingCircle（）</a></span></li><li><span><a href=\"#最优椭圆拟合，cv2.fitEllipse（）\" data-toc-modified-id=\"最优椭圆拟合，cv2.fitEllipse（）-6.4.4\"><span class=\"toc-item-num\">6.4.4&nbsp;&nbsp;</span>最优椭圆拟合，cv2.fitEllipse（）</a></span></li><li><span><a href=\"#最优直线拟合\" data-toc-modified-id=\"最优直线拟合-6.4.5\"><span class=\"toc-item-num\">6.4.5&nbsp;&nbsp;</span>最优直线拟合</a></span></li><li><span><a href=\"#最小外包三角形拟合\" data-toc-modified-id=\"最小外包三角形拟合-6.4.6\"><span class=\"toc-item-num\">6.4.6&nbsp;&nbsp;</span>最小外包三角形拟合</a></span></li><li><span><a href=\"#逼近的多边形拟合，cv2.approxPolyDP（）\" data-toc-modified-id=\"逼近的多边形拟合，cv2.approxPolyDP（）-6.4.7\"><span class=\"toc-item-num\">6.4.7&nbsp;&nbsp;</span>逼近的多边形拟合，cv2.approxPolyDP（）</a></span></li></ul></li><li><span><a href=\"#凸包\" data-toc-modified-id=\"凸包-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>凸包</a></span><ul class=\"toc-item\"><li><span><a href=\"#寻找绘制凸包，cv2.convexHull（），cv2.polylines（）\" data-toc-modified-id=\"寻找绘制凸包，cv2.convexHull（），cv2.polylines（）-6.5.1\"><span class=\"toc-item-num\">6.5.1&nbsp;&nbsp;</span>寻找绘制凸包，cv2.convexHull（），cv2.polylines（）</a></span></li><li><span><a href=\"#凸缺陷，cv2.convexityDefects（）\" data-toc-modified-id=\"凸缺陷，cv2.convexityDefects（）-6.5.2\"><span class=\"toc-item-num\">6.5.2&nbsp;&nbsp;</span>凸缺陷，cv2.convexityDefects（）</a></span></li><li><span><a href=\"#判断形状是否是凸的，cv2.isContourConvex（）\" data-toc-modified-id=\"判断形状是否是凸的，cv2.isContourConvex（）-6.5.3\"><span class=\"toc-item-num\">6.5.3&nbsp;&nbsp;</span>判断形状是否是凸的，cv2.isContourConvex（）</a></span></li><li><span><a href=\"#获取点到多边形的最近距离（点到直线的垂直距离）或位置关系，cv2.pointPolygonTest（）\" data-toc-modified-id=\"获取点到多边形的最近距离（点到直线的垂直距离）或位置关系，cv2.pointPolygonTest（）-6.5.4\"><span class=\"toc-item-num\">6.5.4&nbsp;&nbsp;</span>获取点到多边形的最近距离（点到直线的垂直距离）或位置关系，cv2.pointPolygonTest（）</a></span></li></ul></li><li><span><a href=\"#比较两个轮廓之间的关系\" data-toc-modified-id=\"比较两个轮廓之间的关系-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>比较两个轮廓之间的关系</a></span><ul class=\"toc-item\"><li><span><a href=\"#利用Hu矩比较两个轮廓的近似度，cv2.matchShapes（）\" data-toc-modified-id=\"利用Hu矩比较两个轮廓的近似度，cv2.matchShapes（）-6.6.1\"><span class=\"toc-item-num\">6.6.1&nbsp;&nbsp;</span>利用Hu矩比较两个轮廓的近似度，cv2.matchShapes（）</a></span></li><li><span><a href=\"#使用‘距离’的概念来比较轮廓的形状，cv2.createShapeContextDistanceExtractor.cv2.createShapeContextDistanceExtractor()\" data-toc-modified-id=\"使用‘距离’的概念来比较轮廓的形状，cv2.createShapeContextDistanceExtractor.cv2.createShapeContextDistanceExtractor()-6.6.2\"><span class=\"toc-item-num\">6.6.2&nbsp;&nbsp;</span>使用‘距离’的概念来比较轮廓的形状，cv2.createShapeContextDistanceExtractor.cv2.createShapeContextDistanceExtractor()</a></span></li><li><span><a href=\"#查找数组内最大和最小值的位置，cv2.minMaxLoc（）\" data-toc-modified-id=\"查找数组内最大和最小值的位置，cv2.minMaxLoc（）-6.6.3\"><span class=\"toc-item-num\">6.6.3&nbsp;&nbsp;</span>查找数组内最大和最小值的位置，cv2.minMaxLoc（）</a></span></li><li><span><a href=\"#平均颜色和平均灰度\" data-toc-modified-id=\"平均颜色和平均灰度-6.6.4\"><span class=\"toc-item-num\">6.6.4&nbsp;&nbsp;</span>平均颜色和平均灰度</a></span></li></ul></li></ul></li><li><span><a href=\"#直方图处理\" data-toc-modified-id=\"直方图处理-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>直方图处理</a></span><ul class=\"toc-item\"><li><span><a href=\"#直方图的含义\" data-toc-modified-id=\"直方图的含义-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>直方图的含义</a></span><ul class=\"toc-item\"><li><span><a href=\"#直方图的绘制\" data-toc-modified-id=\"直方图的绘制-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>直方图的绘制</a></span></li></ul></li><li><span><a href=\"#直方图均衡化\" data-toc-modified-id=\"直方图均衡化-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>直方图均衡化</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a59fdc",
   "metadata": {},
   "source": [
    "**运行需要在本代码运行文件目录下，放两张图片，并分别命名为‘jpg1.jpeg’和‘2.jpg’**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfde830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2efa5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('jpg1.jpeg')\n",
    "img2 = cv2.imread('jpg1.jpeg',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1796bf",
   "metadata": {},
   "source": [
    "## 阈值处理\n",
    "阈值处理简单来说，是设定一个阈值，对像素点的值超过阈值和没超过阈值的给与不同的数值变化，常见的变化有，将超过阈值的设为255低于阈值的设为0，或将超过阈值的设为0低于阈值的不变等，具体的变化可以通过选用不同的模式来调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636103b8",
   "metadata": {},
   "source": [
    "### 二值化阈值处理，cv2.threshold（）\n",
    "图片处理完之后只有0和255两个值，需要注意函数返回两个结果，第一个返回值是设定的阈值，输入多少返回多少,第二个才是处理后的图像。  \n",
    "\n",
    "多通道彩色图片处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c902e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test1',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#对多通道BGR图像使用二值化阈值处理\n",
    "reval,img_show = cv2.threshold(img1,175,255,cv2.THRESH_BINARY)\n",
    "if reval:\n",
    "    cv2.imshow('test1',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "#二值化阈值处理并翻转前景和背景颜色\n",
    "reval,img_show = cv2.threshold(img1,175,255,cv2.THRESH_BINARY_INV)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f67abe",
   "metadata": {},
   "source": [
    "单通道灰度图片处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2752921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test1',img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#对灰度图像使用二值化阈值处理\n",
    "reval,img_show = cv2.threshold(img2,225,255,cv2.THRESH_BINARY)\n",
    "if reval: \n",
    "    cv2.imshow('test1',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows() \n",
    "#对灰度图像使用二值化阈值处理并翻转前景和背景\n",
    "reval,img_show = cv2.threshold(img2,225,255,cv2.THRESH_BINARY_INV)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32781d",
   "metadata": {},
   "source": [
    "### 非二值化阈值处理，cv2.threshold（）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76752722",
   "metadata": {},
   "source": [
    "#### cv2.THRESH_TRUNC模式，将大于阈值的像素值都改成阈值,注意函数返回值有两个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7cfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reval,img_show = cv2.threshold(img1,175,255,cv2.THRESH_TRUNC)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "reval,img_show = cv2.threshold(img2,175,255,cv2.THRESH_TRUNC)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fd0b7",
   "metadata": {},
   "source": [
    "#### cv2.THERSH_TOZERO模式，将小于阈值的像素值变成0，大于阈值的不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f51f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test1',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "reval,img_show = cv2.threshold(img1,240,255,cv2.THRESH_TOZERO)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('test1',img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "reval,img_show = cv2.threshold(img2,240,255,cv2.THRESH_TOZERO)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa0620",
   "metadata": {},
   "source": [
    "#### cv2.THERSH_TOZERO_INV模式，将超过阈值的像素值变为0，小于阈值的不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d9f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test1',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "reval,img_show = cv2.threshold(img1,252,255,cv2.THRESH_TOZERO_INV)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('test1',img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "reval,img_show = cv2.threshold(img2,230,255,cv2.THRESH_TOZERO_INV)\n",
    "if reval:\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b49844",
   "metadata": {},
   "source": [
    "#### 自适应局部阈值处理，cv2.adaptiveThreshold()\n",
    "只能用于单通道灰度图片,不需要设定具体的阈值，根据设定的块大小内部像素的平均值或者经过高斯分布计算之后的平均值来作为阈值。  \n",
    "\n",
    "其中有三个参数比较重要：  \n",
    "\n",
    "adaptiveMethod：只能选cv2.ADAPTIVE_THRESH_MEAN_C或cv2.ADAPTIVE_THRESH_GAUSSIAN_C  \n",
    "\n",
    "thresholdType：只能选cv2.THRESH_BINARY或cv2.THRESH_BINARY——INV  \n",
    "\n",
    "blockSize:代表参与阈值计算最小单元的尺寸，只能是int  \n",
    "\n",
    "C：经过平均或者加权平均计算之后，减去C作为最终的阈值，必须要赋值不然会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a74347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#常量等于0时，背景是白色\n",
    "img_show = cv2.adaptiveThreshold(img2,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY_INV,3,0)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "#常量等于25，背景是黑色，因为背景区域算出来的平均阈值接近255，减去常量20之后，阈值小于周边像素的值，所以周边像素会变成0或者255\n",
    "img_show = cv2.adaptiveThreshold(img2,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,51,50)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f08d6c",
   "metadata": {},
   "source": [
    "#### 自动计算全局阈值模式，cv2.THRESH_OTSU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556a1b1",
   "metadata": {},
   "source": [
    "对于灰度分布不均匀的图像，比较整体偏白或者偏黑的图像，手动设定阈值可能达不到区分图像的效果，可能出现像素值都在阈值之上或者之下的情况，使用Otsu模式，可以根据图像情况自己设定全局阈值，并返回图像。  \n",
    "\n",
    "需要注意的是:  \n",
    "1、这个模式的使用需要使用加号将其添加在其他模式后面  \n",
    "2、阈值需要设置为0才能奇效  \n",
    "3、返回的reval是计算出来的最优全局阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "034aec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default: 175.0\n",
      "Otsu: 206.0\n"
     ]
    }
   ],
   "source": [
    "#对灰度图像使用二值化阈值处理\n",
    "reval,img_show = cv2.threshold(img2,175,255,cv2.THRESH_BINARY)\n",
    "if reval: \n",
    "    print(\"default:\",reval)\n",
    "    cv2.imshow('test1',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows() \n",
    "\n",
    "#对灰度图像使用Otsu模式\n",
    "reval,img_show = cv2.threshold(img2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "if reval: \n",
    "    print(\"Otsu:\",reval)\n",
    "    cv2.imshow('test1',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9195d0dc",
   "metadata": {},
   "source": [
    "## 图像模糊/平滑/去噪"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f891e5d",
   "metadata": {},
   "source": [
    "### 均值滤波，cv2.blur（）\n",
    "以中心点周边一定范围内像素点的均值作为中心点的新像素值。需要以tuple的形式提供kernel size，作为滑动窗口的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f307fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img_show = cv2.blur(img1,(5,5))\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97dbc3",
   "metadata": {},
   "source": [
    "### 方框滤波，cv2.boxFilter（）\n",
    "以中心点的周边点的和的均值，或者以中心点的周边点的和，作为中心点的新像素值，可选。  \n",
    "\n",
    "其中，有几个重要参数：  \n",
    "\n",
    "1、ddepth：图片的深度信息，在这里图片的深度信息不会变化，所以使用-1可以保持输入图片的深度  \n",
    "\n",
    "2、normalize: 是否要进行平均处理。如果赋值1，表示要将周边像素的和除以像素数量，如果赋值为0，则直接取周边像素的和作为中间点新的像素值，但是往往会导致像素值超过255，让图片为全白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b975a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img_show = cv2.boxFilter(img1,-1,(5,5),normalize=1)\n",
    "cv2.imshow('normalize=1',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img_show = cv2.boxFilter(img1,-1,(5,5),normalize=0)\n",
    "cv2.imshow('normalize=0',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69294e",
   "metadata": {},
   "source": [
    "### 高斯滤波，cv2.GaussianBlur（）\n",
    "将中心点周边一定范围内像素点的加权平均和作为中心点的新像素值。  \n",
    "\n",
    "其中，有几个参数需要注意：  \n",
    "\n",
    "Kernel size: 控制核的尺寸\n",
    "sigmaY: 控制Y方向各像素值的标准差，如果为0，则只采用sigmaX的值\n",
    "sigmaX: 控制X方向各像素值的标准差，如果和sigmaY同时为0，则通过kernel size来计算sigmaX和sigmaY的值。具体计算公式为$$sigmaX = 0.3*[(kernel -size.width-1)*0.5-1]+0.8$$$$sigmaX = 0.3*[(kernel-size.height-1)*0.5-1]+0.8$$  \n",
    "\n",
    "一般使用，可以显示的指定sigmaX和sigmaY为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f5c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img_show = cv2.GaussianBlur(img1,(11,11),sigmaX=0,sigmaY=0)\n",
    "cv2.imshow('GaussianBlur',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f3105",
   "metadata": {},
   "source": [
    "### 中值滤波，cv2.medianBlur（）\n",
    "以中心点周边一定范围内的像素点的中位值作为中心点的新像素值，范围必须是奇数，这样才能保证中位数是唯一的。  \n",
    "\n",
    "例如，kernel size取3，则表示有每个滑动窗口内有3*3=9个像素值，对这9个像素值进行大小排序，排在第5位的那个数值将被作为计算结果赋予中间点作为新的像素值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90a04479",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img_show = cv2.medianBlur(img1,5)\n",
    "cv2.imshow('median Blur',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3057bd1",
   "metadata": {},
   "source": [
    "### 双边滤波，cv2.bilateralFilter（）\n",
    "基于中心像素点与周边像素点的距离以及像素值的差，进行权重分配之后，再计算加权平均和作为中心点的新像素值。距离越远，像素值差别越大，权重越小，目的是为了保持边缘清晰，不被模糊。  \n",
    "\n",
    "其中有几个比较重要的参数:  \n",
    "\n",
    "1、d：类似于kernel size，也就是窗口的计算范围，不过这里表示的是圆的直径值。这个值对图片处理速度影响较大，官方建议取5，图片噪音非常多的时候可以取9  \n",
    "2、sigmaColor： 颜色差值阈值，如果滑动窗口内的一个点与周围点的颜色差值小于这个阈值，这个点就能参与到模糊计算中，不然就不参与计算，这是边缘能得以保留的原因，边缘的颜色差值一般比较大，不参与模糊计算所以边缘得以保留。  \n",
    "3、sigmaSpace：距离差值阈值，两个像素点的距离差值如果小于这个阈值，就能参与运算，不然就不参与。当d>0时，这个值时效，反之，d失效，这个值控制距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d038f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img_show = cv2.bilateralFilter(img1,9,100,100)\n",
    "cv2.imshow('bilateralFilter',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46caea55",
   "metadata": {},
   "source": [
    "## 形态学操作\n",
    "判断滑动窗口与前景形状之间的包含关系，前景全包含滑动窗口和前景不是全包含滑动窗口时，分别对图像在滑动窗口中心位置的像素点进行处理。  \n",
    "\n",
    "另外，一般要求黑色为背景，白色为前景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03eb49",
   "metadata": {},
   "source": [
    "### 腐蚀与膨胀（背景扩大和前景扩大）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82f365",
   "metadata": {},
   "source": [
    "#### 腐蚀，cv2.erode（）\n",
    "需要重点关注的参数有这些：  \n",
    "1、kernel：一个numpy.array,需要自定义或者通过其他函数产生，不能只是一个形状tuple  \n",
    "2、iterations：进行腐蚀的次数  \n",
    "3、src: 输入的图像，可以是单通道也可以是多通道，但是图像的深度最少要是8位的，不能是1位的2值图像，可以是8位的2值图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ece1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#对多通道图像进行腐蚀\n",
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "img_show = cv2.erode(img1,kernel,iterations=5)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#对单通道灰度图像进行腐蚀\n",
    "cv2.imshow('test',img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "img_show = cv2.erode(img2,kernel,iterations=5)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#对8位2值图像进行腐蚀\n",
    "reval,img3 = cv2.threshold(img2,240,255,cv2.THRESH_BINARY_INV)\n",
    "if reval:\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "for i in range(10):\n",
    "    img_show = cv2.erode(img3,kernel,iterations = i)\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453b224",
   "metadata": {},
   "source": [
    "#### 膨胀，cv2.dilate（）\n",
    "参数同腐蚀，但是注意是图片中的白色部分进行膨胀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e163a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#对多通道图像进行腐蚀\n",
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "img_show = cv2.dilate(img1,kernel,iterations=5)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#对单通道灰度图像进行腐蚀\n",
    "cv2.imshow('test',img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "img_show = cv2.dilate(img2,kernel,iterations=5)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#对8位2值图像进行腐蚀\n",
    "reval,img3 = cv2.threshold(img2,240,255,cv2.THRESH_BINARY_INV)\n",
    "if reval:\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "for i in range(10):\n",
    "    img_show = cv2.dilate(img3,kernel,iterations = i)\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a237195",
   "metadata": {},
   "source": [
    "### 腐蚀与膨胀的组合操作，cv2.morphologyEx()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df018d",
   "metadata": {},
   "source": [
    "#### 开运算，cv2.MORPH_OPEN\n",
    "去除前景的外部噪音：前景先缩小后变大。  \n",
    "\n",
    "其中，需要注意的参数：  \n",
    "1、op：需要进行形态操作的类型，包含多个可选属性，开运算对应的属性是cv2.MORPH_OPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e23dc2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,20):\n",
    "    #显示原始图像\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()   \n",
    "    #显示运算后的图像\n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations = i) \n",
    "    \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2de505",
   "metadata": {},
   "source": [
    "#### 闭运算，cv2.MORPH_CLOSE\n",
    "去除前景内部噪音：前景先变大后缩小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13c90adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,20):\n",
    "    #显示原始图像\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()   \n",
    "    #显示运算后的图像\n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_CLOSE,kernel,iterations = i) \n",
    "    \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f140ca",
   "metadata": {},
   "source": [
    "#### 梯度运算，cv2.MORPH_GRADIENT\n",
    "前景轮廓提取，膨胀图像-腐蚀图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe26439",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    #显示原始图像\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()   \n",
    "    #显示运算后的图像\n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_GRADIENT,kernel,iterations = i) \n",
    "    \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290ebb6",
   "metadata": {},
   "source": [
    "#### 顶帽运算，cv2.MORPH_TOPHAT\n",
    "噪音或边缘提取，原始图像-开运算图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a16ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "    #显示原始图像\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()   \n",
    "    #显示运算后的图像\n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_TOPHAT,kernel,iterations = i) \n",
    "    \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a2c00",
   "metadata": {},
   "source": [
    "#### 黑帽运算，cv2.MORPH_BLACKHAT\n",
    "前景内部缺陷或内部边缘提取，闭运算-原始图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9901eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    #显示原始图像\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()   \n",
    "    #显示运算后的图像\n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_BLACKHAT,kernel,iterations = i) \n",
    "    \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4f9308",
   "metadata": {},
   "source": [
    "#### 自定义核函数\n",
    "方形核函数可以通过numpy直接生成，但是对于一些独特形状的核，如十字架，圆形等形状的核，可以借用函数来生成。  \n",
    "\n",
    "其中有两个重要参数：  \n",
    "\n",
    "1、shape: 选择需要的属性形状，有三种，矩形、十字星、椭圆形，分别为cv2.MORPH_RECT、cv2.MORPH_CROSS、cv2.MORPH_ELLIPSE  \n",
    "2、ksize: kernel的形状,要求是tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73eee3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_RECT = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "kernel_CROSS = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "kernel_ELLIPSE = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "for i in range(1,10):\n",
    "    #显示原始图像\n",
    "    cv2.imshow('test',img3)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()   \n",
    "    #显示不同核运算后的图像\n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_ERODE,kernel_RECT,iterations = i) \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_ERODE,kernel_CROSS,iterations = i) \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    img_show = cv2.morphologyEx(img3,cv2.MORPH_ERODE,kernel_ELLIPSE,iterations = i) \n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a05c0",
   "metadata": {},
   "source": [
    "## 图像边缘（图像梯度）\n",
    "在cv2里图像梯度并不是真的对图像进行梯度计算，而是通过加减乘除来近似逼近梯度的计算值，其中sobel和scharr近似于一阶导，laplacian近似于二阶导。 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34eee7",
   "metadata": {},
   "source": [
    "对于sobel算子，针对X，Y两个方向的边缘用的核不同。  \n",
    "对于水平方向，也就是X方向的边缘，使用的核是：$[[-1,-2,-1],[0,0,0],[1,2,1]]$  \n",
    "对于竖直方向，也就是Y方向的边缘，使用的核是：$[[-1,-2,-1],[0,0,0],[1,2,1]]^T$  \n",
    "计算方式如下，对于一个计算单元内的9个点$[[p1,p2,p3],[p4,p5,p6],[p7,p8,p9]]$  \n",
    "在检测水平方向边缘时，$p5 = p9+2*p8+p7-p3-2*p2-p1$  \n",
    "在检测竖直方向边缘时，$p5 = p3+2*p6+p9-p1-2*p4-p7$\n",
    "\n",
    "对于scharr算子，针对X，Y两个方向的边缘用的核也不同,在核比较小的时候，scharr算子精度更高。  \n",
    "对于水平方向，也就是X方向的边缘，使用的核是：$[[-3,-10,-3],[0,0,0],[3,10,3]]$  \n",
    "对于竖直方向，也就是Y方向的边缘，使用的核是：$[[-3,-10,-3],[0,0,0],[3,10,3]]^T$  \n",
    "计算方式如下，对于一个计算单元内的9个点$[[p1,p2,p3],[p4,p5,p6],[p7,p8,p9]]$  \n",
    "在检测水平方向边缘时，$p5 = 3*p9+10*p8+3*p7-3*p3-10*p2-3*p1$  \n",
    "在检测竖直方向边缘时，$p5 = 3*p3+10*p6+3*p9-3*p1-10*p4-3*p7$\n",
    "\n",
    "对于sobel算子，因为是近似二阶导，所以没有方向限制，使用的核是：$[[0,1,0],[1,-4,1],[0,1,0]]$ ，其特点是，核内各位置权重和为0 \n",
    "计算方式如下，对于一个计算单元内的9个点$[[p1,p2,p3],[p4,p5,p6],[p7,p8,p9]]$  \n",
    "检测水平和垂直方向边缘时，$p5 = p2+p4+p6+p8-4*p5$  \n",
    "\n",
    "**需要注意的是，以上这些点p5像素值的计算方式的结果可能会是负值，如果图片的深度采用的是uint8格式，则所有的负数都会转化成0，所以在指定输出图片的深度时，需要将其使用float32或64来表达，然后将这些负数转换成其绝对值，再显示相应的结果**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f67ac",
   "metadata": {},
   "source": [
    "### 基于sobel算子的边缘检测，cv2.Sobel（）\n",
    "关键参数有如下几个：  \n",
    "ddepth: 输出图片的深度，默认是跟原图片一样，但是因为可能会出现负的‘梯度’，所以用float64会更好。  \n",
    "\n",
    "dx: 是否检测竖向边缘，1是，0否  \n",
    "\n",
    "dy: 是否检测水平向边缘，1是，0否  \n",
    "\n",
    "需要注意的是，当dx和dy都为1时，并不能同时显示水平和竖直边缘，因为算法并不是分别检测两种边缘再讲他们叠加，而是会先检测其中一个边缘，在得到的结果的基础上再检测另一个方向的边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c6ada1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = cv2.imread('2.jpg',0)\n",
    "cv2.imshow('test',img4)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#只检测竖直的边缘\n",
    "img_show = cv2.Sobel(img4,cv2.CV_64F,1,0)\n",
    "img_show = cv2.convertScaleAbs(img_show)\n",
    "cv2.imshow('X',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#只检测水平的边缘\n",
    "img_show = cv2.Sobel(img4,cv2.CV_64F,0,1)\n",
    "img_show = cv2.convertScaleAbs(img_show)\n",
    "cv2.imshow('X',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#检测水平和竖直边缘交叉部分\n",
    "img_show = cv2.Sobel(img4,cv2.CV_64F,1,1)\n",
    "img_show = cv2.convertScaleAbs(img_show)\n",
    "cv2.imshow('X and Y',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692d8c3",
   "metadata": {},
   "source": [
    "### 基于scharr算子的边缘检测，cv2.Scharr（）\n",
    "参数跟sobel基本一样，除了以下两点：  \n",
    "1、如果设定kernel size 为-1，则等价于使用sobel算法  \n",
    "2、不同同时设定dx和dy都为1，会报错。因为需要满足dx+dy=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72a1fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img4)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#只检测竖直的边缘\n",
    "img_show = cv2.Scharr(img4,cv2.CV_64F,1,0)\n",
    "img_show = cv2.convertScaleAbs(img_show)\n",
    "cv2.imshow('X',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#只检测水平的边缘\n",
    "img_show = cv2.Scharr(img4,cv2.CV_64F,0,1)\n",
    "img_show = cv2.convertScaleAbs(img_show)\n",
    "cv2.imshow('X',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#同时检测水平和竖直边缘\n",
    "img_show = cv2.Scharr(img4,cv2.CV_64F,1,0)\n",
    "img_show_tmp = cv2.Scharr(img4,cv2.CV_64F,0,1)\n",
    "\n",
    "img_show = cv2.convertScaleAbs(img_show)\n",
    "img_show_tmp = cv2.convertScaleAbs(img_show_tmp)\n",
    "\n",
    "img_show_tmp = cv2.addWeighted(img_show,1,img_show_tmp,1,0)\n",
    "cv2.imshow('X and Y',img_show_tmp)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ae51c",
   "metadata": {},
   "source": [
    "### 基于laplacian算子的边缘检测，cv2.Laplacian（）\n",
    "参数同sobel，没有dx和dy参数，可以直接同时检测水平和竖直方向边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b6438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img4)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#同时检测水平和竖直边缘\n",
    "img_show = cv2.Laplacian(img4,cv2.CV_64F)\n",
    "img_show = cv2.convertScaleAbs(img_show)\n",
    "cv2.imshow('X and Y',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c7e02",
   "metadata": {},
   "source": [
    "### Canny边缘检测，cv2.Canny（）\n",
    "关键参数：  Theshold1、Theshold2，当这两个值比较小的之后，能获取更多边缘信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bd94f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#使用较小的Theshold1和Theshold2的值\n",
    "img_show = cv2.Canny(img3,20,40)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#使用较大的Theshold1和Theshold2的值\n",
    "img_show = cv2.Canny(img3,180,200)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a6bad",
   "metadata": {},
   "source": [
    "## 图像的上采样与下采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04fa39",
   "metadata": {},
   "source": [
    "### 图像的下采样，cv2.pyrDown（）\n",
    "图像的下采样是将图像的偶数行和偶数列删除（从1开始），这样每一次下采样之后的图片都是原图片的长宽的1/2。直接抽取会造成像素点差别过大的问题，所以比较常见的方式是对图片先进行滤波处理（平均滤波或者高斯滤波），然后再进行抽取，下采样生成的图片会更平滑。cv2.pyrDown()方法默认使用高斯滤波方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "127c4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "img_show = cv2.copyTo(img1,None)\n",
    "\n",
    "for i in range(5):\n",
    "    img_show = cv2.pyrDown(img_show)\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa169a1",
   "metadata": {},
   "source": [
    "### 图像的上采样，cv2.pyrDown（）\n",
    "上采样和下采样是思路是一样的，但是有一个问题需要解决，下采样是把图片变小，所以直接把部分像素点删除就行，但是上采样是要把图片变大，所以需要在图片中插入新的像素点，所以存在一个如何插入以及插入什么像素值的问题。  \n",
    "常规的操作是，同样按照偶数列对原有图片进行插值，插入的值为0，然后再使用高斯滤波将图像进行模糊，将插入值为0的像素点能获得更平均的值，最后再对整张图片乘以高斯滤波器的长宽之和，生成最终的图片，因为高斯滤波在使用过程中会求均值，所以需要进行最后的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faa30e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "img_show = cv2.copyTo(img1,None)\n",
    "\n",
    "#先将图片缩小\n",
    "for i in range(4):\n",
    "    img_show = cv2.pyrDown(img_show)\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "#再将图片放大\n",
    "for i in range(4):\n",
    "    img_show = cv2.pyrUp(img_show)\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "#最后显示一次原图像进行对比\n",
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd6460",
   "metadata": {},
   "source": [
    "### 图像的上下采样可逆化实现：拉普拉斯金字塔\n",
    "完整运行上面一段代码之后会发现，通过相同次数的下采样和上采样之后，虽然生成的最终结果和原图尺寸相同，但是清晰度差很多，原因是下采样的过程中会丢失信息，但是上采样并不会增加信息，只是平滑了图片，所以整体来说经过相同次数的下采样和上采样之后，图片的信息是会丢失的。  \n",
    "如何解决上下采样过程中的信息丢失问题呢？只需要保存每次下、上采样过程中产生的差异即可，这个差异准确来说指的是，经过一次下采样和一次上采样之后生成的图片和原图片之间的差值组成的数组，只要保存了这个信息，就可以将图片逐步的还原，这些每次通过原图像和经过一次下上采样之后的图像形成的差值叫做拉普拉斯金字塔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1592b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "img_show = cv2.copyTo(img1,None)\n",
    "img_show = cv2.resize(img_show,(576,368)) \n",
    "lapl_list = []\n",
    "\n",
    "#获取4轮下上采样的拉普拉斯金字塔\n",
    "for i in range(4):\n",
    "    img_show_tmp = cv2.pyrDown(img_show)\n",
    "    img_show_out = cv2.pyrUp(img_show_tmp)\n",
    "    lapl_list.append(img_show-img_show_out)\n",
    "    img_show = img_show_tmp\n",
    "#先将图片缩小\n",
    "img_show = cv2.copyTo(img1,None)\n",
    "img_show = cv2.resize(img_show,(576,368))\n",
    "for i in range(4):\n",
    "    img_show = cv2.pyrDown(img_show)\n",
    "    cv2.imshow('test',img_show)    \n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "#再将图片放大,每一轮放大的过程都加上拉普拉斯金字塔中的对应差值\n",
    "for i in range(4):\n",
    "    img_show = cv2.pyrUp(img_show)\n",
    "    img_show = img_show+lapl_list[3-i]\n",
    "    cv2.imshow('test',img_show)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "#最后显示一次原图像进行对比\n",
    "img_show = cv2.copyTo(img1,None)\n",
    "img_show = cv2.resize(img_show,(576,368))\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0df47",
   "metadata": {},
   "source": [
    "## 图像轮廓检测\n",
    "轮廓指的是连续的边缘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054b58d2",
   "metadata": {},
   "source": [
    "### 查找、绘制轮廓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58962cd",
   "metadata": {},
   "source": [
    "#### 查找轮廓，cv2.morphologyEx（）\n",
    "返回轮廓和轮廓之间的层级关系，重要参数如下：  \n",
    "\n",
    "image: 要求是8位的单通道图像，处理过程中函数会对图像进行二值化处理，也就是说函数会将大于0的值处理成1\n",
    "\n",
    "mode: 查找轮廓的模式，有多种模式，只查找外轮廓（cv2.RETR_EXTERNAL）,对检测到的轮廓不建立等级（cv2.RETR_LIST）,对检测到的轮廓只建立两层等级（cv2.RETR_CCOMP）,对检测到的轮廓建立树状关系（cv2.RETR_TREE）  \n",
    "\n",
    "method: 对返回的轮廓的形式进行设置，有多种属性，存储所有轮廓的像素点（cv2.CHAIN_APPROX_NONE）,只存储轮廓线上的端点（cv2.CHAIN_APPROX_SIMPLE）,还有cv2.CHAIN_APPROX_TC89_L1和cv2.CHAIN_APPROX_TC89_KCOS  \n",
    "\n",
    "对于返回值，内容如下：  \n",
    "\n",
    "**contours**: 返回的轮廓内容，以tuple的形式把所有找到的轮廓装在一起，每个轮廓以一个三维数组的形式存储。如下方的结果，contours[0]表示第一个轮廓，(571, 1, 2)表示这个轮廓有571个点组成，1是每一个点，2表示每个点由两个坐标即x,y组成。  \n",
    "\n",
    "**hierarchy**: 表示返回的轮廓之间的层级关系，是一个三维数组，每个数据包含四个数字，分别代表[后一个轮廓的编号，前一个轮廓的编号，子轮廓的编号，父轮廓的编号]，其中-1表示不存在，编号从0开始。如[ 1 -1 -1 -1]表示，下一个轮廓编号是1，没有前一个轮廓，没有子轮廓，没有父轮廓。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "490fa076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(571, 1, 2)\n",
      "[[[ 1 -1 -1 -1]\n",
      "  [-1  0 -1 -1]]]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(contours[0].shape)\n",
    "print(hier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff50a19",
   "metadata": {},
   "source": [
    "#### 绘制轮廓，cv2.findContours（）\n",
    "需要注意的是，函数会直接修改传入的图片，如果不是特殊情况，需要先复制一张图片然后再绘制。  \n",
    "\n",
    "有以下几个参数需要注意：\n",
    "\n",
    "image: 用来绘制轮廓的图片，函数会直接在这个图片上进行绘制  \n",
    "\n",
    "contourIdx：明确要绘制的轮廓的索引，如果是-1则绘制所有给定的轮廓  \n",
    "\n",
    "color: 以tuple的形式给出BGR格式的颜色  \n",
    "\n",
    "thickness：绘制的粗细，如果赋值-1，则对轮廓进行填充\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c54f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "img_tmp = img1.copy()\n",
    "img_show = cv2.drawContours(img_tmp,contours,-1,(0,255,0),2) \n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4952f",
   "metadata": {},
   "source": [
    "### 轮廓的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f67868a",
   "metadata": {},
   "source": [
    "#### 轮廓的面积，cv2.contourArea（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8f1a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour 0 area: 31700.0\n",
      "contour 1 area: 33267.5\n"
     ]
    }
   ],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "for i in range(len(contours)):\n",
    "    area = cv2.contourArea(contours[i])\n",
    "    print(f'contour {i} area:',area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3698ebbb",
   "metadata": {},
   "source": [
    "#### 轮廓的周长，cv2.arcLength（）\n",
    "需要注意有一个布尔参数closed用来表明轮廓是否封闭，这个会对轮廓的周长有影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9ed3256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour 0 closed len: 1605.945298910141\n",
      "contour 0 not close len: 1596.945298910141\n",
      "contour 1 closed len: 1627.526034116745\n",
      "contour 1 not close len: 1618.526034116745\n"
     ]
    }
   ],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "for i in range(len(contours)):\n",
    "    l = cv2.arcLength(contours[i],closed=True)\n",
    "    print(f'contour {i} closed len:',l)\n",
    "    l = cv2.arcLength(contours[i],closed=False)\n",
    "    print(f'contour {i} not close len:',l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc9739",
   "metadata": {},
   "source": [
    "### 轮廓的矩\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a5f5d",
   "metadata": {},
   "source": [
    "#### 矩的意义和求法，cv2.moments（）\n",
    "两个轮廓之间如何判断是否相似或接近？为了解决这个问题，使用了矩这个概念，矩就是轮廓的数字表达，用来判断轮廓是否接近或相似。  \n",
    "一个轮廓经过旋转，缩放等操作之后，从人的角度来看与原始轮廓仍然十分相似或接近，机器如何判断两个不同角度和大小的轮廓是否相似呢？在矩的基础上，产生了不同的矩，用来判断不同情况下的轮廓是否相似或接近。  \n",
    "\n",
    "空间矩(下面结果中所有以m开头的)：可以用来判断两个轮廓的大小、位置是否相同  \n",
    "中心矩(下面结果中所有以mu开头的)：可以用来判断两个轮廓的大小是否相同，允许位置不同  \n",
    "归一化中心矩(下面结果中所有以nu开头的)：可以用来判断两个轮廓是否相似，允许大小、位置不同  \n",
    "\n",
    "求矩只需要输入一个数组即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89ac24fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moments1: {'m00': 16967190.0, 'm10': 4896488070.0, 'm01': 3586506660.0, 'm20': 1859277423570.0, 'm11': 1035354929295.0, 'm02': 896556095280.0, 'm30': 796234680824040.0, 'm21': 405557257309245.0, 'm12': 258873674167695.0, 'm03': 249480879689700.0, 'mu20': 446221082499.2438, 'mu11': 340464692.1078419, 'mu02': 138444114320.0204, 'mu30': 2127811188531.3416, 'mu21': 12348657356761.95, 'mu12': -3510704743.0334344, 'mu03': 1439460758313.968, 'nu20': 0.001549994792827283, 'nu11': 1.1826391011222412e-06, 'nu02': 0.0004808998604273261, 'nu30': 1.79435463292212e-06, 'nu21': 1.041345710460684e-05, 'nu12': -2.9605302173599865e-09, 'nu03': 1.2138779486224193e-06} \n",
      "\n",
      "moments2: {'m00': 16937610.0, 'm10': 4888259475.0, 'm01': 3580603665.0, 'm20': 1856398418745.0, 'm11': 1033736145690.0, 'm02': 895094001525.0, 'm30': 795103638995535.0, 'm21': 404982395784900.0, 'm12': 258481904224350.0, 'm03': 249082050905205.0, 'mu20': 445627908919.3943, 'mu11': 360138587.7006112, 'mu02': 138155885355.63293, 'mu30': 2120044733735.5425, 'mu21': 12332672265121.625, 'mu12': 2061964178.491827, 'mu03': 1447360929976.5532, 'nu20': 0.0015533457184815774, 'nu11': 1.2553516556476155e-06, 'nu02': 0.0004815763301733013, 'nu30': 1.7956211121191781e-06, 'nu21': 1.044544312472107e-05, 'nu12': 1.746428437295068e-09, 'nu03': 1.2258759456188618e-06}\n"
     ]
    }
   ],
   "source": [
    "moments1 = cv2.moments(img3)\n",
    "moments2 = cv2.moments(img3_open)\n",
    "print('moments1:',moments1,'\\n')\n",
    "print('moments2:',moments2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77781123",
   "metadata": {},
   "source": [
    "#### Hu矩，cv2.HuMoments()\n",
    "Hu矩：通过归一化中心矩（nu）可以求得，共有7个值，可以用来判断两个轮廓是否相似，允许大小、位置，甚至是旋转角度不同。  \n",
    "\n",
    "注意，输入参数是cv2.moments函数的返回值，即所有的矩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3e4bbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1: [[ 2.03089465e-03]\n",
      " [ 1.14296957e-06]\n",
      " [ 9.04841965e-10]\n",
      " [ 1.38404013e-10]\n",
      " [-4.51389889e-20]\n",
      " [-1.41006846e-13]\n",
      " [-1.90107431e-20]] \n",
      "\n",
      "h1: [[ 2.03492205e-03]\n",
      " [ 1.14869593e-06]\n",
      " [ 9.09844873e-10]\n",
      " [ 1.39450219e-10]\n",
      " [-4.57702650e-20]\n",
      " [-1.42428372e-13]\n",
      " [-1.92976646e-20]]\n"
     ]
    }
   ],
   "source": [
    "moments1 = cv2.moments(img3)\n",
    "moments2 = cv2.moments(img3_open)\n",
    "\n",
    "hu1 = cv2.HuMoments(moments1)\n",
    "hu2 = cv2.HuMoments(moments2)\n",
    "\n",
    "print('h1:',hu1,'\\n')\n",
    "print('h1:',hu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfae1ff",
   "metadata": {},
   "source": [
    "### 轮廓的拟合\n",
    "轮廓很多时候不太规则，形状复杂导致端点很多，使用一些简单的形状来尽量接近轮廓的形状就是轮廓的拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16821509",
   "metadata": {},
   "source": [
    "#### 矩形拟合\n",
    "输入参数为使用cv2.findContours寻找到的轮廓，返回一个包含四个元素的tuple，分别是矩形左上角的x坐标，矩形左上角的y坐标，矩形的宽度w，矩形的高度h。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "993b94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "x,y,w,h = cv2.boundingRect(contours[0])\n",
    "rect_point = np.array([[[x,y]],[[x+w,y]],[[x+w,y+h]],[[x,y+h]]])   #轮廓中的所有点要组合成三维数组\n",
    "img_tmp = img1.copy()\n",
    "img_show = cv2.drawContours(img_tmp,(rect_point,),-1,(0,0,255),2)   #传入的轮廓需要以tuple的形式传入\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415c185",
   "metadata": {},
   "source": [
    "#### 最小矩形拟合，cv2.minAreaRect（）\n",
    "cv2.minAreaRect函数返回的结果不太相同，分别是矩形中心点的x,y坐标，w,h，以及旋转的角度值，所以不能直接传给drawContour，需要先把结果传给boxPoints()函数，再将返回值传给drawContour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f939ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "points = cv2.minAreaRect(contours[0])\n",
    "min_rect_point = cv2.boxPoints(points)\n",
    "min_rect_point = np.int0(min_rect_point)  #需要把结果取整，不然会有小数，传入drawContour后无法使用\n",
    "img_tmp = img1.copy()\n",
    "img_show = cv2.drawContours(img_tmp,[min_rect_point],-1,(0,0,255),2)   #传入的轮廓需要以tuple的形式传入\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb8857",
   "metadata": {},
   "source": [
    "#### 最小圆形拟合，cv2.minEnclosingCircle（）\n",
    "返回的是圆的圆心和半径，不能再使用drawContour来绘制轮廓，需要使用cv2.circle()来绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd8a57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "(x,y),radius = cv2.minEnclosingCircle(contours[0])\n",
    "\n",
    "center = (int(x),int(y))\n",
    "radius = int(radius)\n",
    "\n",
    "img_tmp = img1.copy()\n",
    "img_show = cv2.circle(img_tmp,center,radius,(0,0,255),2)   #传入的轮廓需要以tuple的形式传入\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef55092",
   "metadata": {},
   "source": [
    "#### 最优椭圆拟合，cv2.fitEllipse（）\n",
    "cv2.fitEllipse()生成的信息和cv2.ellipse()需要的信息一致，可以直接使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f8d2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "ellipse_info = cv2.fitEllipse(contours[0])\n",
    "\n",
    "img_tmp = img1.copy()\n",
    "img_show = cv2.ellipse(img_tmp,ellipse_info,(0,0,255),2)   #传入的轮廓需要以tuple的形式传入\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf8ada",
   "metadata": {},
   "source": [
    "#### 最优直线拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879005c1",
   "metadata": {},
   "source": [
    "待更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3143b40",
   "metadata": {},
   "source": [
    "#### 最小外包三角形拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faee167",
   "metadata": {},
   "source": [
    "待更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4888a",
   "metadata": {},
   "source": [
    "#### 逼近的多边形拟合，cv2.approxPolyDP（）\n",
    "需要注意的参数是epsilon，这个参数表达的是，轮廓中最远点到多边形的最大允许距离，值越大，多边形拟合轮廓就越不准确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1f83d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "for i in range(50):\n",
    "    reval = cv2.approxPolyDP(contours[0],i,closed=True)\n",
    "    img_tmp = img1.copy()\n",
    "    img_show = cv2.drawContours(img_tmp,[reval],-1,(0,0,255),2)   #传入的轮廓需要以tuple或list的形式传入\n",
    "    cv2.imshow(f'epsilon {i}',img_show)\n",
    "    cv2.waitKey(200)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165a064",
   "metadata": {},
   "source": [
    "### 凸包"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb85946",
   "metadata": {},
   "source": [
    "#### 寻找绘制凸包，cv2.convexHull（），cv2.polylines（）\n",
    "凸包指的是能把所有轮廓包进去，且凸包上的任意两点的连线都在凸包范围内的多边形。多边形逼近不一定会把轮廓的所有部分都包括进去，跟凸包有些区别。  \n",
    "\n",
    "cv2.convexHull函数有几个关键参数：  \n",
    "\n",
    "1、points: 用于计算凸包的轮廓点，需要以三维数组的形式传入  \n",
    "2、returnPoints: 控制返回的结果是以点的形式，还是以索引的形式，True是点，False是索引，默认True，以点的形式的时候可以把返回结果直接传给cv2.polylines函数来画出凸包。**需要注意的是，之所以可以返回点或者是索引是因为凸包的所有端点一定还是在原有轮廓上的，所以返回的索引其实是原有轮廓点集合的索引**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45b17de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "points = cv2.convexHull(contours[0],clockwise=False,returnPoints=True)\n",
    "img_tmp = img1.copy()\n",
    "img_show = cv2.polylines(img_tmp,[points],True,(0,0,255),2)\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb955a6",
   "metadata": {},
   "source": [
    "#### 凸缺陷，cv2.convexityDefects（）\n",
    "凸包围合起来的区域去掉轮廓包裹的区域之后的范围叫做凸缺陷，因为凸包是紧贴轮廓的，所以凸缺陷可能会被分为多个小块。需要注意的参数是：  \n",
    "\n",
    "convexhull：这个参数需要传入cv2.convexHull函数的返回值，并且要求返回值是索引的形式，所以需要在cv2.convexHull中将returnPoints参数设定为False。  \n",
    "\n",
    "这个函数的返回值是一个数组，结构类似于三维矩阵，每个数据由四个值组成，分别是【凸缺陷起点在轮廓点集上的索引，凸缺陷终点在轮廓点集上的索引，轮廓上距离凸包最远的点在轮廓点集上的索引，轮廓上距离凸包最远的点到凸包的近似距离】，拿下方求得的凸缺陷区域列表结果来举例，【0,2,1,114】表示了第一个凸缺陷区域，其中这个凸缺陷区域的起点在轮廓点集合上的索引为0，终点在轮廓点集的索引为2，距离凸包最远的点在轮廓点集上的索引为1，距离是114。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "889c0ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[    0     2     1   114]]\n",
      "\n",
      " [[    2    66    29 22221]]\n",
      "\n",
      " [[   66   153   109 18631]]\n",
      "\n",
      " [[  153   155   154   114]]\n",
      "\n",
      " [[  156   158   157   114]]\n",
      "\n",
      " [[  158   303   236 11407]]\n",
      "\n",
      " [[  305   457   416  9624]]\n",
      "\n",
      " [[  457   459   458   114]]\n",
      "\n",
      " [[  460   522   497 18006]]\n",
      "\n",
      " [[  522   570   541 21749]]]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "img3_open = cv2.morphologyEx(img3,cv2.MORPH_OPEN,kernel,iterations=2)\n",
    "cv2.imshow('test',img3_open)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "contours,hier = cv2.findContours(img3_open,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "points = cv2.convexHull(contours[0],clockwise=False,returnPoints=False)\n",
    "img_tmp = img1.copy()\n",
    "\n",
    "defects_points = cv2.convexityDefects(contours[0],points)\n",
    "\n",
    "print(defects_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ec5bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tmp = img1.copy()\n",
    "for i in range(len(defects_points)):\n",
    "    s,e,f,d = defects_points[i][0]\n",
    "    s_point = contours[0][s][0]\n",
    "    e_point = contours[0][e][0]\n",
    "    f_point = contours[0][f][0]\n",
    "    img_tmp = cv2.line(img_tmp,s_point,e_point,(0,0,255),2)\n",
    "    img_tmp = cv2.circle(img_tmp,f_point,2,(0,0,255),-1)\n",
    "    cv2.imshow('test',img_tmp)\n",
    "    cv2.waitKey(500)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06d128",
   "metadata": {},
   "source": [
    "#### 判断形状是否是凸的，cv2.isContourConvex（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9234ea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour 0 is convex? False\n",
      "contour 1 is convex? False\n",
      "convexHull is convex? True\n"
     ]
    }
   ],
   "source": [
    "#判断轮廓形状是否是凸的\n",
    "bool1 = cv2.isContourConvex(contours[0])\n",
    "bool2 = cv2.isContourConvex(contours[1])\n",
    "#判断由轮廓形状得到的凸包是否是凸的\n",
    "points_tmp = cv2.convexHull(contours[0])\n",
    "bool3 = cv2.isContourConvex(points_tmp)\n",
    "\n",
    "print('contour 0 is convex?',bool1)\n",
    "print('contour 1 is convex?',bool2)\n",
    "print('convexHull is convex?',bool3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163b7ecd",
   "metadata": {},
   "source": [
    "#### 获取点到多边形的最近距离（点到直线的垂直距离）或位置关系，cv2.pointPolygonTest（）\n",
    "主要参数如下：  \n",
    "1、pt：用来进行距离计算或者位置判断的点，以tuple的形式传入  \n",
    "2、measureDist：布尔值，True时，返回点到轮廓的最近垂直距离，负数表示点在轮廓外，正数表示点在轮廓内。False时，只返回电和轮廓的位置关系，点在轮廓外返回-1，点在轮廓上返回0，点在轮廓内返回1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "07c8162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance: -230.7899477880265\n",
      "relation: -1.0\n"
     ]
    }
   ],
   "source": [
    "test_pt = (100,300)\n",
    "dist = cv2.pointPolygonTest(contours[0],test_pt,True)\n",
    "relation = cv2.pointPolygonTest(contours[0],test_pt,False)\n",
    "print('distance:',dist)\n",
    "print('relation:',relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded60bab",
   "metadata": {},
   "source": [
    "### 比较两个轮廓之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbce43",
   "metadata": {},
   "source": [
    "#### 利用Hu矩比较两个轮廓的近似度，cv2.matchShapes（）\n",
    "重要参数如下：  \n",
    "\n",
    "contour1,contour2：分别是要比较的第一个和第二个轮廓  \n",
    "\n",
    "method：采用的比较方法，有cv2.CONTOURS_MATCH_I1,cv2.CONTOURS_MATCH_I2,cv2.CONTOURS_MATCH_I3三种属性可选  \n",
    "\n",
    "parameter：官方目前没有启用这个参数，但是需要赋值才不会报错，可以赋值为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ec2ca30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour0 and contour1 matchshapes: 0.09302378379959958\n",
      "contour0 and contour0 matchshapes: 0.0\n"
     ]
    }
   ],
   "source": [
    "retval1 = cv2.matchShapes(contours[0],contours[1],cv2.CONTOURS_MATCH_I1,0)\n",
    "retval2 = cv2.matchShapes(contours[0],contours[0],cv2.CONTOURS_MATCH_I1,0)\n",
    "\n",
    "print(\"contour0 and contour1 matchshapes:\",retval1)\n",
    "print(\"contour0 and contour0 matchshapes:\",retval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171f33f",
   "metadata": {},
   "source": [
    "#### 使用‘距离’的概念来比较轮廓的形状，cv2.createShapeContextDistanceExtractor.cv2.createShapeContextDistanceExtractor()\n",
    "‘距离’是仿照实际的距离创造的一个用来衡量形状和形状之间的相似关系的一个概念，使用的时候需要先初始化一个‘距离’比较器实例，再将两个轮廓进行比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创造一个‘距离’比较器实例\n",
    "sd = cv2.createShapeContextDistanceExtractor()\n",
    "retval1 = sd.computerDistance(contours[0],contours[1])\n",
    "retval2 = sd.computerDistance(contours[0],contours[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3587ef2",
   "metadata": {},
   "source": [
    "#### 查找数组内最大和最小值的位置，cv2.minMaxLoc（）\n",
    "只能在单通道图像上使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c2607aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 255.0, (0, 0), (177, 28))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(img3)\n",
    "minVal, maxVal, minLoc, maxLoc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad00b2",
   "metadata": {},
   "source": [
    "#### 平均颜色和平均灰度\n",
    "返回值是RGBA四个通道的平均值，如果是单通道图片则只有一个非零值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b1f5fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215.56585564646505, 223.23712600593822, 237.71032561722174, 0.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#彩色图片\n",
    "mean_val = cv2.mean(img1)\n",
    "mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f5066b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.98417368640253, 0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#单通道灰度图片\n",
    "mean_val = cv2.mean(img3)\n",
    "mean_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f09b6",
   "metadata": {},
   "source": [
    "## 直方图处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e055b67",
   "metadata": {},
   "source": [
    "### 直方图的含义\n",
    "直方图表达的是0-255范围内的每个灰度值范围内所拥有的像素点的个数，其中x轴灰度范围，如果每一个灰度值都是一个范围，则共有256个范围，分别从0到255，或者是对像素值进行分段（bins），如分成两段，那第一段是0-177，第二段是178-255。y轴表示的是对应x灰度范围内在这张图片上有多少个点。  \n",
    "\n",
    "一张色彩均衡的图片，直方图往往具有分布均有的特点，而一张偏暗的图片，直方图会偏向于0，一张偏亮的图片，直方图偏向于255，所以直方图的意义是判断图片是否明暗均衡，也可以借助直方图对图像的明暗情况进行调节，使得其更加均衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca82d5",
   "metadata": {},
   "source": [
    "#### 直方图的绘制\n",
    "可以直接使用matplotlib或者cv2中的直方图工具进行绘制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "86e0d9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#显示图像\n",
    "cv2.imshow('test',img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#使用numpy和matplotlib绘制\n",
    "import matplotlib.pyplot as plt\n",
    "B,G,R = cv2.split(img1)\n",
    "B_data = B.reshape(B.size)\n",
    "G_data = G.reshape(G.size)\n",
    "R_data = R.reshape(R.size)\n",
    "plt.hist(B_data,label='B',rwidth= 0.3)\n",
    "plt.hist(G_data,label='G',rwidth= 0.3)\n",
    "plt.hist(R_data,label='R',rwidth= 0.3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe9e445",
   "metadata": {},
   "source": [
    "### 直方图均衡化\n",
    "对于不太均衡的图片，可以通过直方图均衡进行优化，优化的思路如下：对于每个像素值，保持其含有的元素个数不变，将其值在取值范围内重新取值，使得整体像素值分布更加均匀。具体的办法是首先统计小于每个像素值的像素点个数占整体的比例，然后将这个比例乘以取值范围的最大值，如255，得到的结果作为新的像素值。对每一个像素值进行如上操作，最后完成均衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9dfc1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示原图像\n",
    "cv2.imshow('test',img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img_show = cv2.copyTo(img2,None)\n",
    "img_show = cv2.equalizeHist(img_show)\n",
    "\n",
    "#显示均衡化之后的图片\n",
    "cv2.imshow('test',img_show)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
