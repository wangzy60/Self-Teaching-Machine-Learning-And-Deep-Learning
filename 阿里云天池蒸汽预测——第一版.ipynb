{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一步、先看训练数据的一些基本信息，数据的维度，每个维度的值域，再看一下前面几排数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2888, 39)\n",
      "V0: [ -4.335 2.121 ]\n",
      "V1: [ -5.122000000000001 1.9180000000000001 ]\n",
      "V2: [ -3.42 2.8280000000000003 ]\n",
      "V3: [ -3.9560000000000004 2.457 ]\n",
      "V4: [ -4.742 2.6889999999999996 ]\n",
      "V5: [ -2.182 0.489 ]\n",
      "V6: [ -4.5760000000000005 1.895 ]\n",
      "V7: [ -5.048 1.9180000000000001 ]\n",
      "V8: [ -4.692 2.245 ]\n",
      "V9: [ -12.890999999999998 1.335 ]\n",
      "V10: [ -2.5839999999999996 4.83 ]\n",
      "V11: [ -3.16 1.455 ]\n",
      "V12: [ -5.165 2.657 ]\n",
      "V13: [ -3.675 2.475 ]\n",
      "V14: [ -2.455 2.5580000000000003 ]\n",
      "V15: [ -2.903 4.314 ]\n",
      "V16: [ -5.981 2.861 ]\n",
      "V17: [ -2.224 2.023 ]\n",
      "V18: [ -3.582 4.441 ]\n",
      "V19: [ -3.7039999999999997 3.431 ]\n",
      "V20: [ -3.4019999999999997 3.525 ]\n",
      "V21: [ -2.6430000000000002 2.259 ]\n",
      "V22: [ -1.375 2.0180000000000002 ]\n",
      "V23: [ -5.542000000000001 1.906 ]\n",
      "V24: [ -1.344 2.423 ]\n",
      "V25: [ -3.8080000000000003 7.284 ]\n",
      "V26: [ -5.131 2.98 ]\n",
      "V27: [ -1.1640000000000001 0.925 ]\n",
      "V28: [ -2.435 4.671 ]\n",
      "V29: [ -2.912 4.58 ]\n",
      "V30: [ -4.507 2.6889999999999996 ]\n",
      "V31: [ -5.859 2.013 ]\n",
      "V32: [ -4.053 2.395 ]\n",
      "V33: [ -4.627 5.465 ]\n",
      "V34: [ -4.789 5.11 ]\n",
      "V35: [ -5.695 2.324 ]\n",
      "V36: [ -2.608 5.2379999999999995 ]\n",
      "V37: [ -3.63 3.0 ]\n",
      "target:[ -3.63 3.0 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>-1.812</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>-0.436</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-0.615</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-4.627</td>\n",
       "      <td>-4.789</td>\n",
       "      <td>-5.101</td>\n",
       "      <td>-2.608</td>\n",
       "      <td>-3.508</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-1.566</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>0.332</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.730</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.013</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.112</td>\n",
       "      <td>-0.797</td>\n",
       "      <td>-1.367</td>\n",
       "      <td>-2.360</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.599</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>-1.200</td>\n",
       "      <td>-2.086</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.603</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>-2.086</td>\n",
       "      <td>0.314</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>1.078</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.445</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.458</td>\n",
       "      <td>-1.056</td>\n",
       "      <td>-1.009</td>\n",
       "      <td>-1.896</td>\n",
       "      <td>0.481</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.618</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.224</td>\n",
       "      <td>-0.893</td>\n",
       "      <td>-0.812</td>\n",
       "      <td>-1.823</td>\n",
       "      <td>0.729</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.155</td>\n",
       "      <td>-1.318</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.258</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>-1.721</td>\n",
       "      <td>0.753</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.428</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.100</td>\n",
       "      <td>-0.899</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.591</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.591</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>0.763</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.597</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.553</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.157</td>\n",
       "      <td>1.055</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.617</td>\n",
       "      <td>1.483</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>-1.524</td>\n",
       "      <td>0.968</td>\n",
       "      <td>-2.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.843</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.151</td>\n",
       "      <td>-1.157</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V0     V1     V2     V3     V4     V5     V6     V7     V8     V9  ...  \\\n",
       "0  0.566  0.016 -0.143  0.407  0.452 -0.901 -1.812 -2.360 -0.436 -2.114  ...   \n",
       "1  0.968  0.437  0.066  0.566  0.194 -0.893 -1.566 -2.360  0.332 -2.114  ...   \n",
       "2  1.013  0.568  0.235  0.370  0.112 -0.797 -1.367 -2.360  0.396 -2.114  ...   \n",
       "3  0.733  0.368  0.283  0.165  0.599 -0.679 -1.200 -2.086  0.403 -2.114  ...   \n",
       "4  0.684  0.638  0.260  0.209  0.337 -0.454 -1.073 -2.086  0.314 -2.114  ...   \n",
       "5  0.445  0.627  0.408  0.220  0.458 -1.056 -1.009 -1.896  0.481 -2.114  ...   \n",
       "6  0.889  0.416  0.640  0.356  0.224 -0.893 -0.812 -1.823  0.729 -2.114  ...   \n",
       "7  0.984  0.529  0.704  0.438  0.258 -0.917 -0.682 -1.721  0.753 -2.114  ...   \n",
       "8  0.948  0.850  0.584  0.459  0.591 -0.523 -0.591 -1.524  0.763 -2.114  ...   \n",
       "9  1.157  1.055  0.638  0.617  1.483 -0.731 -0.612 -1.524  0.968 -2.114  ...   \n",
       "\n",
       "     V29    V30    V31    V32    V33    V34    V35    V36    V37  target  \n",
       "0  0.136  0.109 -0.615  0.327 -4.627 -4.789 -5.101 -2.608 -3.508   0.175  \n",
       "1 -0.128  0.124  0.032  0.600 -0.843  0.160  0.364 -0.335 -0.730   0.676  \n",
       "2 -0.009  0.361  0.277 -0.116 -0.843  0.160  0.364  0.765 -0.589   0.633  \n",
       "3  0.015  0.417  0.279  0.603 -0.843 -0.065  0.364  0.333 -0.112   0.206  \n",
       "4  0.183  1.078  0.328  0.418 -0.843 -0.215  0.364 -0.280 -0.028   0.384  \n",
       "5  0.454  0.674  0.358  0.618 -0.843 -0.290  0.364 -0.191 -0.883   0.060  \n",
       "6  0.454  0.081  0.243  0.468 -0.843 -0.290  0.364 -0.155 -1.318   0.415  \n",
       "7  0.139 -0.050  0.428 -0.119 -0.843 -0.290  0.364  0.100 -0.899   0.609  \n",
       "8  0.188  0.467  0.597 -0.057 -0.843 -0.290  0.364  0.053 -0.553   0.981  \n",
       "9  0.860  0.456  0.916  0.039 -0.843 -0.290  0.364  0.151 -1.157   0.818  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('zhengqi_train.txt',sep='\t')\n",
    "print('shape:',train_data.shape)\n",
    "for i in range(38):\n",
    "    print(f'V{i}:','[',train_data['V'+str(i)].min(),train_data['V'+str(i)].max(),']')\n",
    "print('target:[',train_data['V'+str(i)].min(),train_data['V'+str(i)].max(),']')\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第二步、看一下验证集的数据情况划分训练特征和训练结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148</td>\n",
       "      <td>0.489</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.137</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>0.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      V0     V1     V2     V3     V4     V5     V6     V7     V8     V9  ...  \\\n",
       "0  0.368  0.380 -0.225 -0.049  0.379  0.092  0.550  0.551  0.244  0.904  ...   \n",
       "1  0.148  0.489 -0.247 -0.049  0.122 -0.201  0.487  0.493 -0.127  0.904  ...   \n",
       "2 -0.166 -0.062 -0.311  0.046 -0.055  0.063  0.485  0.493 -0.227  0.904  ...   \n",
       "3  0.102  0.294 -0.259  0.051 -0.183  0.148  0.474  0.504  0.010  0.904  ...   \n",
       "4  0.300  0.428  0.208  0.051 -0.033  0.116  0.408  0.497  0.155  0.904  ...   \n",
       "\n",
       "     V28    V29    V30    V31    V32    V33    V34    V35    V36    V37  \n",
       "0 -0.449  0.047  0.057 -0.042  0.847  0.534 -0.009 -0.190 -0.567  0.388  \n",
       "1 -0.443  0.047  0.560  0.176  0.551  0.046 -0.220  0.008 -0.294  0.104  \n",
       "2 -0.458 -0.398  0.101  0.199  0.634  0.017 -0.234  0.008  0.373  0.569  \n",
       "3 -0.456 -0.398  1.007  0.137  1.042 -0.040 -0.290  0.008 -0.666  0.391  \n",
       "4 -0.458 -0.776  0.291  0.370  0.181 -0.040 -0.290  0.008 -0.140 -0.497  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = ['V'+str(i) for i in range(38)]\n",
    "\n",
    "test_data = pd.read_csv('zhengqi_test.txt',sep='\t')\n",
    "test_feat = test_data[feature_list]\n",
    "\n",
    "test_feat.head()\n",
    "\n",
    "#验证集没有target，不能对数据进行验证，所以需要将训练集划分成训练和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2310, 38) (578, 38) (2310,) (578,)\n"
     ]
    }
   ],
   "source": [
    "#将训练集划分成特征和结果数据\n",
    "train_feat = train_data[feature_list]  #生成训练特征\n",
    "train_target = train_data['target']    #生成训练结果\n",
    "\n",
    "#将训练集的特征和结果进一步划分为训练集和验证集，按照8:2的比例进行\n",
    "from sklearn.model_selection import train_test_split\n",
    "t_feat,v_feat,t_target,v_target = train_test_split(train_feat,train_target,test_size=0.2,random_state=1)\n",
    "print(t_feat.shape,v_feat.shape,t_target.shape,v_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第三步、根据数据初步判断是一个多维回归问题，先用最简单的思路线性回归fit一下，然后用交叉验证来验证整个train_data的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.28249032214646264 \n",
      "\n",
      "[ 3.62962217e-01  1.80453314e-01  1.76737262e-01  1.27573139e-01\n",
      "  3.66379068e-02 -9.31148691e-02  1.19962306e-01 -1.66032324e-01\n",
      " -2.23045045e-01  4.19701433e-02  3.29237747e-01  4.91042275e-02\n",
      "  9.46192287e-02 -2.92254237e-03  5.20518693e-02  2.00867740e-02\n",
      "  1.75444312e-02  8.78769670e-02  9.78510360e-03  2.43033862e-02\n",
      " -9.65597429e-04 -8.74573088e-03  1.77847757e-02  1.15275739e-02\n",
      " -3.57682620e-02 -1.64996778e-02  3.05428928e-02  1.12937220e+00\n",
      " -7.42670134e-03 -5.48316240e-02  2.13664811e-02  1.59180497e-02\n",
      " -1.31966008e-02  1.35715978e-02 -1.96018932e-03 -1.69333160e-02\n",
      " -2.57382390e-01 -5.14439231e-02]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9fe0dad196d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcross_predict_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcross_predict_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_predict_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cross_MSE:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_predict_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "#注意训练的时候只用t_feat和t_target验证的时候用的是train_feat和train_target\n",
    "\n",
    "#尝试一：不对输入数据使用正则化\n",
    "#第1步，先创建一个线性回归模型，fit一下\n",
    "import sklearn.linear_model as sl\n",
    "linear_model = sl.LinearRegression()\n",
    "linear_model.fit(t_feat,t_target)\n",
    "print(linear_model.intercept_,'\\n') #打印训练好的偏置\n",
    "print(linear_model.coef_)      #打印训练好的权重集合\n",
    "\n",
    "#第2步，使用交叉验证对整个train数据集进行验证,cv=10表示将整个数据集分成10份，每次取9份计算选中数据的预测值，最后将这10次的每个数据的预测结果取平均值返回\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "cross_predict_value = cross_val_predict(linear_model,train_feat,train_target,cv=10)\n",
    "cross_predict_mse = metrics.mean_squared_error(train_target,cross_predict_value)\n",
    "print('cross_MSE:',cross_predict_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#尝试二：对输入数据进行正则化处理，其余步骤同上\n",
    "norm_linear_model = sl.LinearRegression(normalize=True)\n",
    "norm_linear_model.fit(t_feat,t_target)\n",
    "print(norm_linear_model.intercept_,'\\n') #打印训练好的偏置\n",
    "print(norm_linear_model.coef_)      #打印训练好的权重集合\n",
    "\n",
    "cross_predict_norm_value = cross_val_predict(norm_linear_model,train_feat,train_target,cv=10)\n",
    "cross_predict_norm_mse = metrics.mean_squared_error(train_target,cross_predict_norm_value)\n",
    "print('cross_norm_MSE:',cross_predict_norm_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 赛题要求预测结果以mean square error作为评判标准。目前的MSE大概是在0.12，进入不了排行榜前500位，并且对输入做正则化处理之后并没有提升显著结果，接下来考虑两个思路来提升。    \n",
    "一是用不同的随机数据来训练数据，取效果最好的模型。    \n",
    "二是分析一下特征的相关性，看能否通过去掉相关性比较低的数据来减少噪音，增加准确度。思路一相对简单，先实现思路一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model info: 10_0 index: 0 model_mse: 0.061059639235936665 min_mse: 0.061059639235936665\n",
      "model info: 10_2 index: 2 model_mse: 0.11020904291619603 min_mse: 0.061059639235936665\n",
      "model info: 10_3 index: 3 model_mse: 0.1421445115188771 min_mse: 0.061059639235936665\n",
      "model info: 10_4 index: 4 model_mse: 0.060492159198031734 min_mse: 0.060492159198031734\n",
      "model info: 10_5 index: 5 model_mse: 0.11329182395559911 min_mse: 0.060492159198031734\n",
      "model info: 10_6 index: 6 model_mse: 0.12509888828613147 min_mse: 0.060492159198031734\n",
      "model info: 10_7 index: 7 model_mse: 0.10394065285693674 min_mse: 0.060492159198031734\n",
      "model info: 10_8 index: 8 model_mse: 0.05254305369175427 min_mse: 0.05254305369175427\n",
      "model info: 10_9 index: 9 model_mse: 0.22514634832238561 min_mse: 0.05254305369175427\n",
      "model info: 8_0 index: 10 model_mse: 0.07523311334508745 min_mse: 0.05254305369175427\n",
      "model info: 8_1 index: 11 model_mse: 0.08478630450131343 min_mse: 0.05254305369175427\n",
      "model info: 8_2 index: 12 model_mse: 0.11692212835875501 min_mse: 0.05254305369175427\n",
      "model info: 8_3 index: 13 model_mse: 0.08792288447436176 min_mse: 0.05254305369175427\n",
      "model info: 8_4 index: 14 model_mse: 0.09792865290333505 min_mse: 0.05254305369175427\n",
      "model info: 8_5 index: 15 model_mse: 0.11556139752311977 min_mse: 0.05254305369175427\n",
      "model info: 8_6 index: 16 model_mse: 0.08423681843633914 min_mse: 0.05254305369175427\n",
      "model info: 8_7 index: 17 model_mse: 0.19725500892555592 min_mse: 0.05254305369175427\n",
      "model info: 6_0 index: 18 model_mse: 0.07727890910843221 min_mse: 0.05254305369175427\n",
      "model info: 6_1 index: 19 model_mse: 0.09920414001128414 min_mse: 0.05254305369175427\n",
      "model info: 6_2 index: 20 model_mse: 0.0977629834302669 min_mse: 0.05254305369175427\n",
      "model info: 6_3 index: 21 model_mse: 0.11303928065018554 min_mse: 0.05254305369175427\n",
      "model info: 6_4 index: 22 model_mse: 0.10142390298101701 min_mse: 0.05254305369175427\n",
      "model info: 6_5 index: 23 model_mse: 0.15648907441920468 min_mse: 0.05254305369175427\n",
      "model info: 4_0 index: 24 model_mse: 0.08054530254402413 min_mse: 0.05254305369175427\n",
      "model info: 4_1 index: 25 model_mse: 0.10271741797409795 min_mse: 0.05254305369175427\n",
      "model info: 4_2 index: 26 model_mse: 0.10771534797291499 min_mse: 0.05254305369175427\n",
      "model info: 4_3 index: 27 model_mse: 0.13964559700222237 min_mse: 0.05254305369175427\n",
      "model info: 2_0 index: 28 model_mse: 0.09194587938245093 min_mse: 0.05254305369175427\n",
      "model info: 2_1 index: 29 model_mse: 0.12540164057577277 min_mse: 0.05254305369175427\n"
     ]
    }
   ],
   "source": [
    "#思路一\n",
    "#步骤一：将整个训练集顺序打散。分成10份，分别用其中的9份数据分别训练10个模型，将10个模型和结果存在列表中。\n",
    "#步骤二：然后分别将打散的数据分成8、6、4、2份，分别用n-1份数据训练处n个模型，其中n=8、6、4、2,并将结果存在列表中\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "\n",
    "model_list = []\n",
    "random_train_feat,random_train_target = shuffle(train_feat,train_target)\n",
    "train_data_len = len(random_train_feat)\n",
    "all_index = [i for i in range(2887)]\n",
    "n=0\n",
    "init_mse = 1\n",
    "'''\n",
    "random_train_feat[i]会报错，因为feat不止一类数据，而一个pd数据后面使用索引只有在数据仅一列时才有效，\n",
    "random_train_feat.loc[i/list]能运行，但是返回的是索引为i的那行数据\n",
    "random_train_feat.iloc[i/list]也能运行，返回的是当前pd数据中顺序为i的那一行数据\n",
    "需要注意的是，每一行数据都会有个索引的号码，一般来说索引的号码和数据当前的序号是相同的，但是当把数据打乱之后，这个索引和序号就不相同了。\n",
    "这里需要用的是打乱后的数据的序号\n",
    "'''\n",
    "for i in range(10,1,-2):\n",
    "    for j in range(i):\n",
    "        model_info = []\n",
    "        model_info.append('model'+str(i)+'_'+str(j))\n",
    "        model_info[0] = sl.LinearRegression()  #生成模型\n",
    "        \n",
    "        unselected_index = [i for i in range(j*int(train_data_len/i),min((j+1)*int(train_data_len/i),2888))]\n",
    "        selected_index = [i for i in all_index if i not in unselected_index]\n",
    "        \n",
    "        random_train_feat_for_train = random_train_feat.iloc[selected_index]\n",
    "        random_train_target_for_train = random_train_target.iloc[selected_index]\n",
    "        \n",
    "        model_info[0].fit(random_train_feat_for_train,random_train_target_for_train)\n",
    "        \n",
    "        predict_tmp = model_info[0].predict(train_feat.iloc[unselected_index])\n",
    "        mse_tmp = metrics.mean_squared_error(train_target.iloc[unselected_index],predict_tmp)\n",
    "        model_info.append(mse_tmp)\n",
    "        model_list.append(model_info)\n",
    "        n=n+1\n",
    "        if mse_tmp<init_mse:\n",
    "            init_mse = mse_tmp\n",
    "        print('model info:',str(i)+'_'+str(j),'index:',n-1,'model_mse:',model_info[1],'min_mse:',init_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unselected_feat: V0 \t down\n",
      "unselected_feat: V1 \t down\n",
      "unselected_feat: V2 \t down\n",
      "unselected_feat: V3 \t down\n",
      "unselected_feat: V4 \t down\n",
      "unselected_feat: V5 \t down\n",
      "unselected_feat: V6 \t down\n",
      "unselected_feat: V7 \t down\n",
      "unselected_feat: V8 \t down\n",
      "unselected_feat: V9 \t down\n",
      "unselected_feat: V10 \t down\n",
      "unselected_feat: V11 \t down\n",
      "unselected_feat: V12 \t down\n",
      "unselected_feat: V13 \t down\n",
      "unselected_feat: V14 \t down\n",
      "unselected_feat: V15 \t down\n",
      "unselected_feat: V16 \t down\n",
      "unselected_feat: V17 \t down\n",
      "unselected_feat: V18 \t down\n",
      "unselected_feat: V19 \t down\n",
      "unselected_feat: V20 \t down\n",
      "unselected_feat: V21 \t down\n",
      "unselected_feat: V22 \t down\n",
      "unselected_feat: V23 \t down\n",
      "unselected_feat: V24 \t down\n",
      "unselected_feat: V25 \t down\n",
      "unselected_feat: V26 \t down\n",
      "unselected_feat: V27 \t down\n",
      "unselected_feat: V28 \t down\n",
      "unselected_feat: V29 \t down\n",
      "unselected_feat: V30 \t down\n",
      "unselected_feat: V31 \t down\n",
      "unselected_feat: V32 \t down\n",
      "unselected_feat: V33 \t down\n",
      "unselected_feat: V34 \t down\n",
      "unselected_feat: V35 \t down\n",
      "unselected_feat: V36 \t down\n",
      "unselected_feat: V37 \t down\n",
      "{'V0': 0.113477314117121, 'V1': 0.10974681517583988, 'V2': 0.10978955931351501, 'V3': 0.11419884262850935, 'V4': 0.10795281849002177, 'V5': 0.10822369628047117, 'V6': 0.10861396451589893, 'V7': 0.11017626564497915, 'V8': 0.1097432061884501, 'V9': 0.10823492094302045, 'V10': 0.11736666291203701, 'V11': 0.10807319748638292, 'V12': 0.10852153671304784, 'V13': 0.10794389987495387, 'V14': 0.10894600948727055, 'V15': 0.1078880203648425, 'V16': 0.10793922158262237, 'V17': 0.10983572109389941, 'V18': 0.10794250398751351, 'V19': 0.10808152644558586, 'V20': 0.10792804498723452, 'V21': 0.10790781465317259, 'V22': 0.10792144585984494, 'V23': 0.10803115053840973, 'V24': 0.10855050709991079, 'V25': 0.1081598233578436, 'V26': 0.1083221301599749, 'V27': 0.11748021976554954, 'V28': 0.10793414502902685, 'V29': 0.10797221754180115, 'V30': 0.1080370619297655, 'V31': 0.10789349818529223, 'V32': 0.10794861907804783, 'V33': 0.1079768698969854, 'V34': 0.10781469995377439, 'V35': 0.10801526423462911, 'V36': 0.11410466079599066, 'V37': 0.10834885840351323}\n"
     ]
    }
   ],
   "source": [
    "#思路二，可以看到数据分布很均匀，选取不同比例的训练数据来训练模型对整个数据集的验证基本上没有影响。\n",
    "#接下来在上面的基础上，尝试去掉不同的特征看看对结果是否有影响。为了加快训练速度，选择将模型直接分成10份，然后将模型训练10次，取10次的平均损失作为轴坐标的值，横坐标为不同的维度特征。\n",
    "\n",
    "less_feat_MSE_dict = {}\n",
    "random_train_feat,random_train_target = shuffle(train_feat,train_target)\n",
    "train_data_len = len(random_train_feat)\n",
    "all_index = [i for i in range(2887)]\n",
    "all_feat_list = ['V'+str(i) for i in range(38)]\n",
    "\n",
    "for k in range(38):\n",
    "    mean_MSE_list = []\n",
    "    unselected_feat = 'V'+str(k)\n",
    "    print('unselected_feat:',unselected_feat,'\\t','down')\n",
    "    selected_feat = [i for i in all_feat_list if i != unselected_feat]\n",
    "    less_feat_random_train_feat = random_train_feat[selected_feat]\n",
    "    for i in range(10,8,-2):\n",
    "        for j in range(i):\n",
    "            model_info.append('model'+str(i)+'_'+str(j))\n",
    "            model_info[0] = sl.LinearRegression()  #生成模型\n",
    "\n",
    "            unselected_index = [i for i in range(j*int(train_data_len/i),min((j+1)*int(train_data_len/i),2888))]\n",
    "            selected_index = [i for i in all_index if i not in unselected_index]\n",
    "\n",
    "            less_feat_random_train_feat_for_train = less_feat_random_train_feat.iloc[selected_index]\n",
    "            random_train_target_for_train = random_train_target.iloc[selected_index]\n",
    "\n",
    "            model_info[0].fit(less_feat_random_train_feat_for_train,random_train_target_for_train)\n",
    "\n",
    "            predict_tmp = model_info[0].predict(train_feat[selected_feat].iloc[unselected_index])\n",
    "            mse_tmp = metrics.mean_squared_error(train_target.iloc[unselected_index],predict_tmp)\n",
    "            model_info.append(mse_tmp)\n",
    "            mean_MSE_list.append(mse_tmp)\n",
    "    less_feat_MSE_dict[f'V{k}'] = np.mean(mean_MSE_list)\n",
    "\n",
    "print(less_feat_MSE_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_value: 0.107\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.1071\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.1072\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.1073\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.10740000000000001\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.10750000000000001\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.10760000000000002\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.10770000000000002\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.10780000000000002\n",
      "low value feature:\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10972532733186906\n",
      "\n",
      "feature_value: 0.10790000000000002\n",
      "low value feature:\n",
      "V15 0.1078880203648425\n",
      "V31 0.10789349818529223\n",
      "V34 0.10781469995377439\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V32', 'V33', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10927915458021714\n",
      "\n",
      "feature_value: 0.10800000000000003\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V14', 'V17', 'V19', 'V23', 'V24', 'V25', 'V26', 'V27', 'V30', 'V35', 'V36', 'V37']\n",
      "high_value_MSE: 0.10787504499398094\n",
      "\n",
      "feature_value: 0.10810000000000003\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V11 0.10807319748638292\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V12', 'V14', 'V17', 'V24', 'V25', 'V26', 'V27', 'V36', 'V37']\n",
      "high_value_MSE: 0.10772419358381187\n",
      "\n",
      "feature_value: 0.10820000000000003\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V11 0.10807319748638292\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V25 0.1081598233578436\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V12', 'V14', 'V17', 'V24', 'V26', 'V27', 'V36', 'V37']\n",
      "high_value_MSE: 0.10732634753825387\n",
      "\n",
      "feature_value: 0.10830000000000004\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V25 0.1081598233578436\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V6', 'V7', 'V8', 'V10', 'V12', 'V14', 'V17', 'V24', 'V26', 'V27', 'V36', 'V37']\n",
      "high_value_MSE: 0.10843683461030777\n",
      "\n",
      "feature_value: 0.10840000000000004\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V25 0.1081598233578436\n",
      "V26 0.1083221301599749\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "V37 0.10834885840351323\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V6', 'V7', 'V8', 'V10', 'V12', 'V14', 'V17', 'V24', 'V27', 'V36']\n",
      "high_value_MSE: 0.10974763640257099\n",
      "\n",
      "feature_value: 0.10850000000000004\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V25 0.1081598233578436\n",
      "V26 0.1083221301599749\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "V37 0.10834885840351323\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V6', 'V7', 'V8', 'V10', 'V12', 'V14', 'V17', 'V24', 'V27', 'V36']\n",
      "high_value_MSE: 0.10974763640257099\n",
      "\n",
      "feature_value: 0.10860000000000004\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V12 0.10852153671304784\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V24 0.10855050709991079\n",
      "V25 0.1081598233578436\n",
      "V26 0.1083221301599749\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "V37 0.10834885840351323\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V6', 'V7', 'V8', 'V10', 'V14', 'V17', 'V27', 'V36']\n",
      "high_value_MSE: 0.11201680664396979\n",
      "\n",
      "feature_value: 0.10870000000000005\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V6 0.10861396451589893\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V12 0.10852153671304784\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V24 0.10855050709991079\n",
      "V25 0.1081598233578436\n",
      "V26 0.1083221301599749\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "V37 0.10834885840351323\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V7', 'V8', 'V10', 'V14', 'V17', 'V27', 'V36']\n",
      "high_value_MSE: 0.11395753435309647\n",
      "\n",
      "feature_value: 0.10880000000000005\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V6 0.10861396451589893\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V12 0.10852153671304784\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V24 0.10855050709991079\n",
      "V25 0.1081598233578436\n",
      "V26 0.1083221301599749\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "V37 0.10834885840351323\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V7', 'V8', 'V10', 'V14', 'V17', 'V27', 'V36']\n",
      "high_value_MSE: 0.11395753435309647\n",
      "\n",
      "feature_value: 0.10890000000000005\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V6 0.10861396451589893\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V12 0.10852153671304784\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V24 0.10855050709991079\n",
      "V25 0.1081598233578436\n",
      "V26 0.1083221301599749\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "V37 0.10834885840351323\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V7', 'V8', 'V10', 'V14', 'V17', 'V27', 'V36']\n",
      "high_value_MSE: 0.11395753435309647\n",
      "\n",
      "feature_value: 0.10900000000000006\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V5 0.10822369628047117\n",
      "V6 0.10861396451589893\n",
      "V9 0.10823492094302045\n",
      "V11 0.10807319748638292\n",
      "V12 0.10852153671304784\n",
      "V13 0.10794389987495387\n",
      "V14 0.10894600948727055\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V24 0.10855050709991079\n",
      "V25 0.1081598233578436\n",
      "V26 0.1083221301599749\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "V37 0.10834885840351323\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V7', 'V8', 'V10', 'V17', 'V27', 'V36']\n",
      "high_value_MSE: 0.11726516442516773\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画图\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "fig1,ax1 = plt.subplots()\n",
    "ax1.plot([i for i in range(38)],less_feat_MSE_dict.values())\n",
    "ax1.plot([i for i in range(38)],[0.108 for i in range(38)],'k--')\n",
    "fig1.show()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "#将上述对结果影响较小的feat（MSE小于设定的feature_value）剔除，创建一个feat训练集来训练数据，观察剔除不同feat对结果的影响\n",
    "\n",
    "high_value_MSE_list = []\n",
    "\n",
    "for feature_value in np.arange(0.1070,0.1090,0.0001):\n",
    "    low_value_feat_list = []\n",
    "    print('\\nfeature_value:',feature_value)\n",
    "    print('low value feature:')\n",
    "    for key in less_feat_MSE_dict.keys():\n",
    "        if less_feat_MSE_dict[key] < feature_value:\n",
    "            low_value_feat_list.append(key)\n",
    "            print(key,less_feat_MSE_dict[key])\n",
    "    \n",
    "    high_value_feat = [i for i in all_feat_list if i not in low_value_feat_list]\n",
    "    print('high_value_feat:',high_value_feat)\n",
    "    high_value_random_train_feat = random_train_feat[high_value_feat] \n",
    "    high_value_linear_model = sl.LinearRegression()\n",
    "    high_value_linear_model.fit(high_value_random_train_feat.iloc[[i for i in range(0,1000)]],random_train_target.iloc[[i for i in range(0,1000)]])\n",
    "    high_value_pridict = high_value_linear_model.predict(random_train_feat[high_value_feat].iloc[[i for i in range(1000,2888)]])\n",
    "    high_value_MSE = metrics.mean_squared_error(random_train_target.iloc[[i for i in range(1000,2888)]],high_value_pridict)\n",
    "    print('high_value_MSE:',high_value_MSE)\n",
    "    high_value_MSE_list.append(high_value_MSE)\n",
    "\n",
    "fig2,ax2 = plt.subplots()\n",
    "ax2.plot([i for i in range(1070,1091)],high_value_MSE_list)\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_value: 0.1082\n",
      "low value feature:\n",
      "V4 0.10795281849002177\n",
      "V11 0.10807319748638292\n",
      "V13 0.10794389987495387\n",
      "V15 0.1078880203648425\n",
      "V16 0.10793922158262237\n",
      "V18 0.10794250398751351\n",
      "V19 0.10808152644558586\n",
      "V20 0.10792804498723452\n",
      "V21 0.10790781465317259\n",
      "V22 0.10792144585984494\n",
      "V23 0.10803115053840973\n",
      "V25 0.1081598233578436\n",
      "V28 0.10793414502902685\n",
      "V29 0.10797221754180115\n",
      "V30 0.1080370619297655\n",
      "V31 0.10789349818529223\n",
      "V32 0.10794861907804783\n",
      "V33 0.1079768698969854\n",
      "V34 0.10781469995377439\n",
      "V35 0.10801526423462911\n",
      "high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V12', 'V14', 'V17', 'V24', 'V26', 'V27', 'V36', 'V37']\n",
      "high_value_MSE: 0.11006690789309505\n"
     ]
    }
   ],
   "source": [
    "#根据上面的数据，最终选择0.1082作为特征的分界线，利用如下的特征形成最终的模型\n",
    "#high_value_feat: ['V0', 'V1', 'V2', 'V3', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V12', 'V14', 'V17', 'V24', 'V26', 'V27', 'V36', 'V37']\n",
    "\n",
    "\n",
    "feature_value=0.1082\n",
    "low_value_feat_list = []\n",
    "print('\\nfeature_value:',feature_value)\n",
    "print('low value feature:')\n",
    "for key in less_feat_MSE_dict.keys():\n",
    "    if less_feat_MSE_dict[key] < feature_value:\n",
    "        low_value_feat_list.append(key)\n",
    "        print(key,less_feat_MSE_dict[key])\n",
    "\n",
    "high_value_feat = [i for i in all_feat_list if i not in low_value_feat_list]\n",
    "print('high_value_feat:',high_value_feat)\n",
    "high_value_random_train_feat = random_train_feat[high_value_feat] \n",
    "high_value_linear_model = sl.LinearRegression()\n",
    "high_value_linear_model.fit(high_value_random_train_feat.iloc[[i for i in range(0,1000)]],random_train_target.iloc[[i for i in range(0,1000)]])\n",
    "\n",
    "high_value_pridict = high_value_linear_model.predict(train_feat[high_value_feat])\n",
    "high_value_MSE = metrics.mean_squared_error(train_target,high_value_pridict)\n",
    "print('high_value_MSE:',high_value_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1925, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148</td>\n",
       "      <td>0.489</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.569</td>\n",
       "      <td>-0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.398</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.137</td>\n",
       "      <td>1.042</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.140</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>-1.362</td>\n",
       "      <td>-1.553</td>\n",
       "      <td>-3.096</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1.375</td>\n",
       "      <td>-4.854</td>\n",
       "      <td>-5.331</td>\n",
       "      <td>-4.074</td>\n",
       "      <td>-3.838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171</td>\n",
       "      <td>-4.488</td>\n",
       "      <td>-5.793</td>\n",
       "      <td>-4.050</td>\n",
       "      <td>-1.187</td>\n",
       "      <td>-0.852</td>\n",
       "      <td>-2.131</td>\n",
       "      <td>-2.564</td>\n",
       "      <td>0.597</td>\n",
       "      <td>-2.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>-2.698</td>\n",
       "      <td>-3.452</td>\n",
       "      <td>-3.620</td>\n",
       "      <td>-1.066</td>\n",
       "      <td>-1.385</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-4.927</td>\n",
       "      <td>-5.103</td>\n",
       "      <td>-4.393</td>\n",
       "      <td>-1.683</td>\n",
       "      <td>...</td>\n",
       "      <td>1.297</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>-7.698</td>\n",
       "      <td>-0.674</td>\n",
       "      <td>-1.187</td>\n",
       "      <td>-0.852</td>\n",
       "      <td>-2.131</td>\n",
       "      <td>-2.564</td>\n",
       "      <td>1.215</td>\n",
       "      <td>-4.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>-2.615</td>\n",
       "      <td>-3.564</td>\n",
       "      <td>-3.402</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>-1.272</td>\n",
       "      <td>1.121</td>\n",
       "      <td>-4.223</td>\n",
       "      <td>-4.315</td>\n",
       "      <td>-5.196</td>\n",
       "      <td>-3.407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.125</td>\n",
       "      <td>-6.111</td>\n",
       "      <td>0.275</td>\n",
       "      <td>-1.851</td>\n",
       "      <td>-1.548</td>\n",
       "      <td>-1.537</td>\n",
       "      <td>-2.544</td>\n",
       "      <td>1.612</td>\n",
       "      <td>-3.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>-2.661</td>\n",
       "      <td>-3.646</td>\n",
       "      <td>-3.271</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>-1.270</td>\n",
       "      <td>1.116</td>\n",
       "      <td>-3.716</td>\n",
       "      <td>-3.809</td>\n",
       "      <td>-4.735</td>\n",
       "      <td>-2.976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318</td>\n",
       "      <td>1.086</td>\n",
       "      <td>-5.268</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-1.645</td>\n",
       "      <td>-1.471</td>\n",
       "      <td>-1.537</td>\n",
       "      <td>-2.549</td>\n",
       "      <td>1.431</td>\n",
       "      <td>-3.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>-2.321</td>\n",
       "      <td>-3.037</td>\n",
       "      <td>-3.214</td>\n",
       "      <td>-1.594</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>1.259</td>\n",
       "      <td>-3.616</td>\n",
       "      <td>-3.747</td>\n",
       "      <td>-4.368</td>\n",
       "      <td>-2.976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.774</td>\n",
       "      <td>-5.211</td>\n",
       "      <td>1.618</td>\n",
       "      <td>-1.703</td>\n",
       "      <td>-1.471</td>\n",
       "      <td>-1.537</td>\n",
       "      <td>-1.123</td>\n",
       "      <td>1.988</td>\n",
       "      <td>-2.691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1925 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V0     V1     V2     V3     V4     V5     V6     V7     V8     V9  \\\n",
       "0     0.368  0.380 -0.225 -0.049  0.379  0.092  0.550  0.551  0.244  0.904   \n",
       "1     0.148  0.489 -0.247 -0.049  0.122 -0.201  0.487  0.493 -0.127  0.904   \n",
       "2    -0.166 -0.062 -0.311  0.046 -0.055  0.063  0.485  0.493 -0.227  0.904   \n",
       "3     0.102  0.294 -0.259  0.051 -0.183  0.148  0.474  0.504  0.010  0.904   \n",
       "4     0.300  0.428  0.208  0.051 -0.033  0.116  0.408  0.497  0.155  0.904   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1920 -1.362 -1.553 -3.096 -0.444  0.381  1.375 -4.854 -5.331 -4.074 -3.838   \n",
       "1921 -2.698 -3.452 -3.620 -1.066 -1.385  1.378 -4.927 -5.103 -4.393 -1.683   \n",
       "1922 -2.615 -3.564 -3.402 -0.422 -1.272  1.121 -4.223 -4.315 -5.196 -3.407   \n",
       "1923 -2.661 -3.646 -3.271 -0.699 -1.270  1.116 -3.716 -3.809 -4.735 -2.976   \n",
       "1924 -2.321 -3.037 -3.214 -1.594 -0.910  1.259 -3.616 -3.747 -4.368 -2.976   \n",
       "\n",
       "      ...    V29    V30    V31    V32    V33    V34    V35    V36    V37  \\\n",
       "0     ...  0.047  0.057 -0.042  0.847  0.534 -0.009 -0.190 -0.567  0.388   \n",
       "1     ...  0.047  0.560  0.176  0.551  0.046 -0.220  0.008 -0.294  0.104   \n",
       "2     ... -0.398  0.101  0.199  0.634  0.017 -0.234  0.008  0.373  0.569   \n",
       "3     ... -0.398  1.007  0.137  1.042 -0.040 -0.290  0.008 -0.666  0.391   \n",
       "4     ... -0.776  0.291  0.370  0.181 -0.040 -0.290  0.008 -0.140 -0.497   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1920  ...  0.171 -4.488 -5.793 -4.050 -1.187 -0.852 -2.131 -2.564  0.597   \n",
       "1921  ...  1.297 -0.613 -7.698 -0.674 -1.187 -0.852 -2.131 -2.564  1.215   \n",
       "1922  ...  0.552  0.125 -6.111  0.275 -1.851 -1.548 -1.537 -2.544  1.612   \n",
       "1923  ...  0.318  1.086 -5.268  0.683 -1.645 -1.471 -1.537 -2.549  1.431   \n",
       "1924  ...  0.323 -0.774 -5.211  1.618 -1.703 -1.471 -1.537 -1.123  1.988   \n",
       "\n",
       "      target  \n",
       "0      0.256  \n",
       "1      0.284  \n",
       "2     -0.047  \n",
       "3      0.105  \n",
       "4      0.255  \n",
       "...      ...  \n",
       "1920  -2.850  \n",
       "1921  -4.067  \n",
       "1922  -3.579  \n",
       "1923  -3.533  \n",
       "1924  -2.691  \n",
       "\n",
       "[1925 rows x 39 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对验证集进行预测，产生预测结果,#将预测结果写入新的txt文件，以备提交成果\n",
    "\n",
    "test_data_feat = pd.read_csv('zhengqi_test.txt',sep='\t')\n",
    "print(test_data_feat.shape)\n",
    "test_data_predict = high_value_linear_model.predict(test_data_feat[high_value_feat])\n",
    "test_data_feat['target'] = test_data_predict      #将计算出来的结果增加到读取数据后面\n",
    "test_data_feat = test_data_feat.round(decimals=3) #将数据控制在小数点后三位\n",
    "test_data_feat.to_csv('zhengqi_result.txt',sep='\t',index=False)    #将结果写入csv文件\n",
    "test_data_feat #生成包含预测结果的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "tianchi_metadata": {
   "competitions": [],
   "datasets": [
    {
     "id": "8987",
     "title": "【新人赛】工业蒸汽量预测"
    },
    {
     "id": "7498",
     "title": "工业蒸汽量预测"
    }
   ],
   "description": "",
   "notebookId": "395143",
   "source": "dsw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
