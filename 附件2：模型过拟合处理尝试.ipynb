{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d713eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,img_path,label_content,img_width,img_height):\n",
    "        self.img_path = img_path\n",
    "        self.label_content = label_content\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img_path = self.img_path[index]\n",
    "        img_cv2 = cv2.imread(img_path)  #return （H，W，C），C list by B，G，R\n",
    "        img_array = cv2.resize(img_cv2,(self.img_width,self.img_height))  #cv2.resize的输出为（w,h），宽在前，高在后\n",
    "        \n",
    "        img_name = os.path.split(img_path)[1]\n",
    "        img_label = self.label_content[img_name]['label']\n",
    "        #transform the label 0~9 to index 1~10，index 0 is for blank\n",
    "        img_label_index_list = [x+1 for x in img_label]\n",
    "        \n",
    "        return img_array,img_label_index_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,T,img_width,dropout):\n",
    "        super().__init__()\n",
    "        self.img_width = img_width\n",
    "        self.cnn_out_width = self.cal_finnal_width()\n",
    "        #self.cnn: input(N,3,100,200),output(N,512,4,7)\n",
    "        trained_resnet18 = models.resnet18(weights='DEFAULT')\n",
    "        self.cnn = nn.Sequential(trained_resnet18.conv1,\n",
    "                                 trained_resnet18.bn1,\n",
    "                                 trained_resnet18.relu,\n",
    "                                 trained_resnet18.maxpool,\n",
    "                                 trained_resnet18.layer1,\n",
    "                                 trained_resnet18.layer2,\n",
    "                                 trained_resnet18.layer3,\n",
    "                                 trained_resnet18.layer4)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.feat_to_seq = nn.Conv2d(self.cnn_out_width,T,kernel_size=(1,1),stride=1)\n",
    "        self.rnn = nn.GRU(input_size=512,hidden_size=64,bidirectional=True)\n",
    "        self.linear = nn.Linear(128,11)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = self.cnn(X)\n",
    "        X = self.dropout(X)\n",
    "        X = X.mean(dim=2,keepdim=True)\n",
    "        X = X.permute((0,3,1,2))\n",
    "        X = self.feat_to_seq(X)\n",
    "        X = X.permute((1,0,2,3))\n",
    "        X = X.squeeze(dim=3)\n",
    "        X,_ = self.rnn(X)\n",
    "        X = self.linear(X)\n",
    "#         y_hat = self.softmax(X)\n",
    "#         return y_hat\n",
    "        return X\n",
    "\n",
    "    def cal_finnal_width(self):\n",
    "        width = self.img_width\n",
    "        for i in range(5):\n",
    "            if width%2 == 0:\n",
    "                width = int(width/2)\n",
    "            else:\n",
    "                width = int(width/2)+1\n",
    "        return width\n",
    "\n",
    "class MyDataLoader():\n",
    "    def __init__(self,my_dataset,batch_size=20,use_my_collate=True,shuffle=False,):\n",
    "        from torch.utils.data import DataLoader\n",
    "        if use_my_collate:\n",
    "            self.data_loader = DataLoader(my_dataset,batch_size=batch_size,shuffle=shuffle,collate_fn=self.my_collate)\n",
    "        else:\n",
    "            self.data_loader = DataLoader(my_dataset,batch_size=batch_size,shuffle=shuffle)\n",
    "        \n",
    "    def my_collate(self,batch_data):\n",
    "        '''\n",
    "        batch_data shape: [(feat_array,label_list),(feat_array,label_list),……]\n",
    "        '''\n",
    "        feat_list =[]\n",
    "        label_list = []\n",
    "        label_len_list = []\n",
    "        for sample in batch_data:\n",
    "            feat_list.append(torch.from_numpy(sample[0].transpose((2,0,1))))\n",
    "            label_list.extend(sample[1])\n",
    "            label_len_list.append(len(sample[1]))\n",
    "            \n",
    "        feat = torch.stack(feat_list).float()\n",
    "        label = torch.Tensor(label_list).int()\n",
    "        label_len = torch.Tensor(label_len_list).int()\n",
    "        \n",
    "        return feat,label,label_len\n",
    "        \n",
    "class MyTrain():\n",
    "    def __init__(self,max_epoch=1,batch_size=20,lr=0.001,random_seed=None,grad_threshold=10,T=30,img_width=200,out_dir='./',dropout=0):\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "        self.grad_threshold = grad_threshold\n",
    "        self.T = T\n",
    "        self.img_width = img_width\n",
    "        self.img_height = int(0.5*img_width)\n",
    "        self.out_dir = out_dir\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def train(self):\n",
    "        import json\n",
    "        import glob\n",
    "        \n",
    "        max_epoch,batch_size,grad_threshold = self.max_epoch,self.batch_size,self.grad_threshold\n",
    "        \n",
    "        #fix random seed\n",
    "        if self.random_seed is not None:\n",
    "            self.fix_seed()\n",
    "            \n",
    "        #creat dataset instance\n",
    "        img_path = glob.glob('../input/train/*.png')\n",
    "        label_content = json.load(open('../input/train.json'))\n",
    "        img_path.sort()\n",
    "        my_dataset = MyDataset(img_path,label_content,self.img_width,self.img_height)\n",
    "\n",
    "        #creat model and loss instance\n",
    "        crnn_model = MyModel(self.T,self.img_width,self.dropout)\n",
    "        ctc_loss = nn.CTCLoss()\n",
    "        if torch.cuda.is_available():\n",
    "            crnn_model.cuda()\n",
    "#             ctc_loss.cuda()\n",
    "        \n",
    "        #creat optim instance\n",
    "        adam_optimizer = torch.optim.Adam(crnn_model.parameters(),lr=self.lr,weight_decay=0.0001)\n",
    "        batch_device = next(iter(crnn_model.parameters())).device\n",
    "        print('train device:',batch_device)\n",
    "        \n",
    "        acc_max = 0\n",
    "        epoch_index = 0\n",
    "\n",
    "        while acc_max < 0.90 and epoch_index < max_epoch :\n",
    "        \n",
    "            loss_list=[]\n",
    "            acc_list =[]\n",
    "            \n",
    "            from tqdm import tqdm\n",
    "            my_dataloader = MyDataLoader(my_dataset,batch_size=batch_size,shuffle=True).data_loader\n",
    "            my_dataloader = tqdm(my_dataloader,ncols=120)\n",
    "            \n",
    "            #train each batch data\n",
    "            for batch_index,batch_data in enumerate(my_dataloader):\n",
    "                \n",
    "                batch_feat = batch_data[0]\n",
    "                batch_label = batch_data[1]\n",
    "                batch_label_len = batch_data[2]\n",
    "                if torch.cuda.is_available():\n",
    "                    batch_feat = batch_feat.cuda()\n",
    "                    batch_label = batch_label.cuda()\n",
    "                    batch_label_len = batch_label_len.cuda()\n",
    "                    \n",
    "                adam_optimizer.zero_grad()\n",
    "                \n",
    "                batch_y_hat = crnn_model(batch_feat) \n",
    "                batch_y_hat = batch_y_hat.to(torch.float64)  #经过crnn计算出来结果是float32,传入ctcloss使用GPU时会报错，把这个结果改成float64就不会报错\n",
    "                batch_y_hat_len = torch.LongTensor([len(batch_y_hat)]*batch_size)\n",
    "                \n",
    "#                 print('1:',batch_y_hat,'\\n','2:',batch_label,'\\n','3:',batch_y_hat_len,'\\n','4:',batch_label_len)                \n",
    "                batch_loss = ctc_loss(batch_y_hat,batch_label,batch_y_hat_len,batch_label_len)\n",
    "                batch_loss.backward()\n",
    "                \n",
    "                #进行梯度裁剪，避免梯度爆炸\n",
    "                nn.utils.clip_grad_norm_(crnn_model.parameters(),grad_threshold)\n",
    "                                \n",
    "                #更新模型参数\n",
    "                adam_optimizer.step()\n",
    "                \n",
    "                #调整学习率\n",
    "                adam_optimizer.param_groups[0]['lr'] = self.lr*(0.8**(epoch_index%10))\n",
    "                \n",
    "                #更新tqdm进度条的描述内容\n",
    "                batch_acc = self.get_accurancy(batch_y_hat,batch_label,batch_label_len)\n",
    "                loss_list.append(batch_loss)\n",
    "                acc_list.append(batch_acc)\n",
    "                batch_lr = adam_optimizer.param_groups[0]['lr']\n",
    "                batch_loss_mean = sum(loss_list)/len(loss_list)\n",
    "                batch_acc_mean = round(sum(acc_list)/len(acc_list),3)\n",
    "                                \n",
    "                my_dataloader.set_description(f'epoch{epoch_index}| batch{batch_index}| loss: {round(batch_loss.item(),3)}| lr: {round(batch_lr,4)}| loss_mean: {round(batch_loss_mean.item(),3)}| batch_acc: {batch_acc_mean}')\n",
    "           \n",
    "            #保存最近一个epoch的模型参数，如果比之前的模型都好，则将其设置为最佳模型\n",
    "            if batch_acc_mean > acc_max:\n",
    "                acc_max = batch_acc_mean\n",
    "                torch.save(crnn_model.state_dict(),os.path.join(self.out_dir,f'crnn_resnet18_ctc_dropout{self.dropout}_best'))\n",
    "            \n",
    "            epoch_index+=1\n",
    "    \n",
    "    def fix_seed(self):\n",
    "        import random\n",
    "        import numpy as np\n",
    "        import torch\n",
    "        \n",
    "        random.seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        torch.random.manual_seed(self.random_seed)\n",
    "        torch.cuda.manual_seed_all(self.random_seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "    def get_accurancy(self,y_hat,label,label_len):\n",
    "        #y_hat(T,N,C)\n",
    "        y_hat = y_hat.permute(1,0,2).cpu()\n",
    "#         print('y_hat:',y_hat[0])\n",
    "        label =label.cpu()\n",
    "        label_len = label_len.cpu()\n",
    "        #pred(N,T)\n",
    "        pred = torch.argmax(y_hat,dim=2)\n",
    "#         print('pred:',pred[0])\n",
    "        batch_size = pred.shape[0]\n",
    "        acc = 0\n",
    "        #decode\n",
    "        for i in range(batch_size):\n",
    "            raw_pred_list = list(pred[i].numpy())\n",
    "#             print('raw_pred_list:',raw_pred_list)\n",
    "            pred_data = []\n",
    "            for j in range(len(raw_pred_list)):\n",
    "                if j == 0 and raw_pred_list[0] != 0:\n",
    "                    pred_data.append(raw_pred_list[0]-1)\n",
    "                if j != 0 and raw_pred_list[j] != raw_pred_list[j-1] and raw_pred_list[j] != 0:\n",
    "                    pred_data.append(raw_pred_list[j]-1)\n",
    "#             print('pred_data:',pred_data)\n",
    "            \n",
    "            label_start_index = int(torch.sum(label_len[:i]).item())\n",
    "            label_end_index = int(label_len[i].item())+label_start_index\n",
    "            label_data = list(label[label_start_index:label_end_index].int().numpy())\n",
    "            label_data = [x-1 for x in label_data]\n",
    "#             print(f'pred_data:{pred_data},label_data:{label_data}\\n')\n",
    "            \n",
    "            if pred_data == label_data:\n",
    "                acc+=1\n",
    "        acc/=batch_size\n",
    "        return acc\n",
    "        \n",
    "    def model_save(self,model):\n",
    "        pass\n",
    "    def model_load(self):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afefcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dropout_list = [0.7]\n",
    "    for dropout in dropout_list:\n",
    "        print('Dropout:',dropout)\n",
    "        test_train = MyTrain(max_epoch=50,T=30,img_width=200,dropout=dropout)\n",
    "        test_train.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
